{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:35:31.085138Z",
     "iopub.status.busy": "2022-04-15T06:35:31.084406Z",
     "iopub.status.idle": "2022-04-15T06:35:31.905632Z",
     "shell.execute_reply": "2022-04-15T06:35:31.904809Z",
     "shell.execute_reply.started": "2022-04-15T06:35:31.085100Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991230</td>\n",
       "      <td>0.943533</td>\n",
       "      <td>0.764677</td>\n",
       "      <td>0.618571</td>\n",
       "      <td>0.379632</td>\n",
       "      <td>0.190822</td>\n",
       "      <td>0.040237</td>\n",
       "      <td>0.025995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971482</td>\n",
       "      <td>0.928969</td>\n",
       "      <td>0.572933</td>\n",
       "      <td>0.178457</td>\n",
       "      <td>0.122962</td>\n",
       "      <td>0.132360</td>\n",
       "      <td>0.094392</td>\n",
       "      <td>0.089575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959149</td>\n",
       "      <td>0.701378</td>\n",
       "      <td>0.231778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080698</td>\n",
       "      <td>0.128376</td>\n",
       "      <td>0.187448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975795</td>\n",
       "      <td>0.934088</td>\n",
       "      <td>0.659637</td>\n",
       "      <td>0.249921</td>\n",
       "      <td>0.237116</td>\n",
       "      <td>0.281445</td>\n",
       "      <td>0.249921</td>\n",
       "      <td>0.249921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055816</td>\n",
       "      <td>0.261294</td>\n",
       "      <td>0.359847</td>\n",
       "      <td>0.433143</td>\n",
       "      <td>0.453698</td>\n",
       "      <td>0.499004</td>\n",
       "      <td>0.542796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677705</td>\n",
       "      <td>0.222392</td>\n",
       "      <td>0.257158</td>\n",
       "      <td>0.204690</td>\n",
       "      <td>0.054665</td>\n",
       "      <td>0.026152</td>\n",
       "      <td>0.118181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.926857</td>\n",
       "      <td>0.906347</td>\n",
       "      <td>0.636993</td>\n",
       "      <td>0.415038</td>\n",
       "      <td>0.374745</td>\n",
       "      <td>0.382581</td>\n",
       "      <td>0.358943</td>\n",
       "      <td>0.341359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99997</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.925835</td>\n",
       "      <td>0.587384</td>\n",
       "      <td>0.633226</td>\n",
       "      <td>0.632353</td>\n",
       "      <td>0.639283</td>\n",
       "      <td>0.614292</td>\n",
       "      <td>0.599155</td>\n",
       "      <td>0.517632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99998</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994762</td>\n",
       "      <td>0.829702</td>\n",
       "      <td>0.458193</td>\n",
       "      <td>0.264162</td>\n",
       "      <td>0.240228</td>\n",
       "      <td>0.213766</td>\n",
       "      <td>0.189291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>99999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925999</td>\n",
       "      <td>0.916477</td>\n",
       "      <td>0.404290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263034</td>\n",
       "      <td>0.385431</td>\n",
       "      <td>0.361067</td>\n",
       "      <td>0.332708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label         0         1         2         3         4  \\\n",
       "0          0    0.0  0.991230  0.943533  0.764677  0.618571  0.379632   \n",
       "1          1    0.0  0.971482  0.928969  0.572933  0.178457  0.122962   \n",
       "2          2    2.0  1.000000  0.959149  0.701378  0.231778  0.000000   \n",
       "3          3    0.0  0.975795  0.934088  0.659637  0.249921  0.237116   \n",
       "4          4    2.0  0.000000  0.055816  0.261294  0.359847  0.433143   \n",
       "...      ...    ...       ...       ...       ...       ...       ...   \n",
       "99995  99995    0.0  1.000000  0.677705  0.222392  0.257158  0.204690   \n",
       "99996  99996    2.0  0.926857  0.906347  0.636993  0.415038  0.374745   \n",
       "99997  99997    3.0  0.925835  0.587384  0.633226  0.632353  0.639283   \n",
       "99998  99998    2.0  1.000000  0.994762  0.829702  0.458193  0.264162   \n",
       "99999  99999    0.0  0.925999  0.916477  0.404290  0.000000  0.263034   \n",
       "\n",
       "              5         6         7  ...  195  196  197  198  199  200  201  \\\n",
       "0      0.190822  0.040237  0.025995  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1      0.132360  0.094392  0.089575  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2      0.080698  0.128376  0.187448  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3      0.281445  0.249921  0.249921  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4      0.453698  0.499004  0.542796  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "99995  0.054665  0.026152  0.118181  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "99996  0.382581  0.358943  0.341359  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "99997  0.614292  0.599155  0.517632  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "99998  0.240228  0.213766  0.189291  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "99999  0.385431  0.361067  0.332708  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       202  203  204  \n",
       "0      0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  \n",
       "...    ...  ...  ...  \n",
       "99995  0.0  0.0  0.0  \n",
       "99996  0.0  0.0  0.0  \n",
       "99997  0.0  0.0  0.0  \n",
       "99998  0.0  0.0  0.0  \n",
       "99999  0.0  0.0  0.0  \n",
       "\n",
       "[100000 rows x 207 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# 数据加载\n",
    "with open('./train1.pkl', 'rb') as file:\n",
    "    train1 = pickle.load(file)\n",
    "train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:35:31.907943Z",
     "iopub.status.busy": "2022-04-15T06:35:31.907354Z",
     "iopub.status.idle": "2022-04-15T06:35:32.019357Z",
     "shell.execute_reply": "2022-04-15T06:35:32.018568Z",
     "shell.execute_reply.started": "2022-04-15T06:35:31.907907Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.991571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631816</td>\n",
       "      <td>0.136230</td>\n",
       "      <td>0.041420</td>\n",
       "      <td>0.102707</td>\n",
       "      <td>0.120854</td>\n",
       "      <td>0.123428</td>\n",
       "      <td>0.107915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.607553</td>\n",
       "      <td>0.541708</td>\n",
       "      <td>0.340694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090708</td>\n",
       "      <td>0.164924</td>\n",
       "      <td>0.195034</td>\n",
       "      <td>0.168838</td>\n",
       "      <td>0.198844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.38996</td>\n",
       "      <td>0.386932</td>\n",
       "      <td>0.367251</td>\n",
       "      <td>0.363917</td>\n",
       "      <td>0.360574</td>\n",
       "      <td>0.357245</td>\n",
       "      <td>0.350575</td>\n",
       "      <td>0.350575</td>\n",
       "      <td>0.350565</td>\n",
       "      <td>0.363874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>0.975273</td>\n",
       "      <td>0.671097</td>\n",
       "      <td>0.686759</td>\n",
       "      <td>0.708482</td>\n",
       "      <td>0.718660</td>\n",
       "      <td>0.716763</td>\n",
       "      <td>0.720548</td>\n",
       "      <td>0.701656</td>\n",
       "      <td>0.596579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>0.995635</td>\n",
       "      <td>0.917025</td>\n",
       "      <td>0.521096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.221770</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.490399</td>\n",
       "      <td>0.527158</td>\n",
       "      <td>0.518056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887949</td>\n",
       "      <td>0.745565</td>\n",
       "      <td>0.531720</td>\n",
       "      <td>0.380320</td>\n",
       "      <td>0.224631</td>\n",
       "      <td>0.091148</td>\n",
       "      <td>0.057639</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>119995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833028</td>\n",
       "      <td>0.634047</td>\n",
       "      <td>0.639118</td>\n",
       "      <td>0.623852</td>\n",
       "      <td>0.598042</td>\n",
       "      <td>0.613583</td>\n",
       "      <td>0.623852</td>\n",
       "      <td>0.628958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>119996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.825971</td>\n",
       "      <td>0.452105</td>\n",
       "      <td>0.082227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137119</td>\n",
       "      <td>0.201082</td>\n",
       "      <td>0.165688</td>\n",
       "      <td>0.158125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>119997</td>\n",
       "      <td>0.951745</td>\n",
       "      <td>0.916261</td>\n",
       "      <td>0.667525</td>\n",
       "      <td>0.351985</td>\n",
       "      <td>0.255330</td>\n",
       "      <td>0.197383</td>\n",
       "      <td>0.173536</td>\n",
       "      <td>0.141934</td>\n",
       "      <td>0.134542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>119998</td>\n",
       "      <td>0.927669</td>\n",
       "      <td>0.677190</td>\n",
       "      <td>0.242906</td>\n",
       "      <td>0.055362</td>\n",
       "      <td>0.102120</td>\n",
       "      <td>0.072236</td>\n",
       "      <td>0.021010</td>\n",
       "      <td>0.038288</td>\n",
       "      <td>0.048557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>119999</td>\n",
       "      <td>0.665321</td>\n",
       "      <td>0.527064</td>\n",
       "      <td>0.516663</td>\n",
       "      <td>0.376442</td>\n",
       "      <td>0.489262</td>\n",
       "      <td>0.480725</td>\n",
       "      <td>0.459160</td>\n",
       "      <td>0.482864</td>\n",
       "      <td>0.469983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id         0         1         2         3         4         5  \\\n",
       "0      100000  0.991571  1.000000  0.631816  0.136230  0.041420  0.102707   \n",
       "1      100001  0.607553  0.541708  0.340694  0.000000  0.090708  0.164924   \n",
       "2      100002  0.975273  0.671097  0.686759  0.708482  0.718660  0.716763   \n",
       "3      100003  0.995635  0.917025  0.521096  0.000000  0.221770  0.404100   \n",
       "4      100004  1.000000  0.887949  0.745565  0.531720  0.380320  0.224631   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "19995  119995  1.000000  0.833028  0.634047  0.639118  0.623852  0.598042   \n",
       "19996  119996  1.000000  0.825971  0.452105  0.082227  0.000000  0.137119   \n",
       "19997  119997  0.951745  0.916261  0.667525  0.351985  0.255330  0.197383   \n",
       "19998  119998  0.927669  0.677190  0.242906  0.055362  0.102120  0.072236   \n",
       "19999  119999  0.665321  0.527064  0.516663  0.376442  0.489262  0.480725   \n",
       "\n",
       "              6         7         8  ...      195       196       197  \\\n",
       "0      0.120854  0.123428  0.107915  ...  0.00000  0.000000  0.000000   \n",
       "1      0.195034  0.168838  0.198844  ...  0.38996  0.386932  0.367251   \n",
       "2      0.720548  0.701656  0.596579  ...  0.00000  0.000000  0.000000   \n",
       "3      0.490399  0.527158  0.518056  ...  0.00000  0.000000  0.000000   \n",
       "4      0.091148  0.057639  0.003915  ...  0.00000  0.000000  0.000000   \n",
       "...         ...       ...       ...  ...      ...       ...       ...   \n",
       "19995  0.613583  0.623852  0.628958  ...  0.00000  0.000000  0.000000   \n",
       "19996  0.201082  0.165688  0.158125  ...  0.00000  0.000000  0.000000   \n",
       "19997  0.173536  0.141934  0.134542  ...  0.00000  0.000000  0.000000   \n",
       "19998  0.021010  0.038288  0.048557  ...  0.00000  0.000000  0.000000   \n",
       "19999  0.459160  0.482864  0.469983  ...  0.00000  0.000000  0.000000   \n",
       "\n",
       "            198       199       200       201       202       203       204  \n",
       "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1      0.363917  0.360574  0.357245  0.350575  0.350575  0.350565  0.363874  \n",
       "2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "19995  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "19996  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "19997  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "19998  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "19999  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[20000 rows x 206 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据加载\n",
    "with open('./test1.pkl', 'rb') as file:\n",
    "    test1 = pickle.load(file)\n",
    "test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构造-paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:35:32.021154Z",
     "iopub.status.busy": "2022-04-15T06:35:32.020584Z",
     "iopub.status.idle": "2022-04-15T06:35:33.276579Z",
     "shell.execute_reply": "2022-04-15T06:35:33.275806Z",
     "shell.execute_reply.started": "2022-04-15T06:35:32.021117Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle.io import Dataset, BatchSampler, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:35:33.279015Z",
     "iopub.status.busy": "2022-04-15T06:35:33.278546Z",
     "iopub.status.idle": "2022-04-15T06:35:33.287071Z",
     "shell.execute_reply": "2022-04-15T06:35:33.286553Z",
     "shell.execute_reply.started": "2022-04-15T06:35:33.278980Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 自定义DataSet\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    步骤一：继承paddle.io.Dataset类\n",
    "    \"\"\"\n",
    "    def __init__(self, data, is_train):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.is_train = is_train\n",
    "        # 训练集\n",
    "        if self.is_train:\n",
    "            train_x = data.drop(['id','label'], axis=1)\n",
    "            train_y = data['label']\n",
    "            self.data_x = paddle.to_tensor(train_x.values, dtype='float32')\n",
    "            self.data_y = paddle.to_tensor(train_y.values, dtype='int64')\n",
    "        else:\n",
    "            test_x = data.drop(['id'], axis=1)\n",
    "            self.data_x=paddle.to_tensor(test_x.values, dtype='float32')\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据）\n",
    "        \"\"\"\n",
    "        if self.is_train:\n",
    "            data = self.data_x[index]\n",
    "            label = self.data_y[index]\n",
    "            return data, label\n",
    "        else:\n",
    "            data = self.data_x[index]\n",
    "            return [data]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        步骤四：实现__len__方法，返回数据集总数目\n",
    "        \"\"\"\n",
    "        return len(self.data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:35:33.288609Z",
     "iopub.status.busy": "2022-04-15T06:35:33.288169Z",
     "iopub.status.idle": "2022-04-15T06:35:33.297199Z",
     "shell.execute_reply": "2022-04-15T06:35:33.296708Z",
     "shell.execute_reply.started": "2022-04-15T06:35:33.288583Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paddle.vision.transforms import Transpose\n",
    "\n",
    "# CNN模型\n",
    "class CNNModel(paddle.nn.Layer):\n",
    "    # 定义模型结构\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # 定义CNN网络\n",
    "        self.conv1 = paddle.nn.Conv1D(in_channels=1, out_channels=32, kernel_size=5, padding='SAME', )\n",
    "        self.conv2 = paddle.nn.Conv1D(in_channels=32, out_channels=64, kernel_size=5, padding='SAME')\n",
    "        self.conv3 = paddle.nn.Conv1D(in_channels=64, out_channels=128, kernel_size=5, padding='SAME')\n",
    "        self.max_pool1 = paddle.nn.MaxPool1D(kernel_size=5, stride=2, padding='SAME')\n",
    "        self.dropout = paddle.nn.Dropout(0.5)\n",
    "        self.flatten = paddle.nn.Flatten()\n",
    "        #self.fc1 = paddle.nn.Linear(sequence_length*14, 512)\n",
    "        self.fc1 = paddle.nn.Linear(in_features=13184, out_features=512)\n",
    "        self.fc2 = paddle.nn.Linear(512,4)\n",
    "        # 使用多分类器\n",
    "        self.softmax = paddle.nn.Softmax()\n",
    "\n",
    "    # 前向传播\n",
    "    def forward(self, input):\n",
    "        '''前向计算'''\n",
    "        #print('input', input.shape)\n",
    "        #input = input.values\n",
    "        #input = input.reshape(input.shape[0], 205, 1)\n",
    "        #np.array(data_y.numpy()).reshape(-1, 1)\n",
    "        input = paddle.reshape(input, [input.shape[0], 205, 1])\n",
    "        # 转置\n",
    "        transform_cnn = Transpose(order=(0,2,1))\n",
    "        input = transform_cnn(input)\n",
    "        # 前向传播\n",
    "        x = self.conv1(input)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        # 全连接层        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        out = self.softmax(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:35:33.298670Z",
     "iopub.status.busy": "2022-04-15T06:35:33.298321Z",
     "iopub.status.idle": "2022-04-15T06:35:33.302017Z",
     "shell.execute_reply": "2022-04-15T06:35:33.301541Z",
     "shell.execute_reply.started": "2022-04-15T06:35:33.298645Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义评价函数\n",
    "def mae_loss(y_pred,y_true):\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    loss = sum(sum(abs(y_pred-y_true)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:35:33.303120Z",
     "iopub.status.busy": "2022-04-15T06:35:33.302962Z",
     "iopub.status.idle": "2022-04-15T06:35:33.996974Z",
     "shell.execute_reply": "2022-04-15T06:35:33.996351Z",
     "shell.execute_reply.started": "2022-04-15T06:35:33.303101Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.991230</td>\n",
       "      <td>0.943533</td>\n",
       "      <td>0.764677</td>\n",
       "      <td>0.618571</td>\n",
       "      <td>0.379632</td>\n",
       "      <td>0.190822</td>\n",
       "      <td>0.040237</td>\n",
       "      <td>0.025995</td>\n",
       "      <td>0.031709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.971482</td>\n",
       "      <td>0.928969</td>\n",
       "      <td>0.572933</td>\n",
       "      <td>0.178457</td>\n",
       "      <td>0.122962</td>\n",
       "      <td>0.132360</td>\n",
       "      <td>0.094392</td>\n",
       "      <td>0.089575</td>\n",
       "      <td>0.030481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959149</td>\n",
       "      <td>0.701378</td>\n",
       "      <td>0.231778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080698</td>\n",
       "      <td>0.128376</td>\n",
       "      <td>0.187448</td>\n",
       "      <td>0.280826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.975795</td>\n",
       "      <td>0.934088</td>\n",
       "      <td>0.659637</td>\n",
       "      <td>0.249921</td>\n",
       "      <td>0.237116</td>\n",
       "      <td>0.281445</td>\n",
       "      <td>0.249921</td>\n",
       "      <td>0.249921</td>\n",
       "      <td>0.241397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055816</td>\n",
       "      <td>0.261294</td>\n",
       "      <td>0.359847</td>\n",
       "      <td>0.433143</td>\n",
       "      <td>0.453698</td>\n",
       "      <td>0.499004</td>\n",
       "      <td>0.542796</td>\n",
       "      <td>0.616904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677705</td>\n",
       "      <td>0.222392</td>\n",
       "      <td>0.257158</td>\n",
       "      <td>0.204690</td>\n",
       "      <td>0.054665</td>\n",
       "      <td>0.026152</td>\n",
       "      <td>0.118181</td>\n",
       "      <td>0.244838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99996</td>\n",
       "      <td>0.926857</td>\n",
       "      <td>0.906347</td>\n",
       "      <td>0.636993</td>\n",
       "      <td>0.415038</td>\n",
       "      <td>0.374745</td>\n",
       "      <td>0.382581</td>\n",
       "      <td>0.358943</td>\n",
       "      <td>0.341359</td>\n",
       "      <td>0.336525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99997</td>\n",
       "      <td>0.925835</td>\n",
       "      <td>0.587384</td>\n",
       "      <td>0.633226</td>\n",
       "      <td>0.632353</td>\n",
       "      <td>0.639283</td>\n",
       "      <td>0.614292</td>\n",
       "      <td>0.599155</td>\n",
       "      <td>0.517632</td>\n",
       "      <td>0.403803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994762</td>\n",
       "      <td>0.829702</td>\n",
       "      <td>0.458193</td>\n",
       "      <td>0.264162</td>\n",
       "      <td>0.240228</td>\n",
       "      <td>0.213766</td>\n",
       "      <td>0.189291</td>\n",
       "      <td>0.203816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>99999</td>\n",
       "      <td>0.925999</td>\n",
       "      <td>0.916477</td>\n",
       "      <td>0.404290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263034</td>\n",
       "      <td>0.385431</td>\n",
       "      <td>0.361067</td>\n",
       "      <td>0.332708</td>\n",
       "      <td>0.339850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         0         1         2         3         4         5  \\\n",
       "0          0  0.991230  0.943533  0.764677  0.618571  0.379632  0.190822   \n",
       "1          1  0.971482  0.928969  0.572933  0.178457  0.122962  0.132360   \n",
       "2          2  1.000000  0.959149  0.701378  0.231778  0.000000  0.080698   \n",
       "3          3  0.975795  0.934088  0.659637  0.249921  0.237116  0.281445   \n",
       "4          4  0.000000  0.055816  0.261294  0.359847  0.433143  0.453698   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "99995  99995  1.000000  0.677705  0.222392  0.257158  0.204690  0.054665   \n",
       "99996  99996  0.926857  0.906347  0.636993  0.415038  0.374745  0.382581   \n",
       "99997  99997  0.925835  0.587384  0.633226  0.632353  0.639283  0.614292   \n",
       "99998  99998  1.000000  0.994762  0.829702  0.458193  0.264162  0.240228   \n",
       "99999  99999  0.925999  0.916477  0.404290  0.000000  0.263034  0.385431   \n",
       "\n",
       "              6         7         8  ...  196  197  198  199  200  201  202  \\\n",
       "0      0.040237  0.025995  0.031709  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1      0.094392  0.089575  0.030481  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2      0.128376  0.187448  0.280826  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3      0.249921  0.249921  0.241397  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4      0.499004  0.542796  0.616904  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "99995  0.026152  0.118181  0.244838  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "99996  0.358943  0.341359  0.336525  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "99997  0.599155  0.517632  0.403803  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "99998  0.213766  0.189291  0.203816  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "99999  0.361067  0.332708  0.339850  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       203  204  label  \n",
       "0      0.0  0.0    0.0  \n",
       "1      0.0  0.0    0.0  \n",
       "2      0.0  0.0    2.0  \n",
       "3      0.0  0.0    0.0  \n",
       "4      0.0  0.0    2.0  \n",
       "...    ...  ...    ...  \n",
       "99995  0.0  0.0    0.0  \n",
       "99996  0.0  0.0    2.0  \n",
       "99997  0.0  0.0    3.0  \n",
       "99998  0.0  0.0    2.0  \n",
       "99999  0.0  0.0    0.0  \n",
       "\n",
       "[100000 rows x 207 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train1.drop(['label'], axis=1)\n",
    "train_y = train1['label']\n",
    "train_df = pd.concat([train_x, train_y], axis=1)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:35:33.998383Z",
     "iopub.status.busy": "2022-04-15T06:35:33.997953Z",
     "iopub.status.idle": "2022-04-15T06:35:36.245071Z",
     "shell.execute_reply": "2022-04-15T06:35:36.244406Z",
     "shell.execute_reply.started": "2022-04-15T06:35:33.998354Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_df, is_train=True)\n",
    "test_dataset = MyDataset(test1, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:35:36.246498Z",
     "iopub.status.busy": "2022-04-15T06:35:36.246084Z",
     "iopub.status.idle": "2022-04-15T06:35:36.250315Z",
     "shell.execute_reply": "2022-04-15T06:35:36.249808Z",
     "shell.execute_reply.started": "2022-04-15T06:35:36.246467Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1280\n",
    "train_reader = paddle.io.DataLoader(train_dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True,\n",
    "                    num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:35:36.252613Z",
     "iopub.status.busy": "2022-04-15T06:35:36.252239Z",
     "iopub.status.idle": "2022-04-15T06:35:38.415650Z",
     "shell.execute_reply": "2022-04-15T06:35:38.415083Z",
     "shell.execute_reply.started": "2022-04-15T06:35:36.252585Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0415 14:35:36.255252  3353 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0415 14:35:36.259578  3353 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(sparse=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建CNN模型\n",
    "model=CNNModel()\n",
    "#param_dict = paddle.load('work/model/cnn.model')   #读取保存的参数\n",
    "#model.load_dict(param_dict)    #加载参数\n",
    "# 训练模式\n",
    "model.train() \n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False) # 数据转换\n",
    "yy = train1['label'].values.reshape(-1, 1)\n",
    "onehot_encoder.fit(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:35:38.417051Z",
     "iopub.status.busy": "2022-04-15T06:35:38.416629Z",
     "iopub.status.idle": "2022-04-15T06:42:33.134643Z",
     "shell.execute_reply": "2022-04-15T06:42:33.134030Z",
     "shell.execute_reply.started": "2022-04-15T06:35:38.417021Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,batch:0 loss:1.4682711362838745\n",
      "epoch:0,batch:1 loss:1.1155433654785156\n",
      "epoch:0,batch:2 loss:1.1131995916366577\n",
      "epoch:0,batch:3 loss:1.1163246631622314\n",
      "epoch:0,batch:4 loss:1.098355770111084\n",
      "epoch:0,batch:5 loss:1.092887043952942\n",
      "epoch:0,batch:6 loss:1.1116372346878052\n",
      "epoch:0,batch:7 loss:1.0967934131622314\n",
      "epoch:0,batch:8 loss:1.0835121870040894\n",
      "epoch:0,batch:9 loss:1.108512043952942\n",
      "epoch:0,batch:10 loss:1.1069494485855103\n",
      "epoch:0,batch:11 loss:1.0889809131622314\n",
      "epoch:0,batch:12 loss:1.1311683654785156\n",
      "epoch:0,batch:13 loss:1.1210120916366577\n",
      "epoch:0,batch:14 loss:1.1178861856460571\n",
      "epoch:0,batch:15 loss:1.080386996269226\n",
      "epoch:0,batch:16 loss:1.106168270111084\n",
      "epoch:0,batch:17 loss:1.120230793952942\n",
      "epoch:0,batch:18 loss:1.0921058654785156\n",
      "epoch:0,batch:19 loss:1.0835120677947998\n",
      "epoch:0,batch:20 loss:1.096793293952942\n",
      "epoch:0,batch:21 loss:1.0678870677947998\n",
      "epoch:0,batch:22 loss:1.1139808893203735\n",
      "epoch:0,batch:23 loss:1.1030433177947998\n",
      "epoch:0,batch:24 loss:1.0803871154785156\n",
      "epoch:0,batch:25 loss:1.096793293952942\n",
      "epoch:0,batch:26 loss:1.0952308177947998\n",
      "epoch:0,batch:27 loss:1.0952308177947998\n",
      "epoch:0,batch:28 loss:1.102262020111084\n",
      "epoch:0,batch:29 loss:1.0944496393203735\n",
      "epoch:0,batch:30 loss:1.0858558416366577\n",
      "epoch:0,batch:31 loss:1.0874183177947998\n",
      "epoch:0,batch:32 loss:1.0764808654785156\n",
      "epoch:0,batch:33 loss:1.1366370916366577\n",
      "epoch:0,batch:34 loss:1.088199496269226\n",
      "epoch:0,batch:35 loss:1.1124184131622314\n",
      "epoch:0,batch:36 loss:1.0921058654785156\n",
      "epoch:0,batch:37 loss:1.0749183893203735\n",
      "epoch:0,batch:38 loss:1.0991370677947998\n",
      "epoch:0,batch:39 loss:1.092105746269226\n",
      "epoch:0,batch:40 loss:1.0850746631622314\n",
      "epoch:0,batch:41 loss:1.112418293952942\n",
      "epoch:0,batch:42 loss:1.0819495916366577\n",
      "epoch:0,batch:43 loss:1.0913245677947998\n",
      "epoch:0,batch:44 loss:1.108512043952942\n",
      "epoch:0,batch:45 loss:1.0967934131622314\n",
      "epoch:0,batch:46 loss:1.0881996154785156\n",
      "epoch:0,batch:47 loss:1.1116371154785156\n",
      "epoch:0,batch:48 loss:1.1116371154785156\n",
      "epoch:0,batch:49 loss:1.103824496269226\n",
      "epoch:0,batch:50 loss:1.1100746393203735\n",
      "epoch:0,batch:51 loss:1.0913245677947998\n",
      "epoch:0,batch:52 loss:1.0796058177947998\n",
      "epoch:0,batch:53 loss:1.0827308893203735\n",
      "epoch:0,batch:54 loss:1.1124184131622314\n",
      "epoch:0,batch:55 loss:1.096793293952942\n",
      "epoch:0,batch:56 loss:1.108512043952942\n",
      "epoch:0,batch:57 loss:1.1147621870040894\n",
      "epoch:0,batch:58 loss:1.0897620916366577\n",
      "epoch:0,batch:59 loss:1.1186683177947998\n",
      "epoch:0,batch:60 loss:1.0975744724273682\n",
      "epoch:0,batch:61 loss:1.102262020111084\n",
      "epoch:0,batch:62 loss:1.1178871393203735\n",
      "epoch:0,batch:63 loss:1.1256996393203735\n",
      "epoch:0,batch:64 loss:1.1171058416366577\n",
      "epoch:0,batch:65 loss:1.117887020111084\n",
      "epoch:0,batch:66 loss:1.094449520111084\n",
      "epoch:0,batch:67 loss:1.098355770111084\n",
      "epoch:0,batch:68 loss:1.1108558177947998\n",
      "epoch:0,batch:69 loss:1.0842933654785156\n",
      "epoch:0,batch:70 loss:1.0874183177947998\n",
      "epoch:0,batch:71 loss:1.1014808416366577\n",
      "epoch:0,batch:72 loss:1.1077308654785156\n",
      "epoch:0,batch:73 loss:1.0921058654785156\n",
      "epoch:0,batch:74 loss:1.0780433416366577\n",
      "epoch:0,batch:75 loss:1.0975745916366577\n",
      "epoch:0,batch:76 loss:1.1069495677947998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:08<06:49,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,batch:77 loss:1.102262020111084\n",
      "epoch:0, train_loss:1.102262020111084\n",
      "epoch:1,batch:0 loss:1.1147620677947998\n",
      "epoch:1,batch:1 loss:1.120230793952942\n",
      "epoch:1,batch:2 loss:1.0936684608459473\n",
      "epoch:1,batch:3 loss:1.0686683654785156\n",
      "epoch:1,batch:4 loss:1.0967934131622314\n",
      "epoch:1,batch:5 loss:1.0975745916366577\n",
      "epoch:1,batch:6 loss:1.1335121393203735\n",
      "epoch:1,batch:7 loss:1.0967934131622314\n",
      "epoch:1,batch:8 loss:1.112418293952942\n",
      "epoch:1,batch:9 loss:1.1186683177947998\n",
      "epoch:1,batch:10 loss:1.1053870916366577\n",
      "epoch:1,batch:11 loss:1.0975745916366577\n",
      "epoch:1,batch:12 loss:1.1147620677947998\n",
      "epoch:1,batch:13 loss:1.0944496393203735\n",
      "epoch:1,batch:14 loss:1.1077308654785156\n",
      "epoch:1,batch:15 loss:1.086637020111084\n",
      "epoch:1,batch:16 loss:1.0905433893203735\n",
      "epoch:1,batch:17 loss:1.098355770111084\n",
      "epoch:1,batch:18 loss:1.0897620916366577\n",
      "epoch:1,batch:19 loss:1.0936683416366577\n",
      "epoch:1,batch:20 loss:1.113980770111084\n",
      "epoch:1,batch:21 loss:1.1030433177947998\n",
      "epoch:1,batch:22 loss:1.0983558893203735\n",
      "epoch:1,batch:23 loss:1.092887043952942\n",
      "epoch:1,batch:24 loss:1.1147620677947998\n",
      "epoch:1,batch:25 loss:1.1217933893203735\n",
      "epoch:1,batch:26 loss:1.1131995916366577\n",
      "epoch:1,batch:27 loss:1.096793293952942\n",
      "epoch:1,batch:28 loss:1.1014808416366577\n",
      "epoch:1,batch:29 loss:1.0936683416366577\n",
      "epoch:1,batch:30 loss:1.125699520111084\n",
      "epoch:1,batch:31 loss:1.0764809846878052\n",
      "epoch:1,batch:32 loss:1.0866371393203735\n",
      "epoch:1,batch:33 loss:1.1100746393203735\n",
      "epoch:1,batch:34 loss:1.0921058654785156\n",
      "epoch:1,batch:35 loss:1.1116371154785156\n",
      "epoch:1,batch:36 loss:1.090543270111084\n",
      "epoch:1,batch:37 loss:1.1030433177947998\n",
      "epoch:1,batch:38 loss:1.104605793952942\n",
      "epoch:1,batch:39 loss:1.1069495677947998\n",
      "epoch:1,batch:40 loss:1.1053869724273682\n",
      "epoch:1,batch:41 loss:1.1069495677947998\n",
      "epoch:1,batch:42 loss:1.1147619485855103\n",
      "epoch:1,batch:43 loss:1.0928871631622314\n",
      "epoch:1,batch:44 loss:1.082730770111084\n",
      "epoch:1,batch:45 loss:1.1046059131622314\n",
      "epoch:1,batch:46 loss:1.1038246154785156\n",
      "epoch:1,batch:47 loss:1.0835120677947998\n",
      "epoch:1,batch:48 loss:1.1077308654785156\n",
      "epoch:1,batch:49 loss:1.0725746154785156\n",
      "epoch:1,batch:50 loss:1.1046059131622314\n",
      "epoch:1,batch:51 loss:1.1171058416366577\n",
      "epoch:1,batch:52 loss:1.0866371393203735\n",
      "epoch:1,batch:53 loss:1.080386996269226\n",
      "epoch:1,batch:54 loss:1.1053872108459473\n",
      "epoch:1,batch:55 loss:1.096793293952942\n",
      "epoch:1,batch:56 loss:1.0991370677947998\n",
      "epoch:1,batch:57 loss:1.120230793952942\n",
      "epoch:1,batch:58 loss:1.1116371154785156\n",
      "epoch:1,batch:59 loss:1.0952308177947998\n",
      "epoch:1,batch:60 loss:1.0874183177947998\n",
      "epoch:1,batch:61 loss:1.0913246870040894\n",
      "epoch:1,batch:62 loss:1.1030434370040894\n",
      "epoch:1,batch:63 loss:1.0756995677947998\n",
      "epoch:1,batch:64 loss:1.112418293952942\n",
      "epoch:1,batch:65 loss:1.1194496154785156\n",
      "epoch:1,batch:66 loss:1.1069495677947998\n",
      "epoch:1,batch:67 loss:1.0913245677947998\n",
      "epoch:1,batch:68 loss:1.092887043952942\n",
      "epoch:1,batch:69 loss:1.0975745916366577\n",
      "epoch:1,batch:70 loss:1.0921058654785156\n",
      "epoch:1,batch:71 loss:1.1030433177947998\n",
      "epoch:1,batch:72 loss:1.1014808416366577\n",
      "epoch:1,batch:73 loss:1.090543270111084\n",
      "epoch:1,batch:74 loss:1.086637020111084\n",
      "epoch:1,batch:75 loss:1.0897619724273682\n",
      "epoch:1,batch:76 loss:1.1085121631622314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:16<06:36,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1,batch:77 loss:1.0999183654785156\n",
      "epoch:1, train_loss:1.0999183654785156\n",
      "epoch:2,batch:0 loss:1.121793270111084\n",
      "epoch:2,batch:1 loss:1.1124184131622314\n",
      "epoch:2,batch:2 loss:1.0960121154785156\n",
      "epoch:2,batch:3 loss:1.0928871631622314\n",
      "epoch:2,batch:4 loss:1.1163246631622314\n",
      "epoch:2,batch:5 loss:1.124137043952942\n",
      "epoch:2,batch:6 loss:1.0780434608459473\n",
      "epoch:2,batch:7 loss:1.0639808177947998\n",
      "epoch:2,batch:8 loss:1.1092933416366577\n",
      "epoch:2,batch:9 loss:1.1014808416366577\n",
      "epoch:2,batch:10 loss:1.1053870916366577\n",
      "epoch:2,batch:11 loss:1.1053869724273682\n",
      "epoch:2,batch:12 loss:1.0960121154785156\n",
      "epoch:2,batch:13 loss:1.1092933416366577\n",
      "epoch:2,batch:14 loss:1.0905433893203735\n",
      "epoch:2,batch:15 loss:1.0991370677947998\n",
      "epoch:2,batch:16 loss:1.1077308654785156\n",
      "epoch:2,batch:17 loss:1.1108558177947998\n",
      "epoch:2,batch:18 loss:1.077262043952942\n",
      "epoch:2,batch:19 loss:1.0897620916366577\n",
      "epoch:2,batch:20 loss:1.0913245677947998\n",
      "epoch:2,batch:21 loss:1.0991370677947998\n",
      "epoch:2,batch:22 loss:1.0983558893203735\n",
      "epoch:2,batch:23 loss:1.1022621393203735\n",
      "epoch:2,batch:24 loss:1.1296058893203735\n",
      "epoch:2,batch:25 loss:1.112418293952942\n",
      "epoch:2,batch:26 loss:1.1342933177947998\n",
      "epoch:2,batch:27 loss:1.107730746269226\n",
      "epoch:2,batch:28 loss:1.0999183654785156\n",
      "epoch:2,batch:29 loss:1.092887043952942\n",
      "epoch:2,batch:30 loss:1.0967934131622314\n",
      "epoch:2,batch:31 loss:1.1100746393203735\n",
      "epoch:2,batch:32 loss:1.1202309131622314\n",
      "epoch:2,batch:33 loss:1.0913245677947998\n",
      "epoch:2,batch:34 loss:1.1077308654785156\n",
      "epoch:2,batch:35 loss:1.102262020111084\n",
      "epoch:2,batch:36 loss:1.0975745916366577\n",
      "epoch:2,batch:37 loss:1.1022621393203735\n",
      "epoch:2,batch:38 loss:1.108512043952942\n",
      "epoch:2,batch:39 loss:1.064761996269226\n",
      "epoch:2,batch:40 loss:1.0858558416366577\n",
      "epoch:2,batch:41 loss:1.1053870916366577\n",
      "epoch:2,batch:42 loss:1.0975745916366577\n",
      "epoch:2,batch:43 loss:1.100699543952942\n",
      "epoch:2,batch:44 loss:1.106168270111084\n",
      "epoch:2,batch:45 loss:1.1053870916366577\n",
      "epoch:2,batch:46 loss:1.1085121631622314\n",
      "epoch:2,batch:47 loss:1.1085121631622314\n",
      "epoch:2,batch:48 loss:1.1038246154785156\n",
      "epoch:2,batch:49 loss:1.096793293952942\n",
      "epoch:2,batch:50 loss:1.068668246269226\n",
      "epoch:2,batch:51 loss:1.1186683177947998\n",
      "epoch:2,batch:52 loss:1.0913245677947998\n",
      "epoch:2,batch:53 loss:1.1038246154785156\n",
      "epoch:2,batch:54 loss:1.1233558654785156\n",
      "epoch:2,batch:55 loss:1.1046059131622314\n",
      "epoch:2,batch:56 loss:1.0991370677947998\n",
      "epoch:2,batch:57 loss:1.104605793952942\n",
      "epoch:2,batch:58 loss:1.0600745677947998\n",
      "epoch:2,batch:59 loss:1.0913245677947998\n",
      "epoch:2,batch:60 loss:1.1022621393203735\n",
      "epoch:2,batch:61 loss:1.1155433654785156\n",
      "epoch:2,batch:62 loss:1.1186683177947998\n",
      "epoch:2,batch:63 loss:1.1155433654785156\n",
      "epoch:2,batch:64 loss:1.094449520111084\n",
      "epoch:2,batch:65 loss:1.0991371870040894\n",
      "epoch:2,batch:66 loss:1.0897622108459473\n",
      "epoch:2,batch:67 loss:1.0991370677947998\n",
      "epoch:2,batch:68 loss:1.0717934370040894\n",
      "epoch:2,batch:69 loss:1.092887043952942\n",
      "epoch:2,batch:70 loss:1.0928871631622314\n",
      "epoch:2,batch:71 loss:1.1053870916366577\n",
      "epoch:2,batch:72 loss:1.0835120677947998\n",
      "epoch:2,batch:73 loss:1.1014808416366577\n",
      "epoch:2,batch:74 loss:1.0897620916366577\n",
      "epoch:2,batch:75 loss:1.1030433177947998\n",
      "epoch:2,batch:76 loss:1.0881996154785156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:24<06:22,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2,batch:77 loss:1.1108556985855103\n",
      "epoch:2, train_loss:1.1108556985855103\n",
      "epoch:3,batch:0 loss:1.0991370677947998\n",
      "epoch:3,batch:1 loss:1.085074543952942\n",
      "epoch:3,batch:2 loss:1.0921058654785156\n",
      "epoch:3,batch:3 loss:1.0842933654785156\n",
      "epoch:3,batch:4 loss:1.1131995916366577\n",
      "epoch:3,batch:5 loss:1.1124184131622314\n",
      "epoch:3,batch:6 loss:1.1014808416366577\n",
      "epoch:3,batch:7 loss:1.0944496393203735\n",
      "epoch:3,batch:8 loss:1.1014808416366577\n",
      "epoch:3,batch:9 loss:1.096011996269226\n",
      "epoch:3,batch:10 loss:1.133512020111084\n",
      "epoch:3,batch:11 loss:1.0936683416366577\n",
      "epoch:3,batch:12 loss:1.096793293952942\n",
      "epoch:3,batch:13 loss:1.1108558177947998\n",
      "epoch:3,batch:14 loss:1.0975745916366577\n",
      "epoch:3,batch:15 loss:1.078824520111084\n",
      "epoch:3,batch:16 loss:1.0991370677947998\n",
      "epoch:3,batch:17 loss:1.0960121154785156\n",
      "epoch:3,batch:18 loss:1.1014808416366577\n",
      "epoch:3,batch:19 loss:1.0944496393203735\n",
      "epoch:3,batch:20 loss:1.1030433177947998\n",
      "epoch:3,batch:21 loss:1.0960121154785156\n",
      "epoch:3,batch:22 loss:1.0835120677947998\n",
      "epoch:3,batch:23 loss:1.0983558893203735\n",
      "epoch:3,batch:24 loss:1.1046059131622314\n",
      "epoch:3,batch:25 loss:1.0881996154785156\n",
      "epoch:3,batch:26 loss:1.0717933177947998\n",
      "epoch:3,batch:27 loss:1.1124184131622314\n",
      "epoch:3,batch:28 loss:1.137418270111084\n",
      "epoch:3,batch:29 loss:1.0921058654785156\n",
      "epoch:3,batch:30 loss:1.0952308177947998\n",
      "epoch:3,batch:31 loss:1.0897622108459473\n",
      "epoch:3,batch:32 loss:1.1178871393203735\n",
      "epoch:3,batch:33 loss:1.0756995677947998\n",
      "epoch:3,batch:34 loss:1.1171058416366577\n",
      "epoch:3,batch:35 loss:1.0967934131622314\n",
      "epoch:3,batch:36 loss:1.0796058177947998\n",
      "epoch:3,batch:37 loss:1.0960121154785156\n",
      "epoch:3,batch:38 loss:1.100699543952942\n",
      "epoch:3,batch:39 loss:1.0936683416366577\n",
      "epoch:3,batch:40 loss:1.0967934131622314\n",
      "epoch:3,batch:41 loss:1.1210120916366577\n",
      "epoch:3,batch:42 loss:1.0928871631622314\n",
      "epoch:3,batch:43 loss:1.0960121154785156\n",
      "epoch:3,batch:44 loss:1.1077308654785156\n",
      "epoch:3,batch:45 loss:1.1100746393203735\n",
      "epoch:3,batch:46 loss:1.1061683893203735\n",
      "epoch:3,batch:47 loss:1.0913245677947998\n",
      "epoch:3,batch:48 loss:1.1053872108459473\n",
      "epoch:3,batch:49 loss:1.0827308893203735\n",
      "epoch:3,batch:50 loss:1.0874183177947998\n",
      "epoch:3,batch:51 loss:1.1264808177947998\n",
      "epoch:3,batch:52 loss:1.090543270111084\n",
      "epoch:3,batch:53 loss:1.0796058177947998\n",
      "epoch:3,batch:54 loss:1.120230793952942\n",
      "epoch:3,batch:55 loss:1.092887043952942\n",
      "epoch:3,batch:56 loss:1.096793293952942\n",
      "epoch:3,batch:57 loss:1.088980793952942\n",
      "epoch:3,batch:58 loss:1.1092932224273682\n",
      "epoch:3,batch:59 loss:1.102262020111084\n",
      "epoch:3,batch:60 loss:1.117887020111084\n",
      "epoch:3,batch:61 loss:1.1077308654785156\n",
      "epoch:3,batch:62 loss:1.1014808416366577\n",
      "epoch:3,batch:63 loss:1.1163246631622314\n",
      "epoch:3,batch:64 loss:1.1155433654785156\n",
      "epoch:3,batch:65 loss:1.0999183654785156\n",
      "epoch:3,batch:66 loss:1.081168293952942\n",
      "epoch:3,batch:67 loss:1.110074520111084\n",
      "epoch:3,batch:68 loss:1.0921058654785156\n",
      "epoch:3,batch:69 loss:1.110074520111084\n",
      "epoch:3,batch:70 loss:1.0928871631622314\n",
      "epoch:3,batch:71 loss:1.1092933416366577\n",
      "epoch:3,batch:72 loss:1.0999183654785156\n",
      "epoch:3,batch:73 loss:1.1296058893203735\n",
      "epoch:3,batch:74 loss:1.0975747108459473\n",
      "epoch:3,batch:75 loss:1.0967934131622314\n",
      "epoch:3,batch:76 loss:1.1256996393203735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:32<06:19,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3,batch:77 loss:1.090543270111084\n",
      "epoch:3, train_loss:1.090543270111084\n",
      "epoch:4,batch:0 loss:1.1030433177947998\n",
      "epoch:4,batch:1 loss:1.1085121631622314\n",
      "epoch:4,batch:2 loss:1.1053870916366577\n",
      "epoch:4,batch:3 loss:1.106168270111084\n",
      "epoch:4,batch:4 loss:1.086637020111084\n",
      "epoch:4,batch:5 loss:1.1030433177947998\n",
      "epoch:4,batch:6 loss:1.1069495677947998\n",
      "epoch:4,batch:7 loss:1.108512043952942\n",
      "epoch:4,batch:8 loss:1.1006996631622314\n",
      "epoch:4,batch:9 loss:1.0905433893203735\n",
      "epoch:4,batch:10 loss:1.103824496269226\n",
      "epoch:4,batch:11 loss:1.1014809608459473\n",
      "epoch:4,batch:12 loss:1.1046059131622314\n",
      "epoch:4,batch:13 loss:1.1092933416366577\n",
      "epoch:4,batch:14 loss:1.1178871393203735\n",
      "epoch:4,batch:15 loss:1.1061683893203735\n",
      "epoch:4,batch:16 loss:1.088980793952942\n",
      "epoch:4,batch:17 loss:1.1171058416366577\n",
      "epoch:4,batch:18 loss:1.1311683654785156\n",
      "epoch:4,batch:19 loss:1.0928871631622314\n",
      "epoch:4,batch:20 loss:1.0858557224273682\n",
      "epoch:4,batch:21 loss:1.0991371870040894\n",
      "epoch:4,batch:22 loss:1.0936684608459473\n",
      "epoch:4,batch:23 loss:1.1046059131622314\n",
      "epoch:4,batch:24 loss:1.0983558893203735\n",
      "epoch:4,batch:25 loss:1.106168270111084\n",
      "epoch:4,batch:26 loss:1.1092932224273682\n",
      "epoch:4,batch:27 loss:1.0889809131622314\n",
      "epoch:4,batch:28 loss:1.1069495677947998\n",
      "epoch:4,batch:29 loss:1.1147620677947998\n",
      "epoch:4,batch:30 loss:1.1225745677947998\n",
      "epoch:4,batch:31 loss:1.1171058416366577\n",
      "epoch:4,batch:32 loss:1.0702308416366577\n",
      "epoch:4,batch:33 loss:1.0881996154785156\n",
      "epoch:4,batch:34 loss:1.0850746631622314\n",
      "epoch:4,batch:35 loss:1.1178871393203735\n",
      "epoch:4,batch:36 loss:1.104605793952942\n",
      "epoch:4,batch:37 loss:1.0975747108459473\n",
      "epoch:4,batch:38 loss:1.0811684131622314\n",
      "epoch:4,batch:39 loss:1.1085121631622314\n",
      "epoch:4,batch:40 loss:1.0608558654785156\n",
      "epoch:4,batch:41 loss:1.0717933177947998\n",
      "epoch:4,batch:42 loss:1.0866371393203735\n",
      "epoch:4,batch:43 loss:1.1374183893203735\n",
      "epoch:4,batch:44 loss:1.113980770111084\n",
      "epoch:4,batch:45 loss:1.0983558893203735\n",
      "epoch:4,batch:46 loss:1.1171058416366577\n",
      "epoch:4,batch:47 loss:1.104605793952942\n",
      "epoch:4,batch:48 loss:1.1108558177947998\n",
      "epoch:4,batch:49 loss:1.094449520111084\n",
      "epoch:4,batch:50 loss:1.0960121154785156\n",
      "epoch:4,batch:51 loss:1.1131995916366577\n",
      "epoch:4,batch:52 loss:1.1194496154785156\n",
      "epoch:4,batch:53 loss:1.1108558177947998\n",
      "epoch:4,batch:54 loss:1.1030433177947998\n",
      "epoch:4,batch:55 loss:1.104605793952942\n",
      "epoch:4,batch:56 loss:1.1077308654785156\n",
      "epoch:4,batch:57 loss:1.0671058893203735\n",
      "epoch:4,batch:58 loss:1.1131995916366577\n",
      "epoch:4,batch:59 loss:1.0811684131622314\n",
      "epoch:4,batch:60 loss:1.1046059131622314\n",
      "epoch:4,batch:61 loss:1.0819495916366577\n",
      "epoch:4,batch:62 loss:1.0936683416366577\n",
      "epoch:4,batch:63 loss:1.0921058654785156\n",
      "epoch:4,batch:64 loss:1.1139808893203735\n",
      "epoch:4,batch:65 loss:1.113980770111084\n",
      "epoch:4,batch:66 loss:1.0858558416366577\n",
      "epoch:4,batch:67 loss:1.082730770111084\n",
      "epoch:4,batch:68 loss:1.0975745916366577\n",
      "epoch:4,batch:69 loss:1.0960121154785156\n",
      "epoch:4,batch:70 loss:1.1038246154785156\n",
      "epoch:4,batch:71 loss:1.1038246154785156\n",
      "epoch:4,batch:72 loss:1.1131995916366577\n",
      "epoch:4,batch:73 loss:1.0905433893203735\n",
      "epoch:4,batch:74 loss:1.0655434131622314\n",
      "epoch:4,batch:75 loss:1.0733559131622314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:40<06:07,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4,batch:76 loss:1.1225745677947998\n",
      "epoch:4,batch:77 loss:1.0936683416366577\n",
      "epoch:4, train_loss:1.0936683416366577\n",
      "epoch:5,batch:0 loss:1.119449496269226\n",
      "epoch:5,batch:1 loss:1.1053870916366577\n",
      "epoch:5,batch:2 loss:1.0858558416366577\n",
      "epoch:5,batch:3 loss:1.128043293952942\n",
      "epoch:5,batch:4 loss:1.0913245677947998\n",
      "epoch:5,batch:5 loss:1.1108558177947998\n",
      "epoch:5,batch:6 loss:1.081168293952942\n",
      "epoch:5,batch:7 loss:1.0858558416366577\n",
      "epoch:5,batch:8 loss:1.085074543952942\n",
      "epoch:5,batch:9 loss:1.0913245677947998\n",
      "epoch:5,batch:10 loss:1.108512043952942\n",
      "epoch:5,batch:11 loss:1.1092934608459473\n",
      "epoch:5,batch:12 loss:1.1092933416366577\n",
      "epoch:5,batch:13 loss:1.1030433177947998\n",
      "epoch:5,batch:14 loss:1.0889809131622314\n",
      "epoch:5,batch:15 loss:1.0975747108459473\n",
      "epoch:5,batch:16 loss:1.0913245677947998\n",
      "epoch:5,batch:17 loss:1.1139808893203735\n",
      "epoch:5,batch:18 loss:1.102262020111084\n",
      "epoch:5,batch:19 loss:1.1077308654785156\n",
      "epoch:5,batch:20 loss:1.1030433177947998\n",
      "epoch:5,batch:21 loss:1.0796058177947998\n",
      "epoch:5,batch:22 loss:1.1085121631622314\n",
      "epoch:5,batch:23 loss:1.1171058416366577\n",
      "epoch:5,batch:24 loss:1.1092933416366577\n",
      "epoch:5,batch:25 loss:1.0881996154785156\n",
      "epoch:5,batch:26 loss:1.1194496154785156\n",
      "epoch:5,batch:27 loss:1.0905433893203735\n",
      "epoch:5,batch:28 loss:1.1210122108459473\n",
      "epoch:5,batch:29 loss:1.088980793952942\n",
      "epoch:5,batch:30 loss:1.1046059131622314\n",
      "epoch:5,batch:31 loss:1.1171058416366577\n",
      "epoch:5,batch:32 loss:1.092887043952942\n",
      "epoch:5,batch:33 loss:1.1116371154785156\n",
      "epoch:5,batch:34 loss:1.0874183177947998\n",
      "epoch:5,batch:35 loss:1.127261996269226\n",
      "epoch:5,batch:36 loss:1.0936682224273682\n",
      "epoch:5,batch:37 loss:1.1022621393203735\n",
      "epoch:5,batch:38 loss:1.078824520111084\n",
      "epoch:5,batch:39 loss:1.1038246154785156\n",
      "epoch:5,batch:40 loss:1.0921058654785156\n",
      "epoch:5,batch:41 loss:1.1038246154785156\n",
      "epoch:5,batch:42 loss:1.0928871631622314\n",
      "epoch:5,batch:43 loss:1.123355746269226\n",
      "epoch:5,batch:44 loss:1.1131995916366577\n",
      "epoch:5,batch:45 loss:1.0819497108459473\n",
      "epoch:5,batch:46 loss:1.0967934131622314\n",
      "epoch:5,batch:47 loss:1.0756995677947998\n",
      "epoch:5,batch:48 loss:1.1288245916366577\n",
      "epoch:5,batch:49 loss:1.102262020111084\n",
      "epoch:5,batch:50 loss:1.0991370677947998\n",
      "epoch:5,batch:51 loss:1.0850746631622314\n",
      "epoch:5,batch:52 loss:1.1171058416366577\n",
      "epoch:5,batch:53 loss:1.1006996631622314\n",
      "epoch:5,batch:54 loss:1.1124184131622314\n",
      "epoch:5,batch:55 loss:1.1194496154785156\n",
      "epoch:5,batch:56 loss:1.0897620916366577\n",
      "epoch:5,batch:57 loss:1.1038246154785156\n",
      "epoch:5,batch:58 loss:1.0694496631622314\n",
      "epoch:5,batch:59 loss:1.077262043952942\n",
      "epoch:5,batch:60 loss:1.092887043952942\n",
      "epoch:5,batch:61 loss:1.0936683416366577\n",
      "epoch:5,batch:62 loss:1.073355793952942\n",
      "epoch:5,batch:63 loss:1.1092933416366577\n",
      "epoch:5,batch:64 loss:1.0897620916366577\n",
      "epoch:5,batch:65 loss:1.1053869724273682\n",
      "epoch:5,batch:66 loss:1.0889809131622314\n",
      "epoch:5,batch:67 loss:1.106168270111084\n",
      "epoch:5,batch:68 loss:1.115543246269226\n",
      "epoch:5,batch:69 loss:1.1069495677947998\n",
      "epoch:5,batch:70 loss:1.092887043952942\n",
      "epoch:5,batch:71 loss:1.1069495677947998\n",
      "epoch:5,batch:72 loss:1.088980793952942\n",
      "epoch:5,batch:73 loss:1.1233558654785156\n",
      "epoch:5,batch:74 loss:1.0819495916366577\n",
      "epoch:5,batch:75 loss:1.096793293952942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:48<05:56,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5,batch:76 loss:1.1053870916366577\n",
      "epoch:5,batch:77 loss:1.1053870916366577\n",
      "epoch:5, train_loss:1.1053870916366577\n",
      "epoch:6,batch:0 loss:1.0960121154785156\n",
      "epoch:6,batch:1 loss:1.1108558177947998\n",
      "epoch:6,batch:2 loss:1.0952308177947998\n",
      "epoch:6,batch:3 loss:1.113980770111084\n",
      "epoch:6,batch:4 loss:1.120230793952942\n",
      "epoch:6,batch:5 loss:1.0983558893203735\n",
      "epoch:6,batch:6 loss:1.0842933654785156\n",
      "epoch:6,batch:7 loss:1.1014808416366577\n",
      "epoch:6,batch:8 loss:1.106168270111084\n",
      "epoch:6,batch:9 loss:1.0967934131622314\n",
      "epoch:6,batch:10 loss:1.1147620677947998\n",
      "epoch:6,batch:11 loss:1.0991370677947998\n",
      "epoch:6,batch:12 loss:1.1053870916366577\n",
      "epoch:6,batch:13 loss:1.1014808416366577\n",
      "epoch:6,batch:14 loss:1.092887043952942\n",
      "epoch:6,batch:15 loss:1.0905433893203735\n",
      "epoch:6,batch:16 loss:1.0717933177947998\n",
      "epoch:6,batch:17 loss:1.0788246393203735\n",
      "epoch:6,batch:18 loss:1.0928871631622314\n",
      "epoch:6,batch:19 loss:1.1210120916366577\n",
      "epoch:6,batch:20 loss:1.0999183654785156\n",
      "epoch:6,batch:21 loss:1.078824520111084\n",
      "epoch:6,batch:22 loss:1.117887020111084\n",
      "epoch:6,batch:23 loss:1.1053869724273682\n",
      "epoch:6,batch:24 loss:1.108512043952942\n",
      "epoch:6,batch:25 loss:1.096793293952942\n",
      "epoch:6,batch:26 loss:1.1147620677947998\n",
      "epoch:6,batch:27 loss:1.1061683893203735\n",
      "epoch:6,batch:28 loss:1.120230793952942\n",
      "epoch:6,batch:29 loss:1.1061683893203735\n",
      "epoch:6,batch:30 loss:1.0960121154785156\n",
      "epoch:6,batch:31 loss:1.1124184131622314\n",
      "epoch:6,batch:32 loss:1.112418293952942\n",
      "epoch:6,batch:33 loss:1.104605793952942\n",
      "epoch:6,batch:34 loss:1.099918246269226\n",
      "epoch:6,batch:35 loss:1.0874183177947998\n",
      "epoch:6,batch:36 loss:1.0952309370040894\n",
      "epoch:6,batch:37 loss:1.137418270111084\n",
      "epoch:6,batch:38 loss:1.0835120677947998\n",
      "epoch:6,batch:39 loss:1.103824496269226\n",
      "epoch:6,batch:40 loss:1.0936684608459473\n",
      "epoch:6,batch:41 loss:1.1100746393203735\n",
      "epoch:6,batch:42 loss:1.1131995916366577\n",
      "epoch:6,batch:43 loss:1.0960121154785156\n",
      "epoch:6,batch:44 loss:1.0944496393203735\n",
      "epoch:6,batch:45 loss:1.1038246154785156\n",
      "epoch:6,batch:46 loss:1.0881996154785156\n",
      "epoch:6,batch:47 loss:1.1069495677947998\n",
      "epoch:6,batch:48 loss:1.0913245677947998\n",
      "epoch:6,batch:49 loss:1.1053870916366577\n",
      "epoch:6,batch:50 loss:1.1116371154785156\n",
      "epoch:6,batch:51 loss:1.0975745916366577\n",
      "epoch:6,batch:52 loss:1.0960121154785156\n",
      "epoch:6,batch:53 loss:1.0952308177947998\n",
      "epoch:6,batch:54 loss:1.0725746154785156\n",
      "epoch:6,batch:55 loss:1.1046059131622314\n",
      "epoch:6,batch:56 loss:1.1171058416366577\n",
      "epoch:6,batch:57 loss:1.1053870916366577\n",
      "epoch:6,batch:58 loss:1.0897620916366577\n",
      "epoch:6,batch:59 loss:1.1061683893203735\n",
      "epoch:6,batch:60 loss:1.0835120677947998\n",
      "epoch:6,batch:61 loss:1.0975747108459473\n",
      "epoch:6,batch:62 loss:1.104605793952942\n",
      "epoch:6,batch:63 loss:1.107730746269226\n",
      "epoch:6,batch:64 loss:1.096793293952942\n",
      "epoch:6,batch:65 loss:1.096011996269226\n",
      "epoch:6,batch:66 loss:1.1092933416366577\n",
      "epoch:6,batch:67 loss:1.0967934131622314\n",
      "epoch:6,batch:68 loss:1.1171058416366577\n",
      "epoch:6,batch:69 loss:1.1053870916366577\n",
      "epoch:6,batch:70 loss:1.0850746631622314\n",
      "epoch:6,batch:71 loss:1.077262043952942\n",
      "epoch:6,batch:72 loss:1.0967934131622314\n",
      "epoch:6,batch:73 loss:1.0858558416366577\n",
      "epoch:6,batch:74 loss:1.085074543952942\n",
      "epoch:6,batch:75 loss:1.0952308177947998\n",
      "epoch:6,batch:76 loss:1.1014808416366577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:56<05:45,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6,batch:77 loss:1.1069495677947998\n",
      "epoch:6, train_loss:1.1069495677947998\n",
      "epoch:7,batch:0 loss:1.0991370677947998\n",
      "epoch:7,batch:1 loss:1.0897620916366577\n",
      "epoch:7,batch:2 loss:1.1053870916366577\n",
      "epoch:7,batch:3 loss:1.1038247346878052\n",
      "epoch:7,batch:4 loss:1.094449520111084\n",
      "epoch:7,batch:5 loss:1.1077308654785156\n",
      "epoch:7,batch:6 loss:1.1061683893203735\n",
      "epoch:7,batch:7 loss:1.1155433654785156\n",
      "epoch:7,batch:8 loss:1.086637020111084\n",
      "epoch:7,batch:9 loss:1.1053870916366577\n",
      "epoch:7,batch:10 loss:1.0881996154785156\n",
      "epoch:7,batch:11 loss:1.1147621870040894\n",
      "epoch:7,batch:12 loss:1.0983558893203735\n",
      "epoch:7,batch:13 loss:1.088980793952942\n",
      "epoch:7,batch:14 loss:1.0913245677947998\n",
      "epoch:7,batch:15 loss:1.1108558177947998\n",
      "epoch:7,batch:16 loss:1.0991370677947998\n",
      "epoch:7,batch:17 loss:1.0905433893203735\n",
      "epoch:7,batch:18 loss:1.0842933654785156\n",
      "epoch:7,batch:19 loss:1.0710121393203735\n",
      "epoch:7,batch:20 loss:1.1014809608459473\n",
      "epoch:7,batch:21 loss:1.1006996631622314\n",
      "epoch:7,batch:22 loss:1.0991370677947998\n",
      "epoch:7,batch:23 loss:1.1046059131622314\n",
      "epoch:7,batch:24 loss:1.0952308177947998\n",
      "epoch:7,batch:25 loss:1.123355746269226\n",
      "epoch:7,batch:26 loss:1.0858558416366577\n",
      "epoch:7,batch:27 loss:1.106168270111084\n",
      "epoch:7,batch:28 loss:1.1030433177947998\n",
      "epoch:7,batch:29 loss:1.1038246154785156\n",
      "epoch:7,batch:30 loss:1.0936683416366577\n",
      "epoch:7,batch:31 loss:1.1006996631622314\n",
      "epoch:7,batch:32 loss:1.1131995916366577\n",
      "epoch:7,batch:33 loss:1.1194496154785156\n",
      "epoch:7,batch:34 loss:1.0936682224273682\n",
      "epoch:7,batch:35 loss:1.0874183177947998\n",
      "epoch:7,batch:36 loss:1.098355770111084\n",
      "epoch:7,batch:37 loss:1.0921058654785156\n",
      "epoch:7,batch:38 loss:1.1155433654785156\n",
      "epoch:7,batch:39 loss:1.0952308177947998\n",
      "epoch:7,batch:40 loss:1.1194496154785156\n",
      "epoch:7,batch:41 loss:1.108512043952942\n",
      "epoch:7,batch:42 loss:1.0858558416366577\n",
      "epoch:7,batch:43 loss:1.1030434370040894\n",
      "epoch:7,batch:44 loss:1.0835120677947998\n",
      "epoch:7,batch:45 loss:1.0991371870040894\n",
      "epoch:7,batch:46 loss:1.1124184131622314\n",
      "epoch:7,batch:47 loss:1.0936683416366577\n",
      "epoch:7,batch:48 loss:1.0819495916366577\n",
      "epoch:7,batch:49 loss:1.0991370677947998\n",
      "epoch:7,batch:50 loss:1.0913245677947998\n",
      "epoch:7,batch:51 loss:1.1100746393203735\n",
      "epoch:7,batch:52 loss:1.0921058654785156\n",
      "epoch:7,batch:53 loss:1.1131995916366577\n",
      "epoch:7,batch:54 loss:1.1046059131622314\n",
      "epoch:7,batch:55 loss:1.131949543952942\n",
      "epoch:7,batch:56 loss:1.1163246631622314\n",
      "epoch:7,batch:57 loss:1.112418293952942\n",
      "epoch:7,batch:58 loss:1.0944496393203735\n",
      "epoch:7,batch:59 loss:1.1030433177947998\n",
      "epoch:7,batch:60 loss:1.0921058654785156\n",
      "epoch:7,batch:61 loss:1.0999183654785156\n",
      "epoch:7,batch:62 loss:1.1155433654785156\n",
      "epoch:7,batch:63 loss:1.0842933654785156\n",
      "epoch:7,batch:64 loss:1.1171058416366577\n",
      "epoch:7,batch:65 loss:1.1038246154785156\n",
      "epoch:7,batch:66 loss:1.0913245677947998\n",
      "epoch:7,batch:67 loss:1.0756995677947998\n",
      "epoch:7,batch:68 loss:1.0928871631622314\n",
      "epoch:7,batch:69 loss:1.107730746269226\n",
      "epoch:7,batch:70 loss:1.0725746154785156\n",
      "epoch:7,batch:71 loss:1.0874183177947998\n",
      "epoch:7,batch:72 loss:1.094449520111084\n",
      "epoch:7,batch:73 loss:1.1124184131622314\n",
      "epoch:7,batch:74 loss:1.1186683177947998\n",
      "epoch:7,batch:75 loss:1.1061683893203735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [01:04<05:36,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7,batch:76 loss:1.0921058654785156\n",
      "epoch:7,batch:77 loss:1.1249184608459473\n",
      "epoch:7, train_loss:1.1249184608459473\n",
      "epoch:8,batch:0 loss:1.0819497108459473\n",
      "epoch:8,batch:1 loss:1.1006996631622314\n",
      "epoch:8,batch:2 loss:1.0889809131622314\n",
      "epoch:8,batch:3 loss:1.1006996631622314\n",
      "epoch:8,batch:4 loss:1.094449520111084\n",
      "epoch:8,batch:5 loss:1.1256996393203735\n",
      "epoch:8,batch:6 loss:1.100699543952942\n",
      "epoch:8,batch:7 loss:1.108512043952942\n",
      "epoch:8,batch:8 loss:1.1288245916366577\n",
      "epoch:8,batch:9 loss:1.116324543952942\n",
      "epoch:8,batch:10 loss:1.1022621393203735\n",
      "epoch:8,batch:11 loss:1.107730746269226\n",
      "epoch:8,batch:12 loss:1.1085121631622314\n",
      "epoch:8,batch:13 loss:1.0921058654785156\n",
      "epoch:8,batch:14 loss:1.0967934131622314\n",
      "epoch:8,batch:15 loss:1.1092933416366577\n",
      "epoch:8,batch:16 loss:1.0897620916366577\n",
      "epoch:8,batch:17 loss:1.1085121631622314\n",
      "epoch:8,batch:18 loss:1.099918246269226\n",
      "epoch:8,batch:19 loss:1.117887020111084\n",
      "epoch:8,batch:20 loss:1.0944496393203735\n",
      "epoch:8,batch:21 loss:1.0960121154785156\n",
      "epoch:8,batch:22 loss:1.098355770111084\n",
      "epoch:8,batch:23 loss:1.121793270111084\n",
      "epoch:8,batch:24 loss:1.0858558416366577\n",
      "epoch:8,batch:25 loss:1.094449520111084\n",
      "epoch:8,batch:26 loss:1.1053869724273682\n",
      "epoch:8,batch:27 loss:1.1046059131622314\n",
      "epoch:8,batch:28 loss:1.0928871631622314\n",
      "epoch:8,batch:29 loss:1.1139808893203735\n",
      "epoch:8,batch:30 loss:1.1069495677947998\n",
      "epoch:8,batch:31 loss:1.0921058654785156\n",
      "epoch:8,batch:32 loss:1.120230793952942\n",
      "epoch:8,batch:33 loss:1.0975747108459473\n",
      "epoch:8,batch:34 loss:1.0780433416366577\n",
      "epoch:8,batch:35 loss:1.0967934131622314\n",
      "epoch:8,batch:36 loss:1.116324543952942\n",
      "epoch:8,batch:37 loss:1.102262020111084\n",
      "epoch:8,batch:38 loss:1.0928871631622314\n",
      "epoch:8,batch:39 loss:1.0889809131622314\n",
      "epoch:8,batch:40 loss:1.108512043952942\n",
      "epoch:8,batch:41 loss:1.090543270111084\n",
      "epoch:8,batch:42 loss:1.0897620916366577\n",
      "epoch:8,batch:43 loss:1.0936683416366577\n",
      "epoch:8,batch:44 loss:1.0975745916366577\n",
      "epoch:8,batch:45 loss:1.104605793952942\n",
      "epoch:8,batch:46 loss:1.1022621393203735\n",
      "epoch:8,batch:47 loss:1.1077308654785156\n",
      "epoch:8,batch:48 loss:1.1116371154785156\n",
      "epoch:8,batch:49 loss:1.0991370677947998\n",
      "epoch:8,batch:50 loss:1.090543270111084\n",
      "epoch:8,batch:51 loss:1.1210120916366577\n",
      "epoch:8,batch:52 loss:1.0960121154785156\n",
      "epoch:8,batch:53 loss:1.086637020111084\n",
      "epoch:8,batch:54 loss:1.102262020111084\n",
      "epoch:8,batch:55 loss:1.100699543952942\n",
      "epoch:8,batch:56 loss:1.121793270111084\n",
      "epoch:8,batch:57 loss:1.0913245677947998\n",
      "epoch:8,batch:58 loss:1.0850746631622314\n",
      "epoch:8,batch:59 loss:1.1038246154785156\n",
      "epoch:8,batch:60 loss:1.1053870916366577\n",
      "epoch:8,batch:61 loss:1.0999183654785156\n",
      "epoch:8,batch:62 loss:1.108512043952942\n",
      "epoch:8,batch:63 loss:1.0874183177947998\n",
      "epoch:8,batch:64 loss:1.098355770111084\n",
      "epoch:8,batch:65 loss:1.1108558177947998\n",
      "epoch:8,batch:66 loss:1.099918246269226\n",
      "epoch:8,batch:67 loss:1.094449520111084\n",
      "epoch:8,batch:68 loss:1.104605793952942\n",
      "epoch:8,batch:69 loss:1.0936683416366577\n",
      "epoch:8,batch:70 loss:1.0975744724273682\n",
      "epoch:8,batch:71 loss:1.0866371393203735\n",
      "epoch:8,batch:72 loss:1.096793293952942\n",
      "epoch:8,batch:73 loss:1.0874183177947998\n",
      "epoch:8,batch:74 loss:1.0991370677947998\n",
      "epoch:8,batch:75 loss:1.098355770111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [01:12<05:31,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8,batch:76 loss:1.0897620916366577\n",
      "epoch:8,batch:77 loss:1.0913245677947998\n",
      "epoch:8, train_loss:1.0913245677947998\n",
      "epoch:9,batch:0 loss:1.107730746269226\n",
      "epoch:9,batch:1 loss:1.1038246154785156\n",
      "epoch:9,batch:2 loss:1.1264806985855103\n",
      "epoch:9,batch:3 loss:1.1155433654785156\n",
      "epoch:9,batch:4 loss:1.1116371154785156\n",
      "epoch:9,batch:5 loss:1.1124184131622314\n",
      "epoch:9,batch:6 loss:1.1014808416366577\n",
      "epoch:9,batch:7 loss:1.0905433893203735\n",
      "epoch:9,batch:8 loss:1.1350746154785156\n",
      "epoch:9,batch:9 loss:1.1014808416366577\n",
      "epoch:9,batch:10 loss:1.0975744724273682\n",
      "epoch:9,batch:11 loss:1.0928871631622314\n",
      "epoch:9,batch:12 loss:1.1061683893203735\n",
      "epoch:9,batch:13 loss:1.0897620916366577\n",
      "epoch:9,batch:14 loss:1.0897622108459473\n",
      "epoch:9,batch:15 loss:1.112418293952942\n",
      "epoch:9,batch:16 loss:1.0975744724273682\n",
      "epoch:9,batch:17 loss:1.115543246269226\n",
      "epoch:9,batch:18 loss:1.090543270111084\n",
      "epoch:9,batch:19 loss:1.110074520111084\n",
      "epoch:9,batch:20 loss:1.0702308416366577\n",
      "epoch:9,batch:21 loss:1.113980770111084\n",
      "epoch:9,batch:22 loss:1.0999183654785156\n",
      "epoch:9,batch:23 loss:1.1030434370040894\n",
      "epoch:9,batch:24 loss:1.0913245677947998\n",
      "epoch:9,batch:25 loss:1.0780433416366577\n",
      "epoch:9,batch:26 loss:1.0999184846878052\n",
      "epoch:9,batch:27 loss:1.102262020111084\n",
      "epoch:9,batch:28 loss:1.0983558893203735\n",
      "epoch:9,batch:29 loss:1.090543270111084\n",
      "epoch:9,batch:30 loss:1.0889809131622314\n",
      "epoch:9,batch:31 loss:1.1077308654785156\n",
      "epoch:9,batch:32 loss:1.1085121631622314\n",
      "epoch:9,batch:33 loss:1.1077308654785156\n",
      "epoch:9,batch:34 loss:1.1108558177947998\n",
      "epoch:9,batch:35 loss:1.0881996154785156\n",
      "epoch:9,batch:36 loss:1.1046059131622314\n",
      "epoch:9,batch:37 loss:1.1116371154785156\n",
      "epoch:9,batch:38 loss:1.0936683416366577\n",
      "epoch:9,batch:39 loss:1.1108558177947998\n",
      "epoch:9,batch:40 loss:1.088980793952942\n",
      "epoch:9,batch:41 loss:1.0803871154785156\n",
      "epoch:9,batch:42 loss:1.1171058416366577\n",
      "epoch:9,batch:43 loss:1.116324543952942\n",
      "epoch:9,batch:44 loss:1.0975744724273682\n",
      "epoch:9,batch:45 loss:1.0991370677947998\n",
      "epoch:9,batch:46 loss:1.0967934131622314\n",
      "epoch:9,batch:47 loss:1.1171058416366577\n",
      "epoch:9,batch:48 loss:1.1030433177947998\n",
      "epoch:9,batch:49 loss:1.0944496393203735\n",
      "epoch:9,batch:50 loss:1.0678870677947998\n",
      "epoch:9,batch:51 loss:1.0944496393203735\n",
      "epoch:9,batch:52 loss:1.1225745677947998\n",
      "epoch:9,batch:53 loss:1.098355770111084\n",
      "epoch:9,batch:54 loss:1.076480746269226\n",
      "epoch:9,batch:55 loss:1.1077308654785156\n",
      "epoch:9,batch:56 loss:1.1171059608459473\n",
      "epoch:9,batch:57 loss:1.0944496393203735\n",
      "epoch:9,batch:58 loss:1.0874183177947998\n",
      "epoch:9,batch:59 loss:1.0897619724273682\n",
      "epoch:9,batch:60 loss:1.1171058416366577\n",
      "epoch:9,batch:61 loss:1.071012020111084\n",
      "epoch:9,batch:62 loss:1.0835121870040894\n",
      "epoch:9,batch:63 loss:1.0967934131622314\n",
      "epoch:9,batch:64 loss:1.0960121154785156\n",
      "epoch:9,batch:65 loss:1.1280434131622314\n",
      "epoch:9,batch:66 loss:1.0936683416366577\n",
      "epoch:9,batch:67 loss:1.1006996631622314\n",
      "epoch:9,batch:68 loss:1.0913245677947998\n",
      "epoch:9,batch:69 loss:1.1030433177947998\n",
      "epoch:9,batch:70 loss:1.0936683416366577\n",
      "epoch:9,batch:71 loss:1.094449520111084\n",
      "epoch:9,batch:72 loss:1.1108559370040894\n",
      "epoch:9,batch:73 loss:1.0975747108459473\n",
      "epoch:9,batch:74 loss:1.094449520111084\n",
      "epoch:9,batch:75 loss:1.106168270111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [01:20<05:21,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9,batch:76 loss:1.1053870916366577\n",
      "epoch:9,batch:77 loss:1.0889809131622314\n",
      "epoch:9, train_loss:1.0889809131622314\n",
      "epoch:10,batch:0 loss:1.1108556985855103\n",
      "epoch:10,batch:1 loss:1.0881996154785156\n",
      "epoch:10,batch:2 loss:1.0866371393203735\n",
      "epoch:10,batch:3 loss:1.1038246154785156\n",
      "epoch:10,batch:4 loss:1.104605793952942\n",
      "epoch:10,batch:5 loss:1.0741372108459473\n",
      "epoch:10,batch:6 loss:1.0975745916366577\n",
      "epoch:10,batch:7 loss:1.1077308654785156\n",
      "epoch:10,batch:8 loss:1.1077308654785156\n",
      "epoch:10,batch:9 loss:1.100699543952942\n",
      "epoch:10,batch:10 loss:1.1100746393203735\n",
      "epoch:10,batch:11 loss:1.100699543952942\n",
      "epoch:10,batch:12 loss:1.1069495677947998\n",
      "epoch:10,batch:13 loss:1.1022621393203735\n",
      "epoch:10,batch:14 loss:1.1155433654785156\n",
      "epoch:10,batch:15 loss:1.1077308654785156\n",
      "epoch:10,batch:16 loss:1.0983558893203735\n",
      "epoch:10,batch:17 loss:1.112418293952942\n",
      "epoch:10,batch:18 loss:1.1171058416366577\n",
      "epoch:10,batch:19 loss:1.078824520111084\n",
      "epoch:10,batch:20 loss:1.0983558893203735\n",
      "epoch:10,batch:21 loss:1.0936684608459473\n",
      "epoch:10,batch:22 loss:1.116324543952942\n",
      "epoch:10,batch:23 loss:1.099918246269226\n",
      "epoch:10,batch:24 loss:1.0952309370040894\n",
      "epoch:10,batch:25 loss:1.0960121154785156\n",
      "epoch:10,batch:26 loss:1.103824496269226\n",
      "epoch:10,batch:27 loss:1.0991370677947998\n",
      "epoch:10,batch:28 loss:1.0967934131622314\n",
      "epoch:10,batch:29 loss:1.112418293952942\n",
      "epoch:10,batch:30 loss:1.108512043952942\n",
      "epoch:10,batch:31 loss:1.0967934131622314\n",
      "epoch:10,batch:32 loss:1.0819495916366577\n",
      "epoch:10,batch:33 loss:1.0913245677947998\n",
      "epoch:10,batch:34 loss:1.0850746631622314\n",
      "epoch:10,batch:35 loss:1.1147620677947998\n",
      "epoch:10,batch:36 loss:1.1178871393203735\n",
      "epoch:10,batch:37 loss:1.1014809608459473\n",
      "epoch:10,batch:38 loss:1.106168270111084\n",
      "epoch:10,batch:39 loss:1.1108558177947998\n",
      "epoch:10,batch:40 loss:1.1116371154785156\n",
      "epoch:10,batch:41 loss:1.0858558416366577\n",
      "epoch:10,batch:42 loss:1.0928871631622314\n",
      "epoch:10,batch:43 loss:1.094449520111084\n",
      "epoch:10,batch:44 loss:1.0975745916366577\n",
      "epoch:10,batch:45 loss:1.082730770111084\n",
      "epoch:10,batch:46 loss:1.092105746269226\n",
      "epoch:10,batch:47 loss:1.1006996631622314\n",
      "epoch:10,batch:48 loss:1.1147620677947998\n",
      "epoch:10,batch:49 loss:1.1421058177947998\n",
      "epoch:10,batch:50 loss:1.0725746154785156\n",
      "epoch:10,batch:51 loss:1.1092933416366577\n",
      "epoch:10,batch:52 loss:1.1163246631622314\n",
      "epoch:10,batch:53 loss:1.088980793952942\n",
      "epoch:10,batch:54 loss:1.094449520111084\n",
      "epoch:10,batch:55 loss:1.1100746393203735\n",
      "epoch:10,batch:56 loss:1.110074520111084\n",
      "epoch:10,batch:57 loss:1.0999183654785156\n",
      "epoch:10,batch:58 loss:1.1194496154785156\n",
      "epoch:10,batch:59 loss:1.0897620916366577\n",
      "epoch:10,batch:60 loss:1.0960121154785156\n",
      "epoch:10,batch:61 loss:1.0913245677947998\n",
      "epoch:10,batch:62 loss:1.0999183654785156\n",
      "epoch:10,batch:63 loss:1.1038246154785156\n",
      "epoch:10,batch:64 loss:1.106168270111084\n",
      "epoch:10,batch:65 loss:1.1014808416366577\n",
      "epoch:10,batch:66 loss:1.085074543952942\n",
      "epoch:10,batch:67 loss:1.0803871154785156\n",
      "epoch:10,batch:68 loss:1.102262020111084\n",
      "epoch:10,batch:69 loss:1.0999184846878052\n",
      "epoch:10,batch:70 loss:1.0897622108459473\n",
      "epoch:10,batch:71 loss:1.1210120916366577\n",
      "epoch:10,batch:72 loss:1.0858558416366577\n",
      "epoch:10,batch:73 loss:1.1131997108459473\n",
      "epoch:10,batch:74 loss:1.0897622108459473\n",
      "epoch:10,batch:75 loss:1.0999183654785156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [01:28<05:16,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10,batch:76 loss:1.0811684131622314\n",
      "epoch:10,batch:77 loss:1.1006996631622314\n",
      "epoch:10, train_loss:1.1006996631622314\n",
      "epoch:11,batch:0 loss:1.0913245677947998\n",
      "epoch:11,batch:1 loss:1.1163246631622314\n",
      "epoch:11,batch:2 loss:1.0694494247436523\n",
      "epoch:11,batch:3 loss:1.099918246269226\n",
      "epoch:11,batch:4 loss:1.1038246154785156\n",
      "epoch:11,batch:5 loss:1.139762043952942\n",
      "epoch:11,batch:6 loss:1.0913245677947998\n",
      "epoch:11,batch:7 loss:1.1053870916366577\n",
      "epoch:11,batch:8 loss:1.1108558177947998\n",
      "epoch:11,batch:9 loss:1.1046059131622314\n",
      "epoch:11,batch:10 loss:1.0952306985855103\n",
      "epoch:11,batch:11 loss:1.0897620916366577\n",
      "epoch:11,batch:12 loss:1.1108559370040894\n",
      "epoch:11,batch:13 loss:1.1022621393203735\n",
      "epoch:11,batch:14 loss:1.1038246154785156\n",
      "epoch:11,batch:15 loss:1.1069495677947998\n",
      "epoch:11,batch:16 loss:1.1061683893203735\n",
      "epoch:11,batch:17 loss:1.1061683893203735\n",
      "epoch:11,batch:18 loss:1.1030434370040894\n",
      "epoch:11,batch:19 loss:1.0881996154785156\n",
      "epoch:11,batch:20 loss:1.0905433893203735\n",
      "epoch:11,batch:21 loss:1.102262020111084\n",
      "epoch:11,batch:22 loss:1.096011996269226\n",
      "epoch:11,batch:23 loss:1.098355770111084\n",
      "epoch:11,batch:24 loss:1.098356008529663\n",
      "epoch:11,batch:25 loss:1.1139808893203735\n",
      "epoch:11,batch:26 loss:1.1202309131622314\n",
      "epoch:11,batch:27 loss:1.0756995677947998\n",
      "epoch:11,batch:28 loss:1.1217933893203735\n",
      "epoch:11,batch:29 loss:1.092105746269226\n",
      "epoch:11,batch:30 loss:1.1233558654785156\n",
      "epoch:11,batch:31 loss:1.100699543952942\n",
      "epoch:11,batch:32 loss:1.0991370677947998\n",
      "epoch:11,batch:33 loss:1.0999183654785156\n",
      "epoch:11,batch:34 loss:1.1092933416366577\n",
      "epoch:11,batch:35 loss:1.0874183177947998\n",
      "epoch:11,batch:36 loss:1.1108558177947998\n",
      "epoch:11,batch:37 loss:1.0952308177947998\n",
      "epoch:11,batch:38 loss:1.0991370677947998\n",
      "epoch:11,batch:39 loss:1.113980770111084\n",
      "epoch:11,batch:40 loss:1.0858558416366577\n",
      "epoch:11,batch:41 loss:1.0663245916366577\n",
      "epoch:11,batch:42 loss:1.102262020111084\n",
      "epoch:11,batch:43 loss:1.1038246154785156\n",
      "epoch:11,batch:44 loss:1.111636996269226\n",
      "epoch:11,batch:45 loss:1.0866371393203735\n",
      "epoch:11,batch:46 loss:1.1139808893203735\n",
      "epoch:11,batch:47 loss:1.1147620677947998\n",
      "epoch:11,batch:48 loss:1.1014807224273682\n",
      "epoch:11,batch:49 loss:1.0960121154785156\n",
      "epoch:11,batch:50 loss:1.074918270111084\n",
      "epoch:11,batch:51 loss:1.1030433177947998\n",
      "epoch:11,batch:52 loss:1.086637020111084\n",
      "epoch:11,batch:53 loss:1.0889809131622314\n",
      "epoch:11,batch:54 loss:1.1085121631622314\n",
      "epoch:11,batch:55 loss:1.0983558893203735\n",
      "epoch:11,batch:56 loss:1.0842933654785156\n",
      "epoch:11,batch:57 loss:1.1092933416366577\n",
      "epoch:11,batch:58 loss:1.0952308177947998\n",
      "epoch:11,batch:59 loss:1.0913246870040894\n",
      "epoch:11,batch:60 loss:1.0960121154785156\n",
      "epoch:11,batch:61 loss:1.1163246631622314\n",
      "epoch:11,batch:62 loss:1.0897620916366577\n",
      "epoch:11,batch:63 loss:1.1171058416366577\n",
      "epoch:11,batch:64 loss:1.0928871631622314\n",
      "epoch:11,batch:65 loss:1.1030433177947998\n",
      "epoch:11,batch:66 loss:1.0858558416366577\n",
      "epoch:11,batch:67 loss:1.112418293952942\n",
      "epoch:11,batch:68 loss:1.096011996269226\n",
      "epoch:11,batch:69 loss:1.0858558416366577\n",
      "epoch:11,batch:70 loss:1.094449520111084\n",
      "epoch:11,batch:71 loss:1.1249183416366577\n",
      "epoch:11,batch:72 loss:1.1006996631622314\n",
      "epoch:11,batch:73 loss:1.084293246269226\n",
      "epoch:11,batch:74 loss:1.1030433177947998\n",
      "epoch:11,batch:75 loss:1.1131997108459473\n",
      "epoch:11,batch:76 loss:1.1006996631622314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [01:37<05:13,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11,batch:77 loss:1.0999183654785156\n",
      "epoch:11, train_loss:1.0999183654785156\n",
      "epoch:12,batch:0 loss:1.1053872108459473\n",
      "epoch:12,batch:1 loss:1.0991370677947998\n",
      "epoch:12,batch:2 loss:1.1014808416366577\n",
      "epoch:12,batch:3 loss:1.1061683893203735\n",
      "epoch:12,batch:4 loss:1.086637020111084\n",
      "epoch:12,batch:5 loss:1.0991370677947998\n",
      "epoch:12,batch:6 loss:1.0952308177947998\n",
      "epoch:12,batch:7 loss:1.1006996631622314\n",
      "epoch:12,batch:8 loss:1.1061683893203735\n",
      "epoch:12,batch:9 loss:1.1038246154785156\n",
      "epoch:12,batch:10 loss:1.1077308654785156\n",
      "epoch:12,batch:11 loss:1.0913245677947998\n",
      "epoch:12,batch:12 loss:1.0975745916366577\n",
      "epoch:12,batch:13 loss:1.1178871393203735\n",
      "epoch:12,batch:14 loss:1.1053870916366577\n",
      "epoch:12,batch:15 loss:1.0772621631622314\n",
      "epoch:12,batch:16 loss:1.0975747108459473\n",
      "epoch:12,batch:17 loss:1.1014808416366577\n",
      "epoch:12,batch:18 loss:1.0975744724273682\n",
      "epoch:12,batch:19 loss:1.112418293952942\n",
      "epoch:12,batch:20 loss:1.1350746154785156\n",
      "epoch:12,batch:21 loss:1.106168270111084\n",
      "epoch:12,batch:22 loss:1.1139808893203735\n",
      "epoch:12,batch:23 loss:1.0889809131622314\n",
      "epoch:12,batch:24 loss:1.1233558654785156\n",
      "epoch:12,batch:25 loss:1.090543270111084\n",
      "epoch:12,batch:26 loss:1.1131997108459473\n",
      "epoch:12,batch:27 loss:1.0936683416366577\n",
      "epoch:12,batch:28 loss:1.0991370677947998\n",
      "epoch:12,batch:29 loss:1.0889809131622314\n",
      "epoch:12,batch:30 loss:1.0975745916366577\n",
      "epoch:12,batch:31 loss:1.110074520111084\n",
      "epoch:12,batch:32 loss:1.112418293952942\n",
      "epoch:12,batch:33 loss:1.0858558416366577\n",
      "epoch:12,batch:34 loss:1.0991370677947998\n",
      "epoch:12,batch:35 loss:1.1014808416366577\n",
      "epoch:12,batch:36 loss:1.1249183416366577\n",
      "epoch:12,batch:37 loss:1.096011996269226\n",
      "epoch:12,batch:38 loss:1.0952308177947998\n",
      "epoch:12,batch:39 loss:1.0975747108459473\n",
      "epoch:12,batch:40 loss:1.1014808416366577\n",
      "epoch:12,batch:41 loss:1.078824520111084\n",
      "epoch:12,batch:42 loss:1.0991370677947998\n",
      "epoch:12,batch:43 loss:1.081168293952942\n",
      "epoch:12,batch:44 loss:1.1264808177947998\n",
      "epoch:12,batch:45 loss:1.106168270111084\n",
      "epoch:12,batch:46 loss:1.106168270111084\n",
      "epoch:12,batch:47 loss:1.1155433654785156\n",
      "epoch:12,batch:48 loss:1.0889809131622314\n",
      "epoch:12,batch:49 loss:1.088980793952942\n",
      "epoch:12,batch:50 loss:1.0913245677947998\n",
      "epoch:12,batch:51 loss:1.0952308177947998\n",
      "epoch:12,batch:52 loss:1.0928871631622314\n",
      "epoch:12,batch:53 loss:1.1022621393203735\n",
      "epoch:12,batch:54 loss:1.0897619724273682\n",
      "epoch:12,batch:55 loss:1.090543270111084\n",
      "epoch:12,batch:56 loss:1.1171058416366577\n",
      "epoch:12,batch:57 loss:1.0960121154785156\n",
      "epoch:12,batch:58 loss:1.0835120677947998\n",
      "epoch:12,batch:59 loss:1.0991369485855103\n",
      "epoch:12,batch:60 loss:1.1069495677947998\n",
      "epoch:12,batch:61 loss:1.1163246631622314\n",
      "epoch:12,batch:62 loss:1.0928871631622314\n",
      "epoch:12,batch:63 loss:1.096793293952942\n",
      "epoch:12,batch:64 loss:1.1077308654785156\n",
      "epoch:12,batch:65 loss:1.086637258529663\n",
      "epoch:12,batch:66 loss:1.110074520111084\n",
      "epoch:12,batch:67 loss:1.0936683416366577\n",
      "epoch:12,batch:68 loss:1.0913245677947998\n",
      "epoch:12,batch:69 loss:1.0803871154785156\n",
      "epoch:12,batch:70 loss:1.1022621393203735\n",
      "epoch:12,batch:71 loss:1.0811684131622314\n",
      "epoch:12,batch:72 loss:1.1280434131622314\n",
      "epoch:12,batch:73 loss:1.0913245677947998\n",
      "epoch:12,batch:74 loss:1.1046059131622314\n",
      "epoch:12,batch:75 loss:1.1233558654785156\n",
      "epoch:12,batch:76 loss:1.0819495916366577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [01:46<05:14,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12,batch:77 loss:1.0967934131622314\n",
      "epoch:12, train_loss:1.0967934131622314\n",
      "epoch:13,batch:0 loss:1.1030433177947998\n",
      "epoch:13,batch:1 loss:1.1163246631622314\n",
      "epoch:13,batch:2 loss:1.0678870677947998\n",
      "epoch:13,batch:3 loss:1.1069495677947998\n",
      "epoch:13,batch:4 loss:1.110074520111084\n",
      "epoch:13,batch:5 loss:1.1053870916366577\n",
      "epoch:13,batch:6 loss:1.0936684608459473\n",
      "epoch:13,batch:7 loss:1.086637020111084\n",
      "epoch:13,batch:8 loss:1.0897619724273682\n",
      "epoch:13,batch:9 loss:1.1022621393203735\n",
      "epoch:13,batch:10 loss:1.1210120916366577\n",
      "epoch:13,batch:11 loss:1.0975744724273682\n",
      "epoch:13,batch:12 loss:1.125699520111084\n",
      "epoch:13,batch:13 loss:1.0944496393203735\n",
      "epoch:13,batch:14 loss:1.0780432224273682\n",
      "epoch:13,batch:15 loss:1.0913245677947998\n",
      "epoch:13,batch:16 loss:1.0921058654785156\n",
      "epoch:13,batch:17 loss:1.1272621154785156\n",
      "epoch:13,batch:18 loss:1.0835120677947998\n",
      "epoch:13,batch:19 loss:1.1014808416366577\n",
      "epoch:13,batch:20 loss:1.1038246154785156\n",
      "epoch:13,batch:21 loss:1.1147620677947998\n",
      "epoch:13,batch:22 loss:1.082730770111084\n",
      "epoch:13,batch:23 loss:1.096793293952942\n",
      "epoch:13,batch:24 loss:1.0999183654785156\n",
      "epoch:13,batch:25 loss:1.082730770111084\n",
      "epoch:13,batch:26 loss:1.1108559370040894\n",
      "epoch:13,batch:27 loss:1.100699543952942\n",
      "epoch:13,batch:28 loss:1.0780433416366577\n",
      "epoch:13,batch:29 loss:1.100699543952942\n",
      "epoch:13,batch:30 loss:1.117887020111084\n",
      "epoch:13,batch:31 loss:1.0897619724273682\n",
      "epoch:13,batch:32 loss:1.0827308893203735\n",
      "epoch:13,batch:33 loss:1.0960121154785156\n",
      "epoch:13,batch:34 loss:1.0921059846878052\n",
      "epoch:13,batch:35 loss:1.0842933654785156\n",
      "epoch:13,batch:36 loss:1.1116371154785156\n",
      "epoch:13,batch:37 loss:1.0952308177947998\n",
      "epoch:13,batch:38 loss:1.0967934131622314\n",
      "epoch:13,batch:39 loss:1.106168270111084\n",
      "epoch:13,batch:40 loss:1.1085121631622314\n",
      "epoch:13,batch:41 loss:1.0881996154785156\n",
      "epoch:13,batch:42 loss:1.1155433654785156\n",
      "epoch:13,batch:43 loss:1.0936683416366577\n",
      "epoch:13,batch:44 loss:1.1038246154785156\n",
      "epoch:13,batch:45 loss:1.1116371154785156\n",
      "epoch:13,batch:46 loss:1.1147620677947998\n",
      "epoch:13,batch:47 loss:1.103824496269226\n",
      "epoch:13,batch:48 loss:1.102262020111084\n",
      "epoch:13,batch:49 loss:1.1030433177947998\n",
      "epoch:13,batch:50 loss:1.1100746393203735\n",
      "epoch:13,batch:51 loss:1.0796059370040894\n",
      "epoch:13,batch:52 loss:1.1202309131622314\n",
      "epoch:13,batch:53 loss:1.082730770111084\n",
      "epoch:13,batch:54 loss:1.0764808654785156\n",
      "epoch:13,batch:55 loss:1.1171058416366577\n",
      "epoch:13,batch:56 loss:1.0975747108459473\n",
      "epoch:13,batch:57 loss:1.0960121154785156\n",
      "epoch:13,batch:58 loss:1.106168270111084\n",
      "epoch:13,batch:59 loss:1.0999183654785156\n",
      "epoch:13,batch:60 loss:1.0928871631622314\n",
      "epoch:13,batch:61 loss:1.100699543952942\n",
      "epoch:13,batch:62 loss:1.1014808416366577\n",
      "epoch:13,batch:63 loss:1.0928871631622314\n",
      "epoch:13,batch:64 loss:1.1163246631622314\n",
      "epoch:13,batch:65 loss:1.0960121154785156\n",
      "epoch:13,batch:66 loss:1.1014808416366577\n",
      "epoch:13,batch:67 loss:1.121793270111084\n",
      "epoch:13,batch:68 loss:1.1022621393203735\n",
      "epoch:13,batch:69 loss:1.1108558177947998\n",
      "epoch:13,batch:70 loss:1.1124184131622314\n",
      "epoch:13,batch:71 loss:1.1030433177947998\n",
      "epoch:13,batch:72 loss:1.0960122346878052\n",
      "epoch:13,batch:73 loss:1.064761996269226\n",
      "epoch:13,batch:74 loss:1.1272621154785156\n",
      "epoch:13,batch:75 loss:1.1210120916366577\n",
      "epoch:13,batch:76 loss:1.085074543952942\n",
      "epoch:13,batch:77 loss:1.117887020111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [01:54<04:59,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13, train_loss:1.117887020111084\n",
      "epoch:14,batch:0 loss:1.1202309131622314\n",
      "epoch:14,batch:1 loss:1.0905433893203735\n",
      "epoch:14,batch:2 loss:1.0913245677947998\n",
      "epoch:14,batch:3 loss:1.1014807224273682\n",
      "epoch:14,batch:4 loss:1.0921058654785156\n",
      "epoch:14,batch:5 loss:1.0936683416366577\n",
      "epoch:14,batch:6 loss:1.1210120916366577\n",
      "epoch:14,batch:7 loss:1.104605793952942\n",
      "epoch:14,batch:8 loss:1.1202309131622314\n",
      "epoch:14,batch:9 loss:1.0913245677947998\n",
      "epoch:14,batch:10 loss:1.096011996269226\n",
      "epoch:14,batch:11 loss:1.1171059608459473\n",
      "epoch:14,batch:12 loss:1.1022621393203735\n",
      "epoch:14,batch:13 loss:1.1186683177947998\n",
      "epoch:14,batch:14 loss:1.0788246393203735\n",
      "epoch:14,batch:15 loss:1.1186683177947998\n",
      "epoch:14,batch:16 loss:1.108512043952942\n",
      "epoch:14,batch:17 loss:1.0819495916366577\n",
      "epoch:14,batch:18 loss:1.0874183177947998\n",
      "epoch:14,batch:19 loss:1.100699543952942\n",
      "epoch:14,batch:20 loss:1.0999183654785156\n",
      "epoch:14,batch:21 loss:1.1147620677947998\n",
      "epoch:14,batch:22 loss:1.1131995916366577\n",
      "epoch:14,batch:23 loss:1.1006996631622314\n",
      "epoch:14,batch:24 loss:1.0874184370040894\n",
      "epoch:14,batch:25 loss:1.098355770111084\n",
      "epoch:14,batch:26 loss:1.1038246154785156\n",
      "epoch:14,batch:27 loss:1.1092933416366577\n",
      "epoch:14,batch:28 loss:1.073355793952942\n",
      "epoch:14,batch:29 loss:1.1116371154785156\n",
      "epoch:14,batch:30 loss:1.112418293952942\n",
      "epoch:14,batch:31 loss:1.1139808893203735\n",
      "epoch:14,batch:32 loss:1.1155433654785156\n",
      "epoch:14,batch:33 loss:1.082730770111084\n",
      "epoch:14,batch:34 loss:1.0921058654785156\n",
      "epoch:14,batch:35 loss:1.0881996154785156\n",
      "epoch:14,batch:36 loss:1.0921058654785156\n",
      "epoch:14,batch:37 loss:1.092887043952942\n",
      "epoch:14,batch:38 loss:1.1030434370040894\n",
      "epoch:14,batch:39 loss:1.1108558177947998\n",
      "epoch:14,batch:40 loss:1.107730746269226\n",
      "epoch:14,batch:41 loss:1.090543270111084\n",
      "epoch:14,batch:42 loss:1.108512043952942\n",
      "epoch:14,batch:43 loss:1.0796058177947998\n",
      "epoch:14,batch:44 loss:1.1014808416366577\n",
      "epoch:14,batch:45 loss:1.0897620916366577\n",
      "epoch:14,batch:46 loss:1.0975745916366577\n",
      "epoch:14,batch:47 loss:1.106168270111084\n",
      "epoch:14,batch:48 loss:1.1178871393203735\n",
      "epoch:14,batch:49 loss:1.1217933893203735\n",
      "epoch:14,batch:50 loss:1.0764808654785156\n",
      "epoch:14,batch:51 loss:1.1038246154785156\n",
      "epoch:14,batch:52 loss:1.0960121154785156\n",
      "epoch:14,batch:53 loss:1.0921058654785156\n",
      "epoch:14,batch:54 loss:1.0999183654785156\n",
      "epoch:14,batch:55 loss:1.0850746631622314\n",
      "epoch:14,batch:56 loss:1.112418293952942\n",
      "epoch:14,batch:57 loss:1.0874184370040894\n",
      "epoch:14,batch:58 loss:1.1069495677947998\n",
      "epoch:14,batch:59 loss:1.106168270111084\n",
      "epoch:14,batch:60 loss:1.0921058654785156\n",
      "epoch:14,batch:61 loss:1.0936683416366577\n",
      "epoch:14,batch:62 loss:1.1038246154785156\n",
      "epoch:14,batch:63 loss:1.1069495677947998\n",
      "epoch:14,batch:64 loss:1.1038246154785156\n",
      "epoch:14,batch:65 loss:1.1077308654785156\n",
      "epoch:14,batch:66 loss:1.0944496393203735\n",
      "epoch:14,batch:67 loss:1.1046059131622314\n",
      "epoch:14,batch:68 loss:1.113980770111084\n",
      "epoch:14,batch:69 loss:1.0967934131622314\n",
      "epoch:14,batch:70 loss:1.1186684370040894\n",
      "epoch:14,batch:71 loss:1.084293246269226\n",
      "epoch:14,batch:72 loss:1.1014808416366577\n",
      "epoch:14,batch:73 loss:1.0999183654785156\n",
      "epoch:14,batch:74 loss:1.0913245677947998\n",
      "epoch:14,batch:75 loss:1.077262043952942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [02:02<04:50,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14,batch:76 loss:1.088980793952942\n",
      "epoch:14,batch:77 loss:1.1147620677947998\n",
      "epoch:14, train_loss:1.1147620677947998\n",
      "epoch:15,batch:0 loss:1.104605793952942\n",
      "epoch:15,batch:1 loss:1.0858558416366577\n",
      "epoch:15,batch:2 loss:1.0999183654785156\n",
      "epoch:15,batch:3 loss:1.1069495677947998\n",
      "epoch:15,batch:4 loss:1.0874183177947998\n",
      "epoch:15,batch:5 loss:1.0921058654785156\n",
      "epoch:15,batch:6 loss:1.117887020111084\n",
      "epoch:15,batch:7 loss:1.0850746631622314\n",
      "epoch:15,batch:8 loss:1.124137043952942\n",
      "epoch:15,batch:9 loss:1.1131995916366577\n",
      "epoch:15,batch:10 loss:1.110074520111084\n",
      "epoch:15,batch:11 loss:1.1280434131622314\n",
      "epoch:15,batch:12 loss:1.0788246393203735\n",
      "epoch:15,batch:13 loss:1.131949543952942\n",
      "epoch:15,batch:14 loss:1.0717933177947998\n",
      "epoch:15,batch:15 loss:1.0936683416366577\n",
      "epoch:15,batch:16 loss:1.0921058654785156\n",
      "epoch:15,batch:17 loss:1.0538246631622314\n",
      "epoch:15,batch:18 loss:1.1233558654785156\n",
      "epoch:15,batch:19 loss:1.0725746154785156\n",
      "epoch:15,batch:20 loss:1.1038246154785156\n",
      "epoch:15,batch:21 loss:1.104605793952942\n",
      "epoch:15,batch:22 loss:1.102262020111084\n",
      "epoch:15,batch:23 loss:1.0967934131622314\n",
      "epoch:15,batch:24 loss:1.0866371393203735\n",
      "epoch:15,batch:25 loss:1.1077308654785156\n",
      "epoch:15,batch:26 loss:1.0819495916366577\n",
      "epoch:15,batch:27 loss:1.1061683893203735\n",
      "epoch:15,batch:28 loss:1.1077308654785156\n",
      "epoch:15,batch:29 loss:1.1210120916366577\n",
      "epoch:15,batch:30 loss:1.0796059370040894\n",
      "epoch:15,batch:31 loss:1.1210120916366577\n",
      "epoch:15,batch:32 loss:1.1108558177947998\n",
      "epoch:15,batch:33 loss:1.1171057224273682\n",
      "epoch:15,batch:34 loss:1.0803871154785156\n",
      "epoch:15,batch:35 loss:1.1147620677947998\n",
      "epoch:15,batch:36 loss:1.1038246154785156\n",
      "epoch:15,batch:37 loss:1.0960121154785156\n",
      "epoch:15,batch:38 loss:1.0936683416366577\n",
      "epoch:15,batch:39 loss:1.0960121154785156\n",
      "epoch:15,batch:40 loss:1.1124184131622314\n",
      "epoch:15,batch:41 loss:1.086637020111084\n",
      "epoch:15,batch:42 loss:1.1225745677947998\n",
      "epoch:15,batch:43 loss:1.0952308177947998\n",
      "epoch:15,batch:44 loss:1.1139808893203735\n",
      "epoch:15,batch:45 loss:1.0803871154785156\n",
      "epoch:15,batch:46 loss:1.0764808654785156\n",
      "epoch:15,batch:47 loss:1.092887043952942\n",
      "epoch:15,batch:48 loss:1.0858558416366577\n",
      "epoch:15,batch:49 loss:1.0960121154785156\n",
      "epoch:15,batch:50 loss:1.1171058416366577\n",
      "epoch:15,batch:51 loss:1.100699543952942\n",
      "epoch:15,batch:52 loss:1.1006996631622314\n",
      "epoch:15,batch:53 loss:1.1038246154785156\n",
      "epoch:15,batch:54 loss:1.1288247108459473\n",
      "epoch:15,batch:55 loss:1.085074543952942\n",
      "epoch:15,batch:56 loss:1.0991370677947998\n",
      "epoch:15,batch:57 loss:1.0897619724273682\n",
      "epoch:15,batch:58 loss:1.096011996269226\n",
      "epoch:15,batch:59 loss:1.0944496393203735\n",
      "epoch:15,batch:60 loss:1.0866371393203735\n",
      "epoch:15,batch:61 loss:1.1116371154785156\n",
      "epoch:15,batch:62 loss:1.1014809608459473\n",
      "epoch:15,batch:63 loss:1.0827308893203735\n",
      "epoch:15,batch:64 loss:1.1155433654785156\n",
      "epoch:15,batch:65 loss:1.096793293952942\n",
      "epoch:15,batch:66 loss:1.1131995916366577\n",
      "epoch:15,batch:67 loss:1.0858559608459473\n",
      "epoch:15,batch:68 loss:1.1092932224273682\n",
      "epoch:15,batch:69 loss:1.1100746393203735\n",
      "epoch:15,batch:70 loss:1.108512043952942\n",
      "epoch:15,batch:71 loss:1.1155433654785156\n",
      "epoch:15,batch:72 loss:1.0913245677947998\n",
      "epoch:15,batch:73 loss:1.1053870916366577\n",
      "epoch:15,batch:74 loss:1.0975745916366577\n",
      "epoch:15,batch:75 loss:1.1061683893203735\n",
      "epoch:15,batch:76 loss:1.0952308177947998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [02:10<04:38,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15,batch:77 loss:1.1069495677947998\n",
      "epoch:15, train_loss:1.1069495677947998\n",
      "epoch:16,batch:0 loss:1.1296058893203735\n",
      "epoch:16,batch:1 loss:1.096011996269226\n",
      "epoch:16,batch:2 loss:1.094449520111084\n",
      "epoch:16,batch:3 loss:1.121793270111084\n",
      "epoch:16,batch:4 loss:1.0764808654785156\n",
      "epoch:16,batch:5 loss:1.100699543952942\n",
      "epoch:16,batch:6 loss:1.1272621154785156\n",
      "epoch:16,batch:7 loss:1.0952308177947998\n",
      "epoch:16,batch:8 loss:1.0921058654785156\n",
      "epoch:16,batch:9 loss:1.0905433893203735\n",
      "epoch:16,batch:10 loss:1.1178871393203735\n",
      "epoch:16,batch:11 loss:1.0897620916366577\n",
      "epoch:16,batch:12 loss:1.0913245677947998\n",
      "epoch:16,batch:13 loss:1.094449520111084\n",
      "epoch:16,batch:14 loss:1.0819495916366577\n",
      "epoch:16,batch:15 loss:1.124137043952942\n",
      "epoch:16,batch:16 loss:1.088199496269226\n",
      "epoch:16,batch:17 loss:1.094449520111084\n",
      "epoch:16,batch:18 loss:1.090543270111084\n",
      "epoch:16,batch:19 loss:1.077262043952942\n",
      "epoch:16,batch:20 loss:1.1069495677947998\n",
      "epoch:16,batch:21 loss:1.0858558416366577\n",
      "epoch:16,batch:22 loss:1.1077308654785156\n",
      "epoch:16,batch:23 loss:1.0999183654785156\n",
      "epoch:16,batch:24 loss:1.0913245677947998\n",
      "epoch:16,batch:25 loss:1.1014807224273682\n",
      "epoch:16,batch:26 loss:1.0952308177947998\n",
      "epoch:16,batch:27 loss:1.0936683416366577\n",
      "epoch:16,batch:28 loss:1.100699543952942\n",
      "epoch:16,batch:29 loss:1.1046059131622314\n",
      "epoch:16,batch:30 loss:1.0960121154785156\n",
      "epoch:16,batch:31 loss:1.096011996269226\n",
      "epoch:16,batch:32 loss:1.1038246154785156\n",
      "epoch:16,batch:33 loss:1.1038246154785156\n",
      "epoch:16,batch:34 loss:1.0874183177947998\n",
      "epoch:16,batch:35 loss:1.1053870916366577\n",
      "epoch:16,batch:36 loss:1.0952308177947998\n",
      "epoch:16,batch:37 loss:1.0874183177947998\n",
      "epoch:16,batch:38 loss:1.1116371154785156\n",
      "epoch:16,batch:39 loss:1.0850746631622314\n",
      "epoch:16,batch:40 loss:1.1147620677947998\n",
      "epoch:16,batch:41 loss:1.1053870916366577\n",
      "epoch:16,batch:42 loss:1.084293246269226\n",
      "epoch:16,batch:43 loss:1.1014808416366577\n",
      "epoch:16,batch:44 loss:1.0991370677947998\n",
      "epoch:16,batch:45 loss:1.0952308177947998\n",
      "epoch:16,batch:46 loss:1.092105746269226\n",
      "epoch:16,batch:47 loss:1.086637020111084\n",
      "epoch:16,batch:48 loss:1.1108558177947998\n",
      "epoch:16,batch:49 loss:1.0663245916366577\n",
      "epoch:16,batch:50 loss:1.1077308654785156\n",
      "epoch:16,batch:51 loss:1.1147620677947998\n",
      "epoch:16,batch:52 loss:1.1100746393203735\n",
      "epoch:16,batch:53 loss:1.121793270111084\n",
      "epoch:16,batch:54 loss:1.1046059131622314\n",
      "epoch:16,batch:55 loss:1.137418270111084\n",
      "epoch:16,batch:56 loss:1.0897620916366577\n",
      "epoch:16,batch:57 loss:1.099918246269226\n",
      "epoch:16,batch:58 loss:1.110074520111084\n",
      "epoch:16,batch:59 loss:1.1053872108459473\n",
      "epoch:16,batch:60 loss:1.0952308177947998\n",
      "epoch:16,batch:61 loss:1.1147620677947998\n",
      "epoch:16,batch:62 loss:1.0944496393203735\n",
      "epoch:16,batch:63 loss:1.1053872108459473\n",
      "epoch:16,batch:64 loss:1.090543270111084\n",
      "epoch:16,batch:65 loss:1.1046059131622314\n",
      "epoch:16,batch:66 loss:1.1053870916366577\n",
      "epoch:16,batch:67 loss:1.098355770111084\n",
      "epoch:16,batch:68 loss:1.098355770111084\n",
      "epoch:16,batch:69 loss:1.1030433177947998\n",
      "epoch:16,batch:70 loss:1.1108558177947998\n",
      "epoch:16,batch:71 loss:1.1147620677947998\n",
      "epoch:16,batch:72 loss:1.090543270111084\n",
      "epoch:16,batch:73 loss:1.0913245677947998\n",
      "epoch:16,batch:74 loss:1.0796059370040894\n",
      "epoch:16,batch:75 loss:1.1053870916366577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [02:18<04:27,  8.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16,batch:76 loss:1.1210120916366577\n",
      "epoch:16,batch:77 loss:1.1171058416366577\n",
      "epoch:16, train_loss:1.1171058416366577\n",
      "epoch:17,batch:0 loss:1.1280434131622314\n",
      "epoch:17,batch:1 loss:1.0811684131622314\n",
      "epoch:17,batch:2 loss:1.1053870916366577\n",
      "epoch:17,batch:3 loss:1.108512043952942\n",
      "epoch:17,batch:4 loss:1.1155433654785156\n",
      "epoch:17,batch:5 loss:1.1069496870040894\n",
      "epoch:17,batch:6 loss:1.1092933416366577\n",
      "epoch:17,batch:7 loss:1.082730770111084\n",
      "epoch:17,batch:8 loss:1.096011996269226\n",
      "epoch:17,batch:9 loss:1.1030433177947998\n",
      "epoch:17,batch:10 loss:1.0928869247436523\n",
      "epoch:17,batch:11 loss:1.0913245677947998\n",
      "epoch:17,batch:12 loss:1.1092933416366577\n",
      "epoch:17,batch:13 loss:1.0983558893203735\n",
      "epoch:17,batch:14 loss:1.1053870916366577\n",
      "epoch:17,batch:15 loss:1.1022621393203735\n",
      "epoch:17,batch:16 loss:1.0975747108459473\n",
      "epoch:17,batch:17 loss:1.0803871154785156\n",
      "epoch:17,batch:18 loss:1.086637020111084\n",
      "epoch:17,batch:19 loss:1.1249184608459473\n",
      "epoch:17,batch:20 loss:1.1131995916366577\n",
      "epoch:17,batch:21 loss:1.0850746631622314\n",
      "epoch:17,batch:22 loss:1.0881996154785156\n",
      "epoch:17,batch:23 loss:1.0936683416366577\n",
      "epoch:17,batch:24 loss:1.102262020111084\n",
      "epoch:17,batch:25 loss:1.0913245677947998\n",
      "epoch:17,batch:26 loss:1.1147620677947998\n",
      "epoch:17,batch:27 loss:1.080386996269226\n",
      "epoch:17,batch:28 loss:1.1100746393203735\n",
      "epoch:17,batch:29 loss:1.0936683416366577\n",
      "epoch:17,batch:30 loss:1.1092934608459473\n",
      "epoch:17,batch:31 loss:1.0928871631622314\n",
      "epoch:17,batch:32 loss:1.0835121870040894\n",
      "epoch:17,batch:33 loss:1.0842933654785156\n",
      "epoch:17,batch:34 loss:1.0944496393203735\n",
      "epoch:17,batch:35 loss:1.1046059131622314\n",
      "epoch:17,batch:36 loss:1.1022621393203735\n",
      "epoch:17,batch:37 loss:1.1092933416366577\n",
      "epoch:17,batch:38 loss:1.0999183654785156\n",
      "epoch:17,batch:39 loss:1.0960121154785156\n",
      "epoch:17,batch:40 loss:1.1131995916366577\n",
      "epoch:17,batch:41 loss:1.1038246154785156\n",
      "epoch:17,batch:42 loss:1.0960121154785156\n",
      "epoch:17,batch:43 loss:1.0991370677947998\n",
      "epoch:17,batch:44 loss:1.1053870916366577\n",
      "epoch:17,batch:45 loss:1.117887020111084\n",
      "epoch:17,batch:46 loss:1.096011996269226\n",
      "epoch:17,batch:47 loss:1.074918270111084\n",
      "epoch:17,batch:48 loss:1.1124184131622314\n",
      "epoch:17,batch:49 loss:1.0905433893203735\n",
      "epoch:17,batch:50 loss:1.0835120677947998\n",
      "epoch:17,batch:51 loss:1.139762043952942\n",
      "epoch:17,batch:52 loss:1.1217933893203735\n",
      "epoch:17,batch:53 loss:1.0842934846878052\n",
      "epoch:17,batch:54 loss:1.0921058654785156\n",
      "epoch:17,batch:55 loss:1.120230793952942\n",
      "epoch:17,batch:56 loss:1.1014808416366577\n",
      "epoch:17,batch:57 loss:1.108512043952942\n",
      "epoch:17,batch:58 loss:1.086637020111084\n",
      "epoch:17,batch:59 loss:1.1038246154785156\n",
      "epoch:17,batch:60 loss:1.100699543952942\n",
      "epoch:17,batch:61 loss:1.0960121154785156\n",
      "epoch:17,batch:62 loss:1.1108558177947998\n",
      "epoch:17,batch:63 loss:1.106168270111084\n",
      "epoch:17,batch:64 loss:1.0764808654785156\n",
      "epoch:17,batch:65 loss:1.104605793952942\n",
      "epoch:17,batch:66 loss:1.0874183177947998\n",
      "epoch:17,batch:67 loss:1.1124184131622314\n",
      "epoch:17,batch:68 loss:1.0967934131622314\n",
      "epoch:17,batch:69 loss:1.1053870916366577\n",
      "epoch:17,batch:70 loss:1.0881996154785156\n",
      "epoch:17,batch:71 loss:1.0858558416366577\n",
      "epoch:17,batch:72 loss:1.1171057224273682\n",
      "epoch:17,batch:73 loss:1.1116371154785156\n",
      "epoch:17,batch:74 loss:1.1092933416366577\n",
      "epoch:17,batch:75 loss:1.092887043952942\n",
      "epoch:17,batch:76 loss:1.1053870916366577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [02:27<04:24,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17,batch:77 loss:1.096793293952942\n",
      "epoch:17, train_loss:1.096793293952942\n",
      "epoch:18,batch:0 loss:1.0975745916366577\n",
      "epoch:18,batch:1 loss:1.1186683177947998\n",
      "epoch:18,batch:2 loss:1.0796058177947998\n",
      "epoch:18,batch:3 loss:1.098355770111084\n",
      "epoch:18,batch:4 loss:1.0616371631622314\n",
      "epoch:18,batch:5 loss:1.102262020111084\n",
      "epoch:18,batch:6 loss:1.0913245677947998\n",
      "epoch:18,batch:7 loss:1.1053869724273682\n",
      "epoch:18,batch:8 loss:1.1366369724273682\n",
      "epoch:18,batch:9 loss:1.1280431747436523\n",
      "epoch:18,batch:10 loss:1.1030434370040894\n",
      "epoch:18,batch:11 loss:1.1147620677947998\n",
      "epoch:18,batch:12 loss:1.1030433177947998\n",
      "epoch:18,batch:13 loss:1.082730770111084\n",
      "epoch:18,batch:14 loss:1.1092933416366577\n",
      "epoch:18,batch:15 loss:1.0936682224273682\n",
      "epoch:18,batch:16 loss:1.0936683416366577\n",
      "epoch:18,batch:17 loss:1.0952308177947998\n",
      "epoch:18,batch:18 loss:1.088980793952942\n",
      "epoch:18,batch:19 loss:1.1171058416366577\n",
      "epoch:18,batch:20 loss:1.0835120677947998\n",
      "epoch:18,batch:21 loss:1.1053869724273682\n",
      "epoch:18,batch:22 loss:1.1171059608459473\n",
      "epoch:18,batch:23 loss:1.092105746269226\n",
      "epoch:18,batch:24 loss:1.0874183177947998\n",
      "epoch:18,batch:25 loss:1.0936683416366577\n",
      "epoch:18,batch:26 loss:1.1006996631622314\n",
      "epoch:18,batch:27 loss:1.108512043952942\n",
      "epoch:18,batch:28 loss:1.1210120916366577\n",
      "epoch:18,batch:29 loss:1.1061683893203735\n",
      "epoch:18,batch:30 loss:1.1038246154785156\n",
      "epoch:18,batch:31 loss:1.0928871631622314\n",
      "epoch:18,batch:32 loss:1.0874183177947998\n",
      "epoch:18,batch:33 loss:1.100699543952942\n",
      "epoch:18,batch:34 loss:1.0999183654785156\n",
      "epoch:18,batch:35 loss:1.085074543952942\n",
      "epoch:18,batch:36 loss:1.103824496269226\n",
      "epoch:18,batch:37 loss:1.094449520111084\n",
      "epoch:18,batch:38 loss:1.0921058654785156\n",
      "epoch:18,batch:39 loss:1.0717933177947998\n",
      "epoch:18,batch:40 loss:1.100699543952942\n",
      "epoch:18,batch:41 loss:1.1202309131622314\n",
      "epoch:18,batch:42 loss:1.115543246269226\n",
      "epoch:18,batch:43 loss:1.0780434608459473\n",
      "epoch:18,batch:44 loss:1.1108558177947998\n",
      "epoch:18,batch:45 loss:1.102262020111084\n",
      "epoch:18,batch:46 loss:1.108512043952942\n",
      "epoch:18,batch:47 loss:1.1124184131622314\n",
      "epoch:18,batch:48 loss:1.1069495677947998\n",
      "epoch:18,batch:49 loss:1.108512043952942\n",
      "epoch:18,batch:50 loss:1.115543246269226\n",
      "epoch:18,batch:51 loss:1.1217933893203735\n",
      "epoch:18,batch:52 loss:1.0999183654785156\n",
      "epoch:18,batch:53 loss:1.1061683893203735\n",
      "epoch:18,batch:54 loss:1.1116371154785156\n",
      "epoch:18,batch:55 loss:1.1108558177947998\n",
      "epoch:18,batch:56 loss:1.0827308893203735\n",
      "epoch:18,batch:57 loss:1.0874183177947998\n",
      "epoch:18,batch:58 loss:1.0921058654785156\n",
      "epoch:18,batch:59 loss:1.0881996154785156\n",
      "epoch:18,batch:60 loss:1.1186683177947998\n",
      "epoch:18,batch:61 loss:1.1108558177947998\n",
      "epoch:18,batch:62 loss:1.106168270111084\n",
      "epoch:18,batch:63 loss:1.0921058654785156\n",
      "epoch:18,batch:64 loss:1.088980793952942\n",
      "epoch:18,batch:65 loss:1.0913245677947998\n",
      "epoch:18,batch:66 loss:1.102262020111084\n",
      "epoch:18,batch:67 loss:1.0866371393203735\n",
      "epoch:18,batch:68 loss:1.1046059131622314\n",
      "epoch:18,batch:69 loss:1.0913245677947998\n",
      "epoch:18,batch:70 loss:1.0999183654785156\n",
      "epoch:18,batch:71 loss:1.0967934131622314\n",
      "epoch:18,batch:72 loss:1.0733559131622314\n",
      "epoch:18,batch:73 loss:1.0764808654785156\n",
      "epoch:18,batch:74 loss:1.116324543952942\n",
      "epoch:18,batch:75 loss:1.1210119724273682\n",
      "epoch:18,batch:76 loss:1.0991370677947998\n",
      "epoch:18,batch:77 loss:1.1014808416366577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [02:35<04:13,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18, train_loss:1.1014808416366577\n",
      "epoch:19,batch:0 loss:1.0952309370040894\n",
      "epoch:19,batch:1 loss:1.0897620916366577\n",
      "epoch:19,batch:2 loss:1.1030433177947998\n",
      "epoch:19,batch:3 loss:1.112418293952942\n",
      "epoch:19,batch:4 loss:1.1053869724273682\n",
      "epoch:19,batch:5 loss:1.1014809608459473\n",
      "epoch:19,batch:6 loss:1.1241371631622314\n",
      "epoch:19,batch:7 loss:1.0858558416366577\n",
      "epoch:19,batch:8 loss:1.1108559370040894\n",
      "epoch:19,batch:9 loss:1.1108558177947998\n",
      "epoch:19,batch:10 loss:1.096793293952942\n",
      "epoch:19,batch:11 loss:1.0944496393203735\n",
      "epoch:19,batch:12 loss:1.1241371631622314\n",
      "epoch:19,batch:13 loss:1.1069495677947998\n",
      "epoch:19,batch:14 loss:1.0905433893203735\n",
      "epoch:19,batch:15 loss:1.1053870916366577\n",
      "epoch:19,batch:16 loss:1.1217933893203735\n",
      "epoch:19,batch:17 loss:1.0850746631622314\n",
      "epoch:19,batch:18 loss:1.0819495916366577\n",
      "epoch:19,batch:19 loss:1.0686683654785156\n",
      "epoch:19,batch:20 loss:1.0889809131622314\n",
      "epoch:19,batch:21 loss:1.0960121154785156\n",
      "epoch:19,batch:22 loss:1.0780433416366577\n",
      "epoch:19,batch:23 loss:1.1131995916366577\n",
      "epoch:19,batch:24 loss:1.0952308177947998\n",
      "epoch:19,batch:25 loss:1.0991370677947998\n",
      "epoch:19,batch:26 loss:1.1053870916366577\n",
      "epoch:19,batch:27 loss:1.1100746393203735\n",
      "epoch:19,batch:28 loss:1.0936682224273682\n",
      "epoch:19,batch:29 loss:1.0991370677947998\n",
      "epoch:19,batch:30 loss:1.0858558416366577\n",
      "epoch:19,batch:31 loss:1.102262020111084\n",
      "epoch:19,batch:32 loss:1.1210120916366577\n",
      "epoch:19,batch:33 loss:1.0874183177947998\n",
      "epoch:19,batch:34 loss:1.0913245677947998\n",
      "epoch:19,batch:35 loss:1.121793270111084\n",
      "epoch:19,batch:36 loss:1.0897622108459473\n",
      "epoch:19,batch:37 loss:1.099918246269226\n",
      "epoch:19,batch:38 loss:1.1038246154785156\n",
      "epoch:19,batch:39 loss:1.0874183177947998\n",
      "epoch:19,batch:40 loss:1.0936684608459473\n",
      "epoch:19,batch:41 loss:1.1108559370040894\n",
      "epoch:19,batch:42 loss:1.1092932224273682\n",
      "epoch:19,batch:43 loss:1.117887020111084\n",
      "epoch:19,batch:44 loss:1.0710121393203735\n",
      "epoch:19,batch:45 loss:1.0921059846878052\n",
      "epoch:19,batch:46 loss:1.1100746393203735\n",
      "epoch:19,batch:47 loss:1.1053870916366577\n",
      "epoch:19,batch:48 loss:1.1116371154785156\n",
      "epoch:19,batch:49 loss:1.0991370677947998\n",
      "epoch:19,batch:50 loss:1.1046059131622314\n",
      "epoch:19,batch:51 loss:1.0858558416366577\n",
      "epoch:19,batch:52 loss:1.1171057224273682\n",
      "epoch:19,batch:53 loss:1.0967934131622314\n",
      "epoch:19,batch:54 loss:1.1077308654785156\n",
      "epoch:19,batch:55 loss:1.102262020111084\n",
      "epoch:19,batch:56 loss:1.0944496393203735\n",
      "epoch:19,batch:57 loss:1.0842933654785156\n",
      "epoch:19,batch:58 loss:1.1171057224273682\n",
      "epoch:19,batch:59 loss:1.1147620677947998\n",
      "epoch:19,batch:60 loss:1.077262043952942\n",
      "epoch:19,batch:61 loss:1.0967934131622314\n",
      "epoch:19,batch:62 loss:1.0952308177947998\n",
      "epoch:19,batch:63 loss:1.0702308416366577\n",
      "epoch:19,batch:64 loss:1.1108558177947998\n",
      "epoch:19,batch:65 loss:1.108512043952942\n",
      "epoch:19,batch:66 loss:1.1217933893203735\n",
      "epoch:19,batch:67 loss:1.1053870916366577\n",
      "epoch:19,batch:68 loss:1.106168270111084\n",
      "epoch:19,batch:69 loss:1.0952309370040894\n",
      "epoch:19,batch:70 loss:1.0928871631622314\n",
      "epoch:19,batch:71 loss:1.110074520111084\n",
      "epoch:19,batch:72 loss:1.1116371154785156\n",
      "epoch:19,batch:73 loss:1.0944496393203735\n",
      "epoch:19,batch:74 loss:1.1147620677947998\n",
      "epoch:19,batch:75 loss:1.0788246393203735\n",
      "epoch:19,batch:76 loss:1.108512043952942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [02:43<04:05,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19,batch:77 loss:1.1022621393203735\n",
      "epoch:19, train_loss:1.1022621393203735\n",
      "epoch:20,batch:0 loss:1.1249183416366577\n",
      "epoch:20,batch:1 loss:1.0663245916366577\n",
      "epoch:20,batch:2 loss:1.1053870916366577\n",
      "epoch:20,batch:3 loss:1.1053870916366577\n",
      "epoch:20,batch:4 loss:1.112418293952942\n",
      "epoch:20,batch:5 loss:1.0983558893203735\n",
      "epoch:20,batch:6 loss:1.1022621393203735\n",
      "epoch:20,batch:7 loss:1.0975745916366577\n",
      "epoch:20,batch:8 loss:1.1108558177947998\n",
      "epoch:20,batch:9 loss:1.096793293952942\n",
      "epoch:20,batch:10 loss:1.0866371393203735\n",
      "epoch:20,batch:11 loss:1.082730770111084\n",
      "epoch:20,batch:12 loss:1.1030433177947998\n",
      "epoch:20,batch:13 loss:1.0842933654785156\n",
      "epoch:20,batch:14 loss:1.0952308177947998\n",
      "epoch:20,batch:15 loss:1.1124184131622314\n",
      "epoch:20,batch:16 loss:1.0788246393203735\n",
      "epoch:20,batch:17 loss:1.0991370677947998\n",
      "epoch:20,batch:18 loss:1.1092933416366577\n",
      "epoch:20,batch:19 loss:1.1030433177947998\n",
      "epoch:20,batch:20 loss:1.0921059846878052\n",
      "epoch:20,batch:21 loss:1.1014808416366577\n",
      "epoch:20,batch:22 loss:1.1077308654785156\n",
      "epoch:20,batch:23 loss:1.1014808416366577\n",
      "epoch:20,batch:24 loss:1.0850746631622314\n",
      "epoch:20,batch:25 loss:1.0858558416366577\n",
      "epoch:20,batch:26 loss:1.1178871393203735\n",
      "epoch:20,batch:27 loss:1.1233558654785156\n",
      "epoch:20,batch:28 loss:1.1030433177947998\n",
      "epoch:20,batch:29 loss:1.1163246631622314\n",
      "epoch:20,batch:30 loss:1.082730770111084\n",
      "epoch:20,batch:31 loss:1.110074520111084\n",
      "epoch:20,batch:32 loss:1.1069496870040894\n",
      "epoch:20,batch:33 loss:1.0897620916366577\n",
      "epoch:20,batch:34 loss:1.082730770111084\n",
      "epoch:20,batch:35 loss:1.1108558177947998\n",
      "epoch:20,batch:36 loss:1.1342934370040894\n",
      "epoch:20,batch:37 loss:1.0796058177947998\n",
      "epoch:20,batch:38 loss:1.1030433177947998\n",
      "epoch:20,batch:39 loss:1.113980770111084\n",
      "epoch:20,batch:40 loss:1.0905433893203735\n",
      "epoch:20,batch:41 loss:1.1155433654785156\n",
      "epoch:20,batch:42 loss:1.0960121154785156\n",
      "epoch:20,batch:43 loss:1.085074543952942\n",
      "epoch:20,batch:44 loss:1.1061683893203735\n",
      "epoch:20,batch:45 loss:1.1053870916366577\n",
      "epoch:20,batch:46 loss:1.108512043952942\n",
      "epoch:20,batch:47 loss:1.1108558177947998\n",
      "epoch:20,batch:48 loss:1.0960121154785156\n",
      "epoch:20,batch:49 loss:1.0999183654785156\n",
      "epoch:20,batch:50 loss:1.100699543952942\n",
      "epoch:20,batch:51 loss:1.1147621870040894\n",
      "epoch:20,batch:52 loss:1.115543246269226\n",
      "epoch:20,batch:53 loss:1.0936683416366577\n",
      "epoch:20,batch:54 loss:1.0780433416366577\n",
      "epoch:20,batch:55 loss:1.1085121631622314\n",
      "epoch:20,batch:56 loss:1.1171058416366577\n",
      "epoch:20,batch:57 loss:1.102262020111084\n",
      "epoch:20,batch:58 loss:1.0741370916366577\n",
      "epoch:20,batch:59 loss:1.110074520111084\n",
      "epoch:20,batch:60 loss:1.0897620916366577\n",
      "epoch:20,batch:61 loss:1.1030433177947998\n",
      "epoch:20,batch:62 loss:1.1014809608459473\n",
      "epoch:20,batch:63 loss:1.0889809131622314\n",
      "epoch:20,batch:64 loss:1.0999183654785156\n",
      "epoch:20,batch:65 loss:1.0913245677947998\n",
      "epoch:20,batch:66 loss:1.0991371870040894\n",
      "epoch:20,batch:67 loss:1.1053870916366577\n",
      "epoch:20,batch:68 loss:1.0975745916366577\n",
      "epoch:20,batch:69 loss:1.0866371393203735\n",
      "epoch:20,batch:70 loss:1.104605793952942\n",
      "epoch:20,batch:71 loss:1.0756995677947998\n",
      "epoch:20,batch:72 loss:1.1006996631622314\n",
      "epoch:20,batch:73 loss:1.0796058177947998\n",
      "epoch:20,batch:74 loss:1.1131995916366577\n",
      "epoch:20,batch:75 loss:1.0780433416366577\n",
      "epoch:20,batch:76 loss:1.1225745677947998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [02:51<03:56,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20,batch:77 loss:1.145230770111084\n",
      "epoch:20, train_loss:1.145230770111084\n",
      "epoch:21,batch:0 loss:1.0913245677947998\n",
      "epoch:21,batch:1 loss:1.104605793952942\n",
      "epoch:21,batch:2 loss:1.0952308177947998\n",
      "epoch:21,batch:3 loss:1.0819495916366577\n",
      "epoch:21,batch:4 loss:1.1171058416366577\n",
      "epoch:21,batch:5 loss:1.1014808416366577\n",
      "epoch:21,batch:6 loss:1.1194496154785156\n",
      "epoch:21,batch:7 loss:1.0991371870040894\n",
      "epoch:21,batch:8 loss:1.1139808893203735\n",
      "epoch:21,batch:9 loss:1.0881996154785156\n",
      "epoch:21,batch:10 loss:1.0772621631622314\n",
      "epoch:21,batch:11 loss:1.0764808654785156\n",
      "epoch:21,batch:12 loss:1.0944496393203735\n",
      "epoch:21,batch:13 loss:1.0960121154785156\n",
      "epoch:21,batch:14 loss:1.0811684131622314\n",
      "epoch:21,batch:15 loss:1.078824520111084\n",
      "epoch:21,batch:16 loss:1.0835120677947998\n",
      "epoch:21,batch:17 loss:1.1194496154785156\n",
      "epoch:21,batch:18 loss:1.0967934131622314\n",
      "epoch:21,batch:19 loss:1.1147620677947998\n",
      "epoch:21,batch:20 loss:1.0921058654785156\n",
      "epoch:21,batch:21 loss:1.1171058416366577\n",
      "epoch:21,batch:22 loss:1.108512043952942\n",
      "epoch:21,batch:23 loss:1.0952308177947998\n",
      "epoch:21,batch:24 loss:1.1131995916366577\n",
      "epoch:21,batch:25 loss:1.0835120677947998\n",
      "epoch:21,batch:26 loss:1.0616371631622314\n",
      "epoch:21,batch:27 loss:1.1217933893203735\n",
      "epoch:21,batch:28 loss:1.102262020111084\n",
      "epoch:21,batch:29 loss:1.1006996631622314\n",
      "epoch:21,batch:30 loss:1.0960121154785156\n",
      "epoch:21,batch:31 loss:1.0960121154785156\n",
      "epoch:21,batch:32 loss:1.1444495916366577\n",
      "epoch:21,batch:33 loss:1.1186683177947998\n",
      "epoch:21,batch:34 loss:1.1217933893203735\n",
      "epoch:21,batch:35 loss:1.108512043952942\n",
      "epoch:21,batch:36 loss:1.0999183654785156\n",
      "epoch:21,batch:37 loss:1.0702308416366577\n",
      "epoch:21,batch:38 loss:1.0850746631622314\n",
      "epoch:21,batch:39 loss:1.0889809131622314\n",
      "epoch:21,batch:40 loss:1.1085119247436523\n",
      "epoch:21,batch:41 loss:1.1139808893203735\n",
      "epoch:21,batch:42 loss:1.0874184370040894\n",
      "epoch:21,batch:43 loss:1.0858559608459473\n",
      "epoch:21,batch:44 loss:1.1178871393203735\n",
      "epoch:21,batch:45 loss:1.0967934131622314\n",
      "epoch:21,batch:46 loss:1.117887020111084\n",
      "epoch:21,batch:47 loss:1.1155433654785156\n",
      "epoch:21,batch:48 loss:1.0788246393203735\n",
      "epoch:21,batch:49 loss:1.098355770111084\n",
      "epoch:21,batch:50 loss:1.1303871870040894\n",
      "epoch:21,batch:51 loss:1.102262020111084\n",
      "epoch:21,batch:52 loss:1.0811684131622314\n",
      "epoch:21,batch:53 loss:1.121793270111084\n",
      "epoch:21,batch:54 loss:1.0928871631622314\n",
      "epoch:21,batch:55 loss:1.1256996393203735\n",
      "epoch:21,batch:56 loss:1.0967931747436523\n",
      "epoch:21,batch:57 loss:1.1014807224273682\n",
      "epoch:21,batch:58 loss:1.104605793952942\n",
      "epoch:21,batch:59 loss:1.0999183654785156\n",
      "epoch:21,batch:60 loss:1.0819494724273682\n",
      "epoch:21,batch:61 loss:1.0983558893203735\n",
      "epoch:21,batch:62 loss:1.113980770111084\n",
      "epoch:21,batch:63 loss:1.094449520111084\n",
      "epoch:21,batch:64 loss:1.1030434370040894\n",
      "epoch:21,batch:65 loss:1.1139808893203735\n",
      "epoch:21,batch:66 loss:1.0881996154785156\n",
      "epoch:21,batch:67 loss:1.1092933416366577\n",
      "epoch:21,batch:68 loss:1.0881996154785156\n",
      "epoch:21,batch:69 loss:1.1108559370040894\n",
      "epoch:21,batch:70 loss:1.112418293952942\n",
      "epoch:21,batch:71 loss:1.1022621393203735\n",
      "epoch:21,batch:72 loss:1.1108558177947998\n",
      "epoch:21,batch:73 loss:1.1030433177947998\n",
      "epoch:21,batch:74 loss:1.0764808654785156\n",
      "epoch:21,batch:75 loss:1.090543270111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [03:00<03:51,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21,batch:76 loss:1.1139808893203735\n",
      "epoch:21,batch:77 loss:1.0874184370040894\n",
      "epoch:21, train_loss:1.0874184370040894\n",
      "epoch:22,batch:0 loss:1.1280434131622314\n",
      "epoch:22,batch:1 loss:1.094449520111084\n",
      "epoch:22,batch:2 loss:1.1131997108459473\n",
      "epoch:22,batch:3 loss:1.096793293952942\n",
      "epoch:22,batch:4 loss:1.1038246154785156\n",
      "epoch:22,batch:5 loss:1.0858558416366577\n",
      "epoch:22,batch:6 loss:1.0936682224273682\n",
      "epoch:22,batch:7 loss:1.0913245677947998\n",
      "epoch:22,batch:8 loss:1.1038246154785156\n",
      "epoch:22,batch:9 loss:1.110074520111084\n",
      "epoch:22,batch:10 loss:1.0874183177947998\n",
      "epoch:22,batch:11 loss:1.0881996154785156\n",
      "epoch:22,batch:12 loss:1.1163246631622314\n",
      "epoch:22,batch:13 loss:1.096011996269226\n",
      "epoch:22,batch:14 loss:1.1092934608459473\n",
      "epoch:22,batch:15 loss:1.0842933654785156\n",
      "epoch:22,batch:16 loss:1.1171058416366577\n",
      "epoch:22,batch:17 loss:1.1022621393203735\n",
      "epoch:22,batch:18 loss:1.1350746154785156\n",
      "epoch:22,batch:19 loss:1.1077308654785156\n",
      "epoch:22,batch:20 loss:1.107730746269226\n",
      "epoch:22,batch:21 loss:1.088980793952942\n",
      "epoch:22,batch:22 loss:1.081168293952942\n",
      "epoch:22,batch:23 loss:1.1311683654785156\n",
      "epoch:22,batch:24 loss:1.108512043952942\n",
      "epoch:22,batch:25 loss:1.1116371154785156\n",
      "epoch:22,batch:26 loss:1.1061683893203735\n",
      "epoch:22,batch:27 loss:1.092105746269226\n",
      "epoch:22,batch:28 loss:1.0975747108459473\n",
      "epoch:22,batch:29 loss:1.0905433893203735\n",
      "epoch:22,batch:30 loss:1.1202309131622314\n",
      "epoch:22,batch:31 loss:1.0991370677947998\n",
      "epoch:22,batch:32 loss:1.094449520111084\n",
      "epoch:22,batch:33 loss:1.0835120677947998\n",
      "epoch:22,batch:34 loss:1.0796058177947998\n",
      "epoch:22,batch:35 loss:1.0928871631622314\n",
      "epoch:22,batch:36 loss:1.110074520111084\n",
      "epoch:22,batch:37 loss:1.077262043952942\n",
      "epoch:22,batch:38 loss:1.1186683177947998\n",
      "epoch:22,batch:39 loss:1.085074543952942\n",
      "epoch:22,batch:40 loss:1.0881996154785156\n",
      "epoch:22,batch:41 loss:1.113980770111084\n",
      "epoch:22,batch:42 loss:1.0936684608459473\n",
      "epoch:22,batch:43 loss:1.0983558893203735\n",
      "epoch:22,batch:44 loss:1.1069495677947998\n",
      "epoch:22,batch:45 loss:1.1131995916366577\n",
      "epoch:22,batch:46 loss:1.1092933416366577\n",
      "epoch:22,batch:47 loss:1.1186683177947998\n",
      "epoch:22,batch:48 loss:1.086637020111084\n",
      "epoch:22,batch:49 loss:1.1092932224273682\n",
      "epoch:22,batch:50 loss:1.1124184131622314\n",
      "epoch:22,batch:51 loss:1.0788246393203735\n",
      "epoch:22,batch:52 loss:1.0905433893203735\n",
      "epoch:22,batch:53 loss:1.0991370677947998\n",
      "epoch:22,batch:54 loss:1.098355770111084\n",
      "epoch:22,batch:55 loss:1.0967934131622314\n",
      "epoch:22,batch:56 loss:1.0835120677947998\n",
      "epoch:22,batch:57 loss:1.0921058654785156\n",
      "epoch:22,batch:58 loss:1.1014808416366577\n",
      "epoch:22,batch:59 loss:1.1038246154785156\n",
      "epoch:22,batch:60 loss:1.0858558416366577\n",
      "epoch:22,batch:61 loss:1.1342934370040894\n",
      "epoch:22,batch:62 loss:1.1038246154785156\n",
      "epoch:22,batch:63 loss:1.0952308177947998\n",
      "epoch:22,batch:64 loss:1.0842933654785156\n",
      "epoch:22,batch:65 loss:1.1210119724273682\n",
      "epoch:22,batch:66 loss:1.0819495916366577\n",
      "epoch:22,batch:67 loss:1.088980793952942\n",
      "epoch:22,batch:68 loss:1.1014807224273682\n",
      "epoch:22,batch:69 loss:1.1155433654785156\n",
      "epoch:22,batch:70 loss:1.0936683416366577\n",
      "epoch:22,batch:71 loss:1.0913245677947998\n",
      "epoch:22,batch:72 loss:1.1030433177947998\n",
      "epoch:22,batch:73 loss:1.0999183654785156\n",
      "epoch:22,batch:74 loss:1.0717933177947998\n",
      "epoch:22,batch:75 loss:1.1272621154785156\n",
      "epoch:22,batch:76 loss:1.107730746269226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [03:08<03:42,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22,batch:77 loss:1.0858558416366577\n",
      "epoch:22, train_loss:1.0858558416366577\n",
      "epoch:23,batch:0 loss:1.0858558416366577\n",
      "epoch:23,batch:1 loss:1.0756996870040894\n",
      "epoch:23,batch:2 loss:1.1077308654785156\n",
      "epoch:23,batch:3 loss:1.099918246269226\n",
      "epoch:23,batch:4 loss:1.0928871631622314\n",
      "epoch:23,batch:5 loss:1.1108559370040894\n",
      "epoch:23,batch:6 loss:1.1108558177947998\n",
      "epoch:23,batch:7 loss:1.0803871154785156\n",
      "epoch:23,batch:8 loss:1.1288245916366577\n",
      "epoch:23,batch:9 loss:1.1069495677947998\n",
      "epoch:23,batch:10 loss:1.0897620916366577\n",
      "epoch:23,batch:11 loss:1.0936683416366577\n",
      "epoch:23,batch:12 loss:1.1124184131622314\n",
      "epoch:23,batch:13 loss:1.102262258529663\n",
      "epoch:23,batch:14 loss:1.0960121154785156\n",
      "epoch:23,batch:15 loss:1.1014808416366577\n",
      "epoch:23,batch:16 loss:1.1249183416366577\n",
      "epoch:23,batch:17 loss:1.106168270111084\n",
      "epoch:23,batch:18 loss:1.1217933893203735\n",
      "epoch:23,batch:19 loss:1.1038246154785156\n",
      "epoch:23,batch:20 loss:1.1022621393203735\n",
      "epoch:23,batch:21 loss:1.0866371393203735\n",
      "epoch:23,batch:22 loss:1.0819494724273682\n",
      "epoch:23,batch:23 loss:1.0671058893203735\n",
      "epoch:23,batch:24 loss:1.1077308654785156\n",
      "epoch:23,batch:25 loss:1.1053870916366577\n",
      "epoch:23,batch:26 loss:1.1014809608459473\n",
      "epoch:23,batch:27 loss:1.1085121631622314\n",
      "epoch:23,batch:28 loss:1.0874183177947998\n",
      "epoch:23,batch:29 loss:1.1014808416366577\n",
      "epoch:23,batch:30 loss:1.073355793952942\n",
      "epoch:23,batch:31 loss:1.0928871631622314\n",
      "epoch:23,batch:32 loss:1.1014809608459473\n",
      "epoch:23,batch:33 loss:1.0749183893203735\n",
      "epoch:23,batch:34 loss:1.1061683893203735\n",
      "epoch:23,batch:35 loss:1.0967934131622314\n",
      "epoch:23,batch:36 loss:1.1038246154785156\n",
      "epoch:23,batch:37 loss:1.0936683416366577\n",
      "epoch:23,batch:38 loss:1.1030434370040894\n",
      "epoch:23,batch:39 loss:1.104605793952942\n",
      "epoch:23,batch:40 loss:1.1171058416366577\n",
      "epoch:23,batch:41 loss:1.0913245677947998\n",
      "epoch:23,batch:42 loss:1.0944496393203735\n",
      "epoch:23,batch:43 loss:1.0928871631622314\n",
      "epoch:23,batch:44 loss:1.0921058654785156\n",
      "epoch:23,batch:45 loss:1.1108558177947998\n",
      "epoch:23,batch:46 loss:1.1022621393203735\n",
      "epoch:23,batch:47 loss:1.0913245677947998\n",
      "epoch:23,batch:48 loss:1.0921058654785156\n",
      "epoch:23,batch:49 loss:1.112418293952942\n",
      "epoch:23,batch:50 loss:1.1053869724273682\n",
      "epoch:23,batch:51 loss:1.1264808177947998\n",
      "epoch:23,batch:52 loss:1.0819495916366577\n",
      "epoch:23,batch:53 loss:1.1108558177947998\n",
      "epoch:23,batch:54 loss:1.0960121154785156\n",
      "epoch:23,batch:55 loss:1.119449496269226\n",
      "epoch:23,batch:56 loss:1.1022621393203735\n",
      "epoch:23,batch:57 loss:1.1288245916366577\n",
      "epoch:23,batch:58 loss:1.0749183893203735\n",
      "epoch:23,batch:59 loss:1.0835120677947998\n",
      "epoch:23,batch:60 loss:1.100699543952942\n",
      "epoch:23,batch:61 loss:1.094449520111084\n",
      "epoch:23,batch:62 loss:1.082730770111084\n",
      "epoch:23,batch:63 loss:1.0749183893203735\n",
      "epoch:23,batch:64 loss:1.1155433654785156\n",
      "epoch:23,batch:65 loss:1.0952308177947998\n",
      "epoch:23,batch:66 loss:1.1046059131622314\n",
      "epoch:23,batch:67 loss:1.1178871393203735\n",
      "epoch:23,batch:68 loss:1.110074520111084\n",
      "epoch:23,batch:69 loss:1.1249182224273682\n",
      "epoch:23,batch:70 loss:1.1116371154785156\n",
      "epoch:23,batch:71 loss:1.113980770111084\n",
      "epoch:23,batch:72 loss:1.1069495677947998\n",
      "epoch:23,batch:73 loss:1.1014807224273682\n",
      "epoch:23,batch:74 loss:1.1014808416366577\n",
      "epoch:23,batch:75 loss:1.108512043952942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [03:16<03:32,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23,batch:76 loss:1.0788246393203735\n",
      "epoch:23,batch:77 loss:1.1038246154785156\n",
      "epoch:23, train_loss:1.1038246154785156\n",
      "epoch:24,batch:0 loss:1.1272621154785156\n",
      "epoch:24,batch:1 loss:1.106168270111084\n",
      "epoch:24,batch:2 loss:1.0874183177947998\n",
      "epoch:24,batch:3 loss:1.0999183654785156\n",
      "epoch:24,batch:4 loss:1.1108558177947998\n",
      "epoch:24,batch:5 loss:1.0874183177947998\n",
      "epoch:24,batch:6 loss:1.100699543952942\n",
      "epoch:24,batch:7 loss:1.092887043952942\n",
      "epoch:24,batch:8 loss:1.1038246154785156\n",
      "epoch:24,batch:9 loss:1.1256996393203735\n",
      "epoch:24,batch:10 loss:1.1014808416366577\n",
      "epoch:24,batch:11 loss:1.088980793952942\n",
      "epoch:24,batch:12 loss:1.0725746154785156\n",
      "epoch:24,batch:13 loss:1.107730746269226\n",
      "epoch:24,batch:14 loss:1.1030433177947998\n",
      "epoch:24,batch:15 loss:1.0905433893203735\n",
      "epoch:24,batch:16 loss:1.1264806985855103\n",
      "epoch:24,batch:17 loss:1.0983558893203735\n",
      "epoch:24,batch:18 loss:1.1131995916366577\n",
      "epoch:24,batch:19 loss:1.1210120916366577\n",
      "epoch:24,batch:20 loss:1.1014808416366577\n",
      "epoch:24,batch:21 loss:1.1100746393203735\n",
      "epoch:24,batch:22 loss:1.088980793952942\n",
      "epoch:24,batch:23 loss:1.0999183654785156\n",
      "epoch:24,batch:24 loss:1.1069495677947998\n",
      "epoch:24,batch:25 loss:1.104605793952942\n",
      "epoch:24,batch:26 loss:1.1030434370040894\n",
      "epoch:24,batch:27 loss:1.1006996631622314\n",
      "epoch:24,batch:28 loss:1.1178871393203735\n",
      "epoch:24,batch:29 loss:1.0975745916366577\n",
      "epoch:24,batch:30 loss:1.1030433177947998\n",
      "epoch:24,batch:31 loss:1.121793270111084\n",
      "epoch:24,batch:32 loss:1.0999183654785156\n",
      "epoch:24,batch:33 loss:1.0905433893203735\n",
      "epoch:24,batch:34 loss:1.1163246631622314\n",
      "epoch:24,batch:35 loss:1.0952308177947998\n",
      "epoch:24,batch:36 loss:1.1163246631622314\n",
      "epoch:24,batch:37 loss:1.112418293952942\n",
      "epoch:24,batch:38 loss:1.1147620677947998\n",
      "epoch:24,batch:39 loss:1.081168293952942\n",
      "epoch:24,batch:40 loss:1.0788246393203735\n",
      "epoch:24,batch:41 loss:1.081168293952942\n",
      "epoch:24,batch:42 loss:1.1108558177947998\n",
      "epoch:24,batch:43 loss:1.1108558177947998\n",
      "epoch:24,batch:44 loss:1.1030431985855103\n",
      "epoch:24,batch:45 loss:1.1053870916366577\n",
      "epoch:24,batch:46 loss:1.113980770111084\n",
      "epoch:24,batch:47 loss:1.0655434131622314\n",
      "epoch:24,batch:48 loss:1.106168270111084\n",
      "epoch:24,batch:49 loss:1.0835120677947998\n",
      "epoch:24,batch:50 loss:1.1147621870040894\n",
      "epoch:24,batch:51 loss:1.1038246154785156\n",
      "epoch:24,batch:52 loss:1.0975745916366577\n",
      "epoch:24,batch:53 loss:1.0819495916366577\n",
      "epoch:24,batch:54 loss:1.0725746154785156\n",
      "epoch:24,batch:55 loss:1.0678870677947998\n",
      "epoch:24,batch:56 loss:1.0725746154785156\n",
      "epoch:24,batch:57 loss:1.1171059608459473\n",
      "epoch:24,batch:58 loss:1.0952308177947998\n",
      "epoch:24,batch:59 loss:1.1085121631622314\n",
      "epoch:24,batch:60 loss:1.1171058416366577\n",
      "epoch:24,batch:61 loss:1.0999183654785156\n",
      "epoch:24,batch:62 loss:1.0858558416366577\n",
      "epoch:24,batch:63 loss:1.0983558893203735\n",
      "epoch:24,batch:64 loss:1.0952308177947998\n",
      "epoch:24,batch:65 loss:1.0796058177947998\n",
      "epoch:24,batch:66 loss:1.1124184131622314\n",
      "epoch:24,batch:67 loss:1.0913245677947998\n",
      "epoch:24,batch:68 loss:1.1100746393203735\n",
      "epoch:24,batch:69 loss:1.1116371154785156\n",
      "epoch:24,batch:70 loss:1.1116371154785156\n",
      "epoch:24,batch:71 loss:1.1092933416366577\n",
      "epoch:24,batch:72 loss:1.0936682224273682\n",
      "epoch:24,batch:73 loss:1.116324543952942\n",
      "epoch:24,batch:74 loss:1.0842933654785156\n",
      "epoch:24,batch:75 loss:1.0881996154785156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [03:24<03:24,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24,batch:76 loss:1.0960121154785156\n",
      "epoch:24,batch:77 loss:1.088199496269226\n",
      "epoch:24, train_loss:1.088199496269226\n",
      "epoch:25,batch:0 loss:1.0991370677947998\n",
      "epoch:25,batch:1 loss:1.0975745916366577\n",
      "epoch:25,batch:2 loss:1.0678870677947998\n",
      "epoch:25,batch:3 loss:1.1272621154785156\n",
      "epoch:25,batch:4 loss:1.0975745916366577\n",
      "epoch:25,batch:5 loss:1.0936684608459473\n",
      "epoch:25,batch:6 loss:1.1030433177947998\n",
      "epoch:25,batch:7 loss:1.0874183177947998\n",
      "epoch:25,batch:8 loss:1.100699543952942\n",
      "epoch:25,batch:9 loss:1.085074543952942\n",
      "epoch:25,batch:10 loss:1.1163246631622314\n",
      "epoch:25,batch:11 loss:1.1249184608459473\n",
      "epoch:25,batch:12 loss:1.0842933654785156\n",
      "epoch:25,batch:13 loss:1.102262020111084\n",
      "epoch:25,batch:14 loss:1.111636996269226\n",
      "epoch:25,batch:15 loss:1.0952308177947998\n",
      "epoch:25,batch:16 loss:1.0952308177947998\n",
      "epoch:25,batch:17 loss:1.1131995916366577\n",
      "epoch:25,batch:18 loss:1.0991370677947998\n",
      "epoch:25,batch:19 loss:1.1069494485855103\n",
      "epoch:25,batch:20 loss:1.0944496393203735\n",
      "epoch:25,batch:21 loss:1.1155433654785156\n",
      "epoch:25,batch:22 loss:1.0921058654785156\n",
      "epoch:25,batch:23 loss:1.1014807224273682\n",
      "epoch:25,batch:24 loss:1.1053869724273682\n",
      "epoch:25,batch:25 loss:1.099918246269226\n",
      "epoch:25,batch:26 loss:1.0881996154785156\n",
      "epoch:25,batch:27 loss:1.1100746393203735\n",
      "epoch:25,batch:28 loss:1.100699543952942\n",
      "epoch:25,batch:29 loss:1.0905433893203735\n",
      "epoch:25,batch:30 loss:1.1053870916366577\n",
      "epoch:25,batch:31 loss:1.0960121154785156\n",
      "epoch:25,batch:32 loss:1.098355770111084\n",
      "epoch:25,batch:33 loss:1.090543508529663\n",
      "epoch:25,batch:34 loss:1.1092934608459473\n",
      "epoch:25,batch:35 loss:1.0952308177947998\n",
      "epoch:25,batch:36 loss:1.0858557224273682\n",
      "epoch:25,batch:37 loss:1.1124184131622314\n",
      "epoch:25,batch:38 loss:1.0936682224273682\n",
      "epoch:25,batch:39 loss:1.0975745916366577\n",
      "epoch:25,batch:40 loss:1.1014808416366577\n",
      "epoch:25,batch:41 loss:1.1124184131622314\n",
      "epoch:25,batch:42 loss:1.1124184131622314\n",
      "epoch:25,batch:43 loss:1.088980793952942\n",
      "epoch:25,batch:44 loss:1.096793293952942\n",
      "epoch:25,batch:45 loss:1.0983558893203735\n",
      "epoch:25,batch:46 loss:1.0866371393203735\n",
      "epoch:25,batch:47 loss:1.0952308177947998\n",
      "epoch:25,batch:48 loss:1.1194496154785156\n",
      "epoch:25,batch:49 loss:1.106168270111084\n",
      "epoch:25,batch:50 loss:1.0960121154785156\n",
      "epoch:25,batch:51 loss:1.1116371154785156\n",
      "epoch:25,batch:52 loss:1.0874183177947998\n",
      "epoch:25,batch:53 loss:1.124137043952942\n",
      "epoch:25,batch:54 loss:1.0999183654785156\n",
      "epoch:25,batch:55 loss:1.092887043952942\n",
      "epoch:25,batch:56 loss:1.1046059131622314\n",
      "epoch:25,batch:57 loss:1.098355770111084\n",
      "epoch:25,batch:58 loss:1.1030433177947998\n",
      "epoch:25,batch:59 loss:1.085074543952942\n",
      "epoch:25,batch:60 loss:1.1311683654785156\n",
      "epoch:25,batch:61 loss:1.0827308893203735\n",
      "epoch:25,batch:62 loss:1.0897620916366577\n",
      "epoch:25,batch:63 loss:1.1272621154785156\n",
      "epoch:25,batch:64 loss:1.0960121154785156\n",
      "epoch:25,batch:65 loss:1.0921058654785156\n",
      "epoch:25,batch:66 loss:1.1131997108459473\n",
      "epoch:25,batch:67 loss:1.0741370916366577\n",
      "epoch:25,batch:68 loss:1.111636996269226\n",
      "epoch:25,batch:69 loss:1.0936683416366577\n",
      "epoch:25,batch:70 loss:1.0881996154785156\n",
      "epoch:25,batch:71 loss:1.1030434370040894\n",
      "epoch:25,batch:72 loss:1.092105746269226\n",
      "epoch:25,batch:73 loss:1.0913245677947998\n",
      "epoch:25,batch:74 loss:1.1069495677947998\n",
      "epoch:25,batch:75 loss:1.0999183654785156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [03:32<03:15,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25,batch:76 loss:1.098355770111084\n",
      "epoch:25,batch:77 loss:1.1186683177947998\n",
      "epoch:25, train_loss:1.1186683177947998\n",
      "epoch:26,batch:0 loss:1.1046059131622314\n",
      "epoch:26,batch:1 loss:1.113980770111084\n",
      "epoch:26,batch:2 loss:1.098355770111084\n",
      "epoch:26,batch:3 loss:1.0952309370040894\n",
      "epoch:26,batch:4 loss:1.1210120916366577\n",
      "epoch:26,batch:5 loss:1.0983558893203735\n",
      "epoch:26,batch:6 loss:1.100699543952942\n",
      "epoch:26,batch:7 loss:1.1092934608459473\n",
      "epoch:26,batch:8 loss:1.0928871631622314\n",
      "epoch:26,batch:9 loss:1.1241371631622314\n",
      "epoch:26,batch:10 loss:1.1147620677947998\n",
      "epoch:26,batch:11 loss:1.0936683416366577\n",
      "epoch:26,batch:12 loss:1.0999183654785156\n",
      "epoch:26,batch:13 loss:1.0960121154785156\n",
      "epoch:26,batch:14 loss:1.1092933416366577\n",
      "epoch:26,batch:15 loss:1.1210120916366577\n",
      "epoch:26,batch:16 loss:1.125699520111084\n",
      "epoch:26,batch:17 loss:1.1030433177947998\n",
      "epoch:26,batch:18 loss:1.110074520111084\n",
      "epoch:26,batch:19 loss:1.1038246154785156\n",
      "epoch:26,batch:20 loss:1.1342933177947998\n",
      "epoch:26,batch:21 loss:1.0967934131622314\n",
      "epoch:26,batch:22 loss:1.0835120677947998\n",
      "epoch:26,batch:23 loss:1.106168508529663\n",
      "epoch:26,batch:24 loss:1.0921058654785156\n",
      "epoch:26,batch:25 loss:1.1061683893203735\n",
      "epoch:26,batch:26 loss:1.0999183654785156\n",
      "epoch:26,batch:27 loss:1.1131995916366577\n",
      "epoch:26,batch:28 loss:1.0913245677947998\n",
      "epoch:26,batch:29 loss:1.0936683416366577\n",
      "epoch:26,batch:30 loss:1.0991370677947998\n",
      "epoch:26,batch:31 loss:1.106168270111084\n",
      "epoch:26,batch:32 loss:1.0913245677947998\n",
      "epoch:26,batch:33 loss:1.0881996154785156\n",
      "epoch:26,batch:34 loss:1.0811684131622314\n",
      "epoch:26,batch:35 loss:1.1131997108459473\n",
      "epoch:26,batch:36 loss:1.0881996154785156\n",
      "epoch:26,batch:37 loss:1.0952308177947998\n",
      "epoch:26,batch:38 loss:1.0983558893203735\n",
      "epoch:26,batch:39 loss:1.0991370677947998\n",
      "epoch:26,batch:40 loss:1.0952309370040894\n",
      "epoch:26,batch:41 loss:1.0913245677947998\n",
      "epoch:26,batch:42 loss:1.0913245677947998\n",
      "epoch:26,batch:43 loss:1.078824520111084\n",
      "epoch:26,batch:44 loss:1.1131995916366577\n",
      "epoch:26,batch:45 loss:1.1006996631622314\n",
      "epoch:26,batch:46 loss:1.096793293952942\n",
      "epoch:26,batch:47 loss:1.0663245916366577\n",
      "epoch:26,batch:48 loss:1.1014808416366577\n",
      "epoch:26,batch:49 loss:1.088980793952942\n",
      "epoch:26,batch:50 loss:1.0952309370040894\n",
      "epoch:26,batch:51 loss:1.125699520111084\n",
      "epoch:26,batch:52 loss:1.0749183893203735\n",
      "epoch:26,batch:53 loss:1.0913246870040894\n",
      "epoch:26,batch:54 loss:1.098355770111084\n",
      "epoch:26,batch:55 loss:1.098355770111084\n",
      "epoch:26,batch:56 loss:1.117887020111084\n",
      "epoch:26,batch:57 loss:1.1053870916366577\n",
      "epoch:26,batch:58 loss:1.1100746393203735\n",
      "epoch:26,batch:59 loss:1.1069495677947998\n",
      "epoch:26,batch:60 loss:1.1069495677947998\n",
      "epoch:26,batch:61 loss:1.0991370677947998\n",
      "epoch:26,batch:62 loss:1.1171058416366577\n",
      "epoch:26,batch:63 loss:1.0944496393203735\n",
      "epoch:26,batch:64 loss:1.1092934608459473\n",
      "epoch:26,batch:65 loss:1.103824496269226\n",
      "epoch:26,batch:66 loss:1.113980770111084\n",
      "epoch:26,batch:67 loss:1.1108558177947998\n",
      "epoch:26,batch:68 loss:1.0717933177947998\n",
      "epoch:26,batch:69 loss:1.0975745916366577\n",
      "epoch:26,batch:70 loss:1.0850744247436523\n",
      "epoch:26,batch:71 loss:1.1046059131622314\n",
      "epoch:26,batch:72 loss:1.0913245677947998\n",
      "epoch:26,batch:73 loss:1.0975747108459473\n",
      "epoch:26,batch:74 loss:1.0975745916366577\n",
      "epoch:26,batch:75 loss:1.108512043952942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [03:40<03:07,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26,batch:76 loss:1.0842933654785156\n",
      "epoch:26,batch:77 loss:1.0819495916366577\n",
      "epoch:26, train_loss:1.0819495916366577\n",
      "epoch:27,batch:0 loss:1.0944496393203735\n",
      "epoch:27,batch:1 loss:1.0944496393203735\n",
      "epoch:27,batch:2 loss:1.1061683893203735\n",
      "epoch:27,batch:3 loss:1.1022621393203735\n",
      "epoch:27,batch:4 loss:1.090543270111084\n",
      "epoch:27,batch:5 loss:1.1116371154785156\n",
      "epoch:27,batch:6 loss:1.1061683893203735\n",
      "epoch:27,batch:7 loss:1.085074543952942\n",
      "epoch:27,batch:8 loss:1.0874183177947998\n",
      "epoch:27,batch:9 loss:1.1194496154785156\n",
      "epoch:27,batch:10 loss:1.0624183416366577\n",
      "epoch:27,batch:11 loss:1.0991370677947998\n",
      "epoch:27,batch:12 loss:1.1014808416366577\n",
      "epoch:27,batch:13 loss:1.0952308177947998\n",
      "epoch:27,batch:14 loss:1.1108558177947998\n",
      "epoch:27,batch:15 loss:1.0725746154785156\n",
      "epoch:27,batch:16 loss:1.1014808416366577\n",
      "epoch:27,batch:17 loss:1.102262020111084\n",
      "epoch:27,batch:18 loss:1.1256996393203735\n",
      "epoch:27,batch:19 loss:1.0952308177947998\n",
      "epoch:27,batch:20 loss:1.0835120677947998\n",
      "epoch:27,batch:21 loss:1.108512043952942\n",
      "epoch:27,batch:22 loss:1.108512043952942\n",
      "epoch:27,batch:23 loss:1.0952308177947998\n",
      "epoch:27,batch:24 loss:1.1077308654785156\n",
      "epoch:27,batch:25 loss:1.1194496154785156\n",
      "epoch:27,batch:26 loss:1.0991370677947998\n",
      "epoch:27,batch:27 loss:1.0952308177947998\n",
      "epoch:27,batch:28 loss:1.1053869724273682\n",
      "epoch:27,batch:29 loss:1.1092933416366577\n",
      "epoch:27,batch:30 loss:1.120230793952942\n",
      "epoch:27,batch:31 loss:1.0928871631622314\n",
      "epoch:27,batch:32 loss:1.1069495677947998\n",
      "epoch:27,batch:33 loss:1.104605793952942\n",
      "epoch:27,batch:34 loss:1.1139808893203735\n",
      "epoch:27,batch:35 loss:1.0936683416366577\n",
      "epoch:27,batch:36 loss:1.1053870916366577\n",
      "epoch:27,batch:37 loss:1.116324543952942\n",
      "epoch:27,batch:38 loss:1.1178871393203735\n",
      "epoch:27,batch:39 loss:1.1108558177947998\n",
      "epoch:27,batch:40 loss:1.0991370677947998\n",
      "epoch:27,batch:41 loss:1.1053869724273682\n",
      "epoch:27,batch:42 loss:1.1077308654785156\n",
      "epoch:27,batch:43 loss:1.0913245677947998\n",
      "epoch:27,batch:44 loss:1.1014808416366577\n",
      "epoch:27,batch:45 loss:1.1022621393203735\n",
      "epoch:27,batch:46 loss:1.081168293952942\n",
      "epoch:27,batch:47 loss:1.094449520111084\n",
      "epoch:27,batch:48 loss:1.1155433654785156\n",
      "epoch:27,batch:49 loss:1.1233558654785156\n",
      "epoch:27,batch:50 loss:1.088980793952942\n",
      "epoch:27,batch:51 loss:1.112418293952942\n",
      "epoch:27,batch:52 loss:1.107730746269226\n",
      "epoch:27,batch:53 loss:1.107730746269226\n",
      "epoch:27,batch:54 loss:1.0835120677947998\n",
      "epoch:27,batch:55 loss:1.0967934131622314\n",
      "epoch:27,batch:56 loss:1.084293246269226\n",
      "epoch:27,batch:57 loss:1.112418293952942\n",
      "epoch:27,batch:58 loss:1.085074543952942\n",
      "epoch:27,batch:59 loss:1.0952308177947998\n",
      "epoch:27,batch:60 loss:1.0850746631622314\n",
      "epoch:27,batch:61 loss:1.1178871393203735\n",
      "epoch:27,batch:62 loss:1.1077308654785156\n",
      "epoch:27,batch:63 loss:1.1069495677947998\n",
      "epoch:27,batch:64 loss:1.1038247346878052\n",
      "epoch:27,batch:65 loss:1.0991370677947998\n",
      "epoch:27,batch:66 loss:1.0952308177947998\n",
      "epoch:27,batch:67 loss:1.0921058654785156\n",
      "epoch:27,batch:68 loss:1.057730793952942\n",
      "epoch:27,batch:69 loss:1.1085121631622314\n",
      "epoch:27,batch:70 loss:1.100699543952942\n",
      "epoch:27,batch:71 loss:1.1038246154785156\n",
      "epoch:27,batch:72 loss:1.1092933416366577\n",
      "epoch:27,batch:73 loss:1.0897620916366577\n",
      "epoch:27,batch:74 loss:1.0850746631622314\n",
      "epoch:27,batch:75 loss:1.090543270111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [03:49<03:04,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27,batch:76 loss:1.1186683177947998\n",
      "epoch:27,batch:77 loss:1.0858558416366577\n",
      "epoch:27, train_loss:1.0858558416366577\n",
      "epoch:28,batch:0 loss:1.1163246631622314\n",
      "epoch:28,batch:1 loss:1.1022621393203735\n",
      "epoch:28,batch:2 loss:1.1006996631622314\n",
      "epoch:28,batch:3 loss:1.1303870677947998\n",
      "epoch:28,batch:4 loss:1.1030433177947998\n",
      "epoch:28,batch:5 loss:1.0835120677947998\n",
      "epoch:28,batch:6 loss:1.1046059131622314\n",
      "epoch:28,batch:7 loss:1.0960121154785156\n",
      "epoch:28,batch:8 loss:1.0936683416366577\n",
      "epoch:28,batch:9 loss:1.1069494485855103\n",
      "epoch:28,batch:10 loss:1.1030433177947998\n",
      "epoch:28,batch:11 loss:1.069449543952942\n",
      "epoch:28,batch:12 loss:1.088199496269226\n",
      "epoch:28,batch:13 loss:1.112418293952942\n",
      "epoch:28,batch:14 loss:1.128043293952942\n",
      "epoch:28,batch:15 loss:1.0780433416366577\n",
      "epoch:28,batch:16 loss:1.0936683416366577\n",
      "epoch:28,batch:17 loss:1.0694496631622314\n",
      "epoch:28,batch:18 loss:1.090543270111084\n",
      "epoch:28,batch:19 loss:1.086637020111084\n",
      "epoch:28,batch:20 loss:1.117887020111084\n",
      "epoch:28,batch:21 loss:1.1038246154785156\n",
      "epoch:28,batch:22 loss:1.127261996269226\n",
      "epoch:28,batch:23 loss:1.0866371393203735\n",
      "epoch:28,batch:24 loss:1.1108558177947998\n",
      "epoch:28,batch:25 loss:1.1171058416366577\n",
      "epoch:28,batch:26 loss:1.110074520111084\n",
      "epoch:28,batch:27 loss:1.0913246870040894\n",
      "epoch:28,batch:28 loss:1.1233558654785156\n",
      "epoch:28,batch:29 loss:1.082730770111084\n",
      "epoch:28,batch:30 loss:1.1194496154785156\n",
      "epoch:28,batch:31 loss:1.1038246154785156\n",
      "epoch:28,batch:32 loss:1.1030433177947998\n",
      "epoch:28,batch:33 loss:1.104605793952942\n",
      "epoch:28,batch:34 loss:1.1030433177947998\n",
      "epoch:28,batch:35 loss:1.0819495916366577\n",
      "epoch:28,batch:36 loss:1.0772621631622314\n",
      "epoch:28,batch:37 loss:1.0811684131622314\n",
      "epoch:28,batch:38 loss:1.096011996269226\n",
      "epoch:28,batch:39 loss:1.1022621393203735\n",
      "epoch:28,batch:40 loss:1.0788246393203735\n",
      "epoch:28,batch:41 loss:1.090543270111084\n",
      "epoch:28,batch:42 loss:1.1210120916366577\n",
      "epoch:28,batch:43 loss:1.0624184608459473\n",
      "epoch:28,batch:44 loss:1.1186684370040894\n",
      "epoch:28,batch:45 loss:1.1139808893203735\n",
      "epoch:28,batch:46 loss:1.102262020111084\n",
      "epoch:28,batch:47 loss:1.1108558177947998\n",
      "epoch:28,batch:48 loss:1.0858558416366577\n",
      "epoch:28,batch:49 loss:1.117887020111084\n",
      "epoch:28,batch:50 loss:1.1030433177947998\n",
      "epoch:28,batch:51 loss:1.106168270111084\n",
      "epoch:28,batch:52 loss:1.0835121870040894\n",
      "epoch:28,batch:53 loss:1.0874183177947998\n",
      "epoch:28,batch:54 loss:1.0936684608459473\n",
      "epoch:28,batch:55 loss:1.1217933893203735\n",
      "epoch:28,batch:56 loss:1.106168270111084\n",
      "epoch:28,batch:57 loss:1.100699543952942\n",
      "epoch:28,batch:58 loss:1.1139808893203735\n",
      "epoch:28,batch:59 loss:1.1288245916366577\n",
      "epoch:28,batch:60 loss:1.098355770111084\n",
      "epoch:28,batch:61 loss:1.1303870677947998\n",
      "epoch:28,batch:62 loss:1.092105746269226\n",
      "epoch:28,batch:63 loss:1.1155433654785156\n",
      "epoch:28,batch:64 loss:1.0975747108459473\n",
      "epoch:28,batch:65 loss:1.1006996631622314\n",
      "epoch:28,batch:66 loss:1.0975745916366577\n",
      "epoch:28,batch:67 loss:1.0999183654785156\n",
      "epoch:28,batch:68 loss:1.110074520111084\n",
      "epoch:28,batch:69 loss:1.0991371870040894\n",
      "epoch:28,batch:70 loss:1.088980793952942\n",
      "epoch:28,batch:71 loss:1.0897620916366577\n",
      "epoch:28,batch:72 loss:1.1092933416366577\n",
      "epoch:28,batch:73 loss:1.0858559608459473\n",
      "epoch:28,batch:74 loss:1.0819495916366577\n",
      "epoch:28,batch:75 loss:1.0913245677947998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [03:57<02:55,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28,batch:76 loss:1.106168270111084\n",
      "epoch:28,batch:77 loss:1.1006996631622314\n",
      "epoch:28, train_loss:1.1006996631622314\n",
      "epoch:29,batch:0 loss:1.1085121631622314\n",
      "epoch:29,batch:1 loss:1.096793293952942\n",
      "epoch:29,batch:2 loss:1.0975745916366577\n",
      "epoch:29,batch:3 loss:1.1077308654785156\n",
      "epoch:29,batch:4 loss:1.0858557224273682\n",
      "epoch:29,batch:5 loss:1.0991370677947998\n",
      "epoch:29,batch:6 loss:1.0874183177947998\n",
      "epoch:29,batch:7 loss:1.1100746393203735\n",
      "epoch:29,batch:8 loss:1.113981008529663\n",
      "epoch:29,batch:9 loss:1.1030433177947998\n",
      "epoch:29,batch:10 loss:1.1171058416366577\n",
      "epoch:29,batch:11 loss:1.1038246154785156\n",
      "epoch:29,batch:12 loss:1.1006996631622314\n",
      "epoch:29,batch:13 loss:1.1171058416366577\n",
      "epoch:29,batch:14 loss:1.0936683416366577\n",
      "epoch:29,batch:15 loss:1.0921058654785156\n",
      "epoch:29,batch:16 loss:1.0702308416366577\n",
      "epoch:29,batch:17 loss:1.119449496269226\n",
      "epoch:29,batch:18 loss:1.103824496269226\n",
      "epoch:29,batch:19 loss:1.0866371393203735\n",
      "epoch:29,batch:20 loss:1.081168293952942\n",
      "epoch:29,batch:21 loss:1.1053870916366577\n",
      "epoch:29,batch:22 loss:1.1108558177947998\n",
      "epoch:29,batch:23 loss:1.0983558893203735\n",
      "epoch:29,batch:24 loss:1.094449520111084\n",
      "epoch:29,batch:25 loss:1.1100746393203735\n",
      "epoch:29,batch:26 loss:1.1241371631622314\n",
      "epoch:29,batch:27 loss:1.0967934131622314\n",
      "epoch:29,batch:28 loss:1.1038246154785156\n",
      "epoch:29,batch:29 loss:1.1061683893203735\n",
      "epoch:29,batch:30 loss:1.0874183177947998\n",
      "epoch:29,batch:31 loss:1.1264808177947998\n",
      "epoch:29,batch:32 loss:1.0960121154785156\n",
      "epoch:29,batch:33 loss:1.1061683893203735\n",
      "epoch:29,batch:34 loss:1.0960121154785156\n",
      "epoch:29,batch:35 loss:1.117887020111084\n",
      "epoch:29,batch:36 loss:1.0702309608459473\n",
      "epoch:29,batch:37 loss:1.0975745916366577\n",
      "epoch:29,batch:38 loss:1.1022621393203735\n",
      "epoch:29,batch:39 loss:1.0686683654785156\n",
      "epoch:29,batch:40 loss:1.102262020111084\n",
      "epoch:29,batch:41 loss:1.088980793952942\n",
      "epoch:29,batch:42 loss:1.112418293952942\n",
      "epoch:29,batch:43 loss:1.1006994247436523\n",
      "epoch:29,batch:44 loss:1.1038246154785156\n",
      "epoch:29,batch:45 loss:1.0975747108459473\n",
      "epoch:29,batch:46 loss:1.0897620916366577\n",
      "epoch:29,batch:47 loss:1.106168270111084\n",
      "epoch:29,batch:48 loss:1.1077308654785156\n",
      "epoch:29,batch:49 loss:1.0960121154785156\n",
      "epoch:29,batch:50 loss:1.108512043952942\n",
      "epoch:29,batch:51 loss:1.1131994724273682\n",
      "epoch:29,batch:52 loss:1.1085121631622314\n",
      "epoch:29,batch:53 loss:1.1014809608459473\n",
      "epoch:29,batch:54 loss:1.0936683416366577\n",
      "epoch:29,batch:55 loss:1.1163246631622314\n",
      "epoch:29,batch:56 loss:1.1069495677947998\n",
      "epoch:29,batch:57 loss:1.1030433177947998\n",
      "epoch:29,batch:58 loss:1.082730770111084\n",
      "epoch:29,batch:59 loss:1.0905433893203735\n",
      "epoch:29,batch:60 loss:1.1053872108459473\n",
      "epoch:29,batch:61 loss:1.1022621393203735\n",
      "epoch:29,batch:62 loss:1.1155433654785156\n",
      "epoch:29,batch:63 loss:1.1014808416366577\n",
      "epoch:29,batch:64 loss:1.1194496154785156\n",
      "epoch:29,batch:65 loss:1.117887020111084\n",
      "epoch:29,batch:66 loss:1.088980793952942\n",
      "epoch:29,batch:67 loss:1.0889809131622314\n",
      "epoch:29,batch:68 loss:1.094449520111084\n",
      "epoch:29,batch:69 loss:1.100699543952942\n",
      "epoch:29,batch:70 loss:1.074918270111084\n",
      "epoch:29,batch:71 loss:1.1014808416366577\n",
      "epoch:29,batch:72 loss:1.0975745916366577\n",
      "epoch:29,batch:73 loss:1.074918270111084\n",
      "epoch:29,batch:74 loss:1.0936683416366577\n",
      "epoch:29,batch:75 loss:1.1171058416366577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [04:06<02:46,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29,batch:76 loss:1.0647621154785156\n",
      "epoch:29,batch:77 loss:1.1233558654785156\n",
      "epoch:29, train_loss:1.1233558654785156\n",
      "epoch:30,batch:0 loss:1.0975745916366577\n",
      "epoch:30,batch:1 loss:1.090543270111084\n",
      "epoch:30,batch:2 loss:1.081168293952942\n",
      "epoch:30,batch:3 loss:1.0936683416366577\n",
      "epoch:30,batch:4 loss:1.092887043952942\n",
      "epoch:30,batch:5 loss:1.1194496154785156\n",
      "epoch:30,batch:6 loss:1.088980793952942\n",
      "epoch:30,batch:7 loss:1.0936684608459473\n",
      "epoch:30,batch:8 loss:1.1077308654785156\n",
      "epoch:30,batch:9 loss:1.0874183177947998\n",
      "epoch:30,batch:10 loss:1.102262020111084\n",
      "epoch:30,batch:11 loss:1.0999183654785156\n",
      "epoch:30,batch:12 loss:1.1303870677947998\n",
      "epoch:30,batch:13 loss:1.0999183654785156\n",
      "epoch:30,batch:14 loss:1.0952309370040894\n",
      "epoch:30,batch:15 loss:1.0842933654785156\n",
      "epoch:30,batch:16 loss:1.125699520111084\n",
      "epoch:30,batch:17 loss:1.0960121154785156\n",
      "epoch:30,batch:18 loss:1.113980770111084\n",
      "epoch:30,batch:19 loss:1.0991370677947998\n",
      "epoch:30,batch:20 loss:1.1194496154785156\n",
      "epoch:30,batch:21 loss:1.085074543952942\n",
      "epoch:30,batch:22 loss:1.1022621393203735\n",
      "epoch:30,batch:23 loss:1.1006996631622314\n",
      "epoch:30,batch:24 loss:1.1085121631622314\n",
      "epoch:30,batch:25 loss:1.1186683177947998\n",
      "epoch:30,batch:26 loss:1.1311683654785156\n",
      "epoch:30,batch:27 loss:1.102262020111084\n",
      "epoch:30,batch:28 loss:1.0913245677947998\n",
      "epoch:30,batch:29 loss:1.0928871631622314\n",
      "epoch:30,batch:30 loss:1.106168270111084\n",
      "epoch:30,batch:31 loss:1.120230793952942\n",
      "epoch:30,batch:32 loss:1.1061683893203735\n",
      "epoch:30,batch:33 loss:1.1061683893203735\n",
      "epoch:30,batch:34 loss:1.086637020111084\n",
      "epoch:30,batch:35 loss:1.112418293952942\n",
      "epoch:30,batch:36 loss:1.0975745916366577\n",
      "epoch:30,batch:37 loss:1.0975745916366577\n",
      "epoch:30,batch:38 loss:1.0842933654785156\n",
      "epoch:30,batch:39 loss:1.085074543952942\n",
      "epoch:30,batch:40 loss:1.1288244724273682\n",
      "epoch:30,batch:41 loss:1.0952308177947998\n",
      "epoch:30,batch:42 loss:1.088980793952942\n",
      "epoch:30,batch:43 loss:1.124137043952942\n",
      "epoch:30,batch:44 loss:1.0928871631622314\n",
      "epoch:30,batch:45 loss:1.0960121154785156\n",
      "epoch:30,batch:46 loss:1.0819494724273682\n",
      "epoch:30,batch:47 loss:1.0999183654785156\n",
      "epoch:30,batch:48 loss:1.1022621393203735\n",
      "epoch:30,batch:49 loss:1.1085121631622314\n",
      "epoch:30,batch:50 loss:1.107730746269226\n",
      "epoch:30,batch:51 loss:1.0944496393203735\n",
      "epoch:30,batch:52 loss:1.1131997108459473\n",
      "epoch:30,batch:53 loss:1.1014808416366577\n",
      "epoch:30,batch:54 loss:1.0897620916366577\n",
      "epoch:30,batch:55 loss:1.1186683177947998\n",
      "epoch:30,batch:56 loss:1.1077308654785156\n",
      "epoch:30,batch:57 loss:1.113980770111084\n",
      "epoch:30,batch:58 loss:1.0819495916366577\n",
      "epoch:30,batch:59 loss:1.115543246269226\n",
      "epoch:30,batch:60 loss:1.0960121154785156\n",
      "epoch:30,batch:61 loss:1.0999183654785156\n",
      "epoch:30,batch:62 loss:1.088980793952942\n",
      "epoch:30,batch:63 loss:1.0733559131622314\n",
      "epoch:30,batch:64 loss:1.0803871154785156\n",
      "epoch:30,batch:65 loss:1.1155433654785156\n",
      "epoch:30,batch:66 loss:1.1006996631622314\n",
      "epoch:30,batch:67 loss:1.078824520111084\n",
      "epoch:30,batch:68 loss:1.0913245677947998\n",
      "epoch:30,batch:69 loss:1.1053870916366577\n",
      "epoch:30,batch:70 loss:1.113980770111084\n",
      "epoch:30,batch:71 loss:1.090543270111084\n",
      "epoch:30,batch:72 loss:1.096793293952942\n",
      "epoch:30,batch:73 loss:1.0975745916366577\n",
      "epoch:30,batch:74 loss:1.092887043952942\n",
      "epoch:30,batch:75 loss:1.0952308177947998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [04:14<02:37,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30,batch:76 loss:1.0967934131622314\n",
      "epoch:30,batch:77 loss:1.1006996631622314\n",
      "epoch:30, train_loss:1.1006996631622314\n",
      "epoch:31,batch:0 loss:1.1163246631622314\n",
      "epoch:31,batch:1 loss:1.0991370677947998\n",
      "epoch:31,batch:2 loss:1.098355770111084\n",
      "epoch:31,batch:3 loss:1.072574496269226\n",
      "epoch:31,batch:4 loss:1.104605793952942\n",
      "epoch:31,batch:5 loss:1.1249183416366577\n",
      "epoch:31,batch:6 loss:1.102262020111084\n",
      "epoch:31,batch:7 loss:1.1061683893203735\n",
      "epoch:31,batch:8 loss:1.0936684608459473\n",
      "epoch:31,batch:9 loss:1.0991370677947998\n",
      "epoch:31,batch:10 loss:1.086637020111084\n",
      "epoch:31,batch:11 loss:1.1030434370040894\n",
      "epoch:31,batch:12 loss:1.0913245677947998\n",
      "epoch:31,batch:13 loss:1.0835120677947998\n",
      "epoch:31,batch:14 loss:1.0975745916366577\n",
      "epoch:31,batch:15 loss:1.061637043952942\n",
      "epoch:31,batch:16 loss:1.1022621393203735\n",
      "epoch:31,batch:17 loss:1.1030433177947998\n",
      "epoch:31,batch:18 loss:1.0819495916366577\n",
      "epoch:31,batch:19 loss:1.0858558416366577\n",
      "epoch:31,batch:20 loss:1.124137043952942\n",
      "epoch:31,batch:21 loss:1.1014807224273682\n",
      "epoch:31,batch:22 loss:1.0983558893203735\n",
      "epoch:31,batch:23 loss:1.1030433177947998\n",
      "epoch:31,batch:24 loss:1.0842933654785156\n",
      "epoch:31,batch:25 loss:1.1014808416366577\n",
      "epoch:31,batch:26 loss:1.107730746269226\n",
      "epoch:31,batch:27 loss:1.1046059131622314\n",
      "epoch:31,batch:28 loss:1.0952308177947998\n",
      "epoch:31,batch:29 loss:1.1147621870040894\n",
      "epoch:31,batch:30 loss:1.0913245677947998\n",
      "epoch:31,batch:31 loss:1.1046059131622314\n",
      "epoch:31,batch:32 loss:1.0999183654785156\n",
      "epoch:31,batch:33 loss:1.0928871631622314\n",
      "epoch:31,batch:34 loss:1.0967934131622314\n",
      "epoch:31,batch:35 loss:1.1163246631622314\n",
      "epoch:31,batch:36 loss:1.1186684370040894\n",
      "epoch:31,batch:37 loss:1.1202309131622314\n",
      "epoch:31,batch:38 loss:1.1171058416366577\n",
      "epoch:31,batch:39 loss:1.103824496269226\n",
      "epoch:31,batch:40 loss:1.099918246269226\n",
      "epoch:31,batch:41 loss:1.1077308654785156\n",
      "epoch:31,batch:42 loss:1.0811684131622314\n",
      "epoch:31,batch:43 loss:1.1116371154785156\n",
      "epoch:31,batch:44 loss:1.0936683416366577\n",
      "epoch:31,batch:45 loss:1.0819495916366577\n",
      "epoch:31,batch:46 loss:1.0936683416366577\n",
      "epoch:31,batch:47 loss:1.0803871154785156\n",
      "epoch:31,batch:48 loss:1.0952308177947998\n",
      "epoch:31,batch:49 loss:1.0960121154785156\n",
      "epoch:31,batch:50 loss:1.0967934131622314\n",
      "epoch:31,batch:51 loss:1.1053870916366577\n",
      "epoch:31,batch:52 loss:1.085074543952942\n",
      "epoch:31,batch:53 loss:1.0850746631622314\n",
      "epoch:31,batch:54 loss:1.1171058416366577\n",
      "epoch:31,batch:55 loss:1.1014808416366577\n",
      "epoch:31,batch:56 loss:1.0936683416366577\n",
      "epoch:31,batch:57 loss:1.1053869724273682\n",
      "epoch:31,batch:58 loss:1.1077308654785156\n",
      "epoch:31,batch:59 loss:1.1327308416366577\n",
      "epoch:31,batch:60 loss:1.1053870916366577\n",
      "epoch:31,batch:61 loss:1.0936684608459473\n",
      "epoch:31,batch:62 loss:1.1069495677947998\n",
      "epoch:31,batch:63 loss:1.0819495916366577\n",
      "epoch:31,batch:64 loss:1.1249183416366577\n",
      "epoch:31,batch:65 loss:1.1264809370040894\n",
      "epoch:31,batch:66 loss:1.1131997108459473\n",
      "epoch:31,batch:67 loss:1.0944496393203735\n",
      "epoch:31,batch:68 loss:1.0788246393203735\n",
      "epoch:31,batch:69 loss:1.1038246154785156\n",
      "epoch:31,batch:70 loss:1.112418293952942\n",
      "epoch:31,batch:71 loss:1.092887043952942\n",
      "epoch:31,batch:72 loss:1.0928871631622314\n",
      "epoch:31,batch:73 loss:1.110074520111084\n",
      "epoch:31,batch:74 loss:1.1053870916366577\n",
      "epoch:31,batch:75 loss:1.0944496393203735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [04:22<02:28,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31,batch:76 loss:1.1116371154785156\n",
      "epoch:31,batch:77 loss:1.0952309370040894\n",
      "epoch:31, train_loss:1.0952309370040894\n",
      "epoch:32,batch:0 loss:1.0733559131622314\n",
      "epoch:32,batch:1 loss:1.092887043952942\n",
      "epoch:32,batch:2 loss:1.0897620916366577\n",
      "epoch:32,batch:3 loss:1.1108558177947998\n",
      "epoch:32,batch:4 loss:1.0858558416366577\n",
      "epoch:32,batch:5 loss:1.0991370677947998\n",
      "epoch:32,batch:6 loss:1.1202309131622314\n",
      "epoch:32,batch:7 loss:1.112418293952942\n",
      "epoch:32,batch:8 loss:1.1061683893203735\n",
      "epoch:32,batch:9 loss:1.096793293952942\n",
      "epoch:32,batch:10 loss:1.0866371393203735\n",
      "epoch:32,batch:11 loss:1.0897620916366577\n",
      "epoch:32,batch:12 loss:1.0952308177947998\n",
      "epoch:32,batch:13 loss:1.1038246154785156\n",
      "epoch:32,batch:14 loss:1.1124184131622314\n",
      "epoch:32,batch:15 loss:1.0960121154785156\n",
      "epoch:32,batch:16 loss:1.0999183654785156\n",
      "epoch:32,batch:17 loss:1.0803871154785156\n",
      "epoch:32,batch:18 loss:1.1046059131622314\n",
      "epoch:32,batch:19 loss:1.1053870916366577\n",
      "epoch:32,batch:20 loss:1.1038246154785156\n",
      "epoch:32,batch:21 loss:1.0796058177947998\n",
      "epoch:32,batch:22 loss:1.1053872108459473\n",
      "epoch:32,batch:23 loss:1.0921058654785156\n",
      "epoch:32,batch:24 loss:1.0960122346878052\n",
      "epoch:32,batch:25 loss:1.1139808893203735\n",
      "epoch:32,batch:26 loss:1.0811684131622314\n",
      "epoch:32,batch:27 loss:1.1124184131622314\n",
      "epoch:32,batch:28 loss:1.112418293952942\n",
      "epoch:32,batch:29 loss:1.0850746631622314\n",
      "epoch:32,batch:30 loss:1.0835119485855103\n",
      "epoch:32,batch:31 loss:1.1108558177947998\n",
      "epoch:32,batch:32 loss:1.1092933416366577\n",
      "epoch:32,batch:33 loss:1.0975744724273682\n",
      "epoch:32,batch:34 loss:1.096793293952942\n",
      "epoch:32,batch:35 loss:1.0858558416366577\n",
      "epoch:32,batch:36 loss:1.0999183654785156\n",
      "epoch:32,batch:37 loss:1.1131995916366577\n",
      "epoch:32,batch:38 loss:1.1092933416366577\n",
      "epoch:32,batch:39 loss:1.0913245677947998\n",
      "epoch:32,batch:40 loss:1.0897620916366577\n",
      "epoch:32,batch:41 loss:1.1014808416366577\n",
      "epoch:32,batch:42 loss:1.1225745677947998\n",
      "epoch:32,batch:43 loss:1.100699543952942\n",
      "epoch:32,batch:44 loss:1.1030433177947998\n",
      "epoch:32,batch:45 loss:1.1108558177947998\n",
      "epoch:32,batch:46 loss:1.1155433654785156\n",
      "epoch:32,batch:47 loss:1.099918246269226\n",
      "epoch:32,batch:48 loss:1.1116371154785156\n",
      "epoch:32,batch:49 loss:1.0991370677947998\n",
      "epoch:32,batch:50 loss:1.1030434370040894\n",
      "epoch:32,batch:51 loss:1.0858558416366577\n",
      "epoch:32,batch:52 loss:1.078824520111084\n",
      "epoch:32,batch:53 loss:1.106168270111084\n",
      "epoch:32,batch:54 loss:1.0874183177947998\n",
      "epoch:32,batch:55 loss:1.117887020111084\n",
      "epoch:32,batch:56 loss:1.1053870916366577\n",
      "epoch:32,batch:57 loss:1.0967931747436523\n",
      "epoch:32,batch:58 loss:1.1046059131622314\n",
      "epoch:32,batch:59 loss:1.0733559131622314\n",
      "epoch:32,batch:60 loss:1.085074543952942\n",
      "epoch:32,batch:61 loss:1.0881996154785156\n",
      "epoch:32,batch:62 loss:1.1225745677947998\n",
      "epoch:32,batch:63 loss:1.1249183416366577\n",
      "epoch:32,batch:64 loss:1.0921058654785156\n",
      "epoch:32,batch:65 loss:1.104605793952942\n",
      "epoch:32,batch:66 loss:1.096793293952942\n",
      "epoch:32,batch:67 loss:1.106168270111084\n",
      "epoch:32,batch:68 loss:1.1053870916366577\n",
      "epoch:32,batch:69 loss:1.1108558177947998\n",
      "epoch:32,batch:70 loss:1.1116371154785156\n",
      "epoch:32,batch:71 loss:1.0936683416366577\n",
      "epoch:32,batch:72 loss:1.1210120916366577\n",
      "epoch:32,batch:73 loss:1.0975745916366577\n",
      "epoch:32,batch:74 loss:1.088980793952942\n",
      "epoch:32,batch:75 loss:1.104605793952942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [04:32<02:27,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32,batch:76 loss:1.1108559370040894\n",
      "epoch:32,batch:77 loss:1.111636996269226\n",
      "epoch:32, train_loss:1.111636996269226\n",
      "epoch:33,batch:0 loss:1.0999183654785156\n",
      "epoch:33,batch:1 loss:1.113980770111084\n",
      "epoch:33,batch:2 loss:1.088199496269226\n",
      "epoch:33,batch:3 loss:1.1046059131622314\n",
      "epoch:33,batch:4 loss:1.1077308654785156\n",
      "epoch:33,batch:5 loss:1.0944496393203735\n",
      "epoch:33,batch:6 loss:1.0842933654785156\n",
      "epoch:33,batch:7 loss:1.0991370677947998\n",
      "epoch:33,batch:8 loss:1.0921058654785156\n",
      "epoch:33,batch:9 loss:1.100699543952942\n",
      "epoch:33,batch:10 loss:1.0991370677947998\n",
      "epoch:33,batch:11 loss:1.1069495677947998\n",
      "epoch:33,batch:12 loss:1.116324543952942\n",
      "epoch:33,batch:13 loss:1.1053870916366577\n",
      "epoch:33,batch:14 loss:1.1046059131622314\n",
      "epoch:33,batch:15 loss:1.0881996154785156\n",
      "epoch:33,batch:16 loss:1.128043293952942\n",
      "epoch:33,batch:17 loss:1.1014808416366577\n",
      "epoch:33,batch:18 loss:1.0874183177947998\n",
      "epoch:33,batch:19 loss:1.0788246393203735\n",
      "epoch:33,batch:20 loss:1.1014807224273682\n",
      "epoch:33,batch:21 loss:1.1046059131622314\n",
      "epoch:33,batch:22 loss:1.1163246631622314\n",
      "epoch:33,batch:23 loss:1.1108558177947998\n",
      "epoch:33,batch:24 loss:1.1194496154785156\n",
      "epoch:33,batch:25 loss:1.0866371393203735\n",
      "epoch:33,batch:26 loss:1.092887043952942\n",
      "epoch:33,batch:27 loss:1.0842933654785156\n",
      "epoch:33,batch:28 loss:1.1210120916366577\n",
      "epoch:33,batch:29 loss:1.0975745916366577\n",
      "epoch:33,batch:30 loss:1.0842933654785156\n",
      "epoch:33,batch:31 loss:1.0975745916366577\n",
      "epoch:33,batch:32 loss:1.1038246154785156\n",
      "epoch:33,batch:33 loss:1.1124184131622314\n",
      "epoch:33,batch:34 loss:1.090543270111084\n",
      "epoch:33,batch:35 loss:1.0897620916366577\n",
      "epoch:33,batch:36 loss:1.0991371870040894\n",
      "epoch:33,batch:37 loss:1.1085121631622314\n",
      "epoch:33,batch:38 loss:1.1006996631622314\n",
      "epoch:33,batch:39 loss:1.0858557224273682\n",
      "epoch:33,batch:40 loss:1.104605793952942\n",
      "epoch:33,batch:41 loss:1.1077308654785156\n",
      "epoch:33,batch:42 loss:1.1186683177947998\n",
      "epoch:33,batch:43 loss:1.1069495677947998\n",
      "epoch:33,batch:44 loss:1.0881996154785156\n",
      "epoch:33,batch:45 loss:1.0991370677947998\n",
      "epoch:33,batch:46 loss:1.0835120677947998\n",
      "epoch:33,batch:47 loss:1.082731008529663\n",
      "epoch:33,batch:48 loss:1.0999183654785156\n",
      "epoch:33,batch:49 loss:1.1014807224273682\n",
      "epoch:33,batch:50 loss:1.116324543952942\n",
      "epoch:33,batch:51 loss:1.0913245677947998\n",
      "epoch:33,batch:52 loss:1.133512020111084\n",
      "epoch:33,batch:53 loss:1.1108558177947998\n",
      "epoch:33,batch:54 loss:1.1217933893203735\n",
      "epoch:33,batch:55 loss:1.0983558893203735\n",
      "epoch:33,batch:56 loss:1.0897620916366577\n",
      "epoch:33,batch:57 loss:1.0913245677947998\n",
      "epoch:33,batch:58 loss:1.1030433177947998\n",
      "epoch:33,batch:59 loss:1.096793293952942\n",
      "epoch:33,batch:60 loss:1.113980770111084\n",
      "epoch:33,batch:61 loss:1.098355770111084\n",
      "epoch:33,batch:62 loss:1.1014808416366577\n",
      "epoch:33,batch:63 loss:1.0874183177947998\n",
      "epoch:33,batch:64 loss:1.1147620677947998\n",
      "epoch:33,batch:65 loss:1.094449520111084\n",
      "epoch:33,batch:66 loss:1.0975745916366577\n",
      "epoch:33,batch:67 loss:1.1077308654785156\n",
      "epoch:33,batch:68 loss:1.0756996870040894\n",
      "epoch:33,batch:69 loss:1.1139808893203735\n",
      "epoch:33,batch:70 loss:1.112418293952942\n",
      "epoch:33,batch:71 loss:1.085074543952942\n",
      "epoch:33,batch:72 loss:1.085074543952942\n",
      "epoch:33,batch:73 loss:1.0991370677947998\n",
      "epoch:33,batch:74 loss:1.0819495916366577\n",
      "epoch:33,batch:75 loss:1.1038246154785156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [04:40<02:15,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33,batch:76 loss:1.0921058654785156\n",
      "epoch:33,batch:77 loss:1.1061683893203735\n",
      "epoch:33, train_loss:1.1061683893203735\n",
      "epoch:34,batch:0 loss:1.0764808654785156\n",
      "epoch:34,batch:1 loss:1.1280434131622314\n",
      "epoch:34,batch:2 loss:1.098355770111084\n",
      "epoch:34,batch:3 loss:1.0960121154785156\n",
      "epoch:34,batch:4 loss:1.0960121154785156\n",
      "epoch:34,batch:5 loss:1.1014808416366577\n",
      "epoch:34,batch:6 loss:1.090543270111084\n",
      "epoch:34,batch:7 loss:1.1210120916366577\n",
      "epoch:34,batch:8 loss:1.065543293952942\n",
      "epoch:34,batch:9 loss:1.1171058416366577\n",
      "epoch:34,batch:10 loss:1.1116371154785156\n",
      "epoch:34,batch:11 loss:1.0725746154785156\n",
      "epoch:34,batch:12 loss:1.1038247346878052\n",
      "epoch:34,batch:13 loss:1.1171057224273682\n",
      "epoch:34,batch:14 loss:1.117887020111084\n",
      "epoch:34,batch:15 loss:1.1202309131622314\n",
      "epoch:34,batch:16 loss:1.1131995916366577\n",
      "epoch:34,batch:17 loss:1.0842933654785156\n",
      "epoch:34,batch:18 loss:1.092887043952942\n",
      "epoch:34,batch:19 loss:1.102262020111084\n",
      "epoch:34,batch:20 loss:1.092887043952942\n",
      "epoch:34,batch:21 loss:1.0780433416366577\n",
      "epoch:34,batch:22 loss:1.1131995916366577\n",
      "epoch:34,batch:23 loss:1.088980793952942\n",
      "epoch:34,batch:24 loss:1.1038246154785156\n",
      "epoch:34,batch:25 loss:1.104605793952942\n",
      "epoch:34,batch:26 loss:1.1194496154785156\n",
      "epoch:34,batch:27 loss:1.1014808416366577\n",
      "epoch:34,batch:28 loss:1.102262020111084\n",
      "epoch:34,batch:29 loss:1.0874183177947998\n",
      "epoch:34,batch:30 loss:1.1116371154785156\n",
      "epoch:34,batch:31 loss:1.0952308177947998\n",
      "epoch:34,batch:32 loss:1.1038247346878052\n",
      "epoch:34,batch:33 loss:1.0999183654785156\n",
      "epoch:34,batch:34 loss:1.1194496154785156\n",
      "epoch:34,batch:35 loss:1.1100746393203735\n",
      "epoch:34,batch:36 loss:1.1030434370040894\n",
      "epoch:34,batch:37 loss:1.1210120916366577\n",
      "epoch:34,batch:38 loss:1.127261996269226\n",
      "epoch:34,batch:39 loss:1.1038246154785156\n",
      "epoch:34,batch:40 loss:1.080386996269226\n",
      "epoch:34,batch:41 loss:1.1085121631622314\n",
      "epoch:34,batch:42 loss:1.1131995916366577\n",
      "epoch:34,batch:43 loss:1.098355770111084\n",
      "epoch:34,batch:44 loss:1.1038246154785156\n",
      "epoch:34,batch:45 loss:1.088980793952942\n",
      "epoch:34,batch:46 loss:1.1217933893203735\n",
      "epoch:34,batch:47 loss:1.1061683893203735\n",
      "epoch:34,batch:48 loss:1.1108558177947998\n",
      "epoch:34,batch:49 loss:1.0921058654785156\n",
      "epoch:34,batch:50 loss:1.1006996631622314\n",
      "epoch:34,batch:51 loss:1.0960121154785156\n",
      "epoch:34,batch:52 loss:1.1014807224273682\n",
      "epoch:34,batch:53 loss:1.1092933416366577\n",
      "epoch:34,batch:54 loss:1.0897620916366577\n",
      "epoch:34,batch:55 loss:1.0944496393203735\n",
      "epoch:34,batch:56 loss:1.0866371393203735\n",
      "epoch:34,batch:57 loss:1.0842933654785156\n",
      "epoch:34,batch:58 loss:1.0811684131622314\n",
      "epoch:34,batch:59 loss:1.1147620677947998\n",
      "epoch:34,batch:60 loss:1.0905433893203735\n",
      "epoch:34,batch:61 loss:1.085074543952942\n",
      "epoch:34,batch:62 loss:1.1053870916366577\n",
      "epoch:34,batch:63 loss:1.0764808654785156\n",
      "epoch:34,batch:64 loss:1.119449496269226\n",
      "epoch:34,batch:65 loss:1.100699543952942\n",
      "epoch:34,batch:66 loss:1.1131997108459473\n",
      "epoch:34,batch:67 loss:1.0858558416366577\n",
      "epoch:34,batch:68 loss:1.065543293952942\n",
      "epoch:34,batch:69 loss:1.1303870677947998\n",
      "epoch:34,batch:70 loss:1.106168270111084\n",
      "epoch:34,batch:71 loss:1.1217933893203735\n",
      "epoch:34,batch:72 loss:1.0858558416366577\n",
      "epoch:34,batch:73 loss:1.1092933416366577\n",
      "epoch:34,batch:74 loss:1.088980793952942\n",
      "epoch:34,batch:75 loss:1.0780433416366577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [04:48<02:06,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34,batch:76 loss:1.0764808654785156\n",
      "epoch:34,batch:77 loss:1.0991370677947998\n",
      "epoch:34, train_loss:1.0991370677947998\n",
      "epoch:35,batch:0 loss:1.1022621393203735\n",
      "epoch:35,batch:1 loss:1.098356008529663\n",
      "epoch:35,batch:2 loss:1.0960121154785156\n",
      "epoch:35,batch:3 loss:1.0819497108459473\n",
      "epoch:35,batch:4 loss:1.1038246154785156\n",
      "epoch:35,batch:5 loss:1.1171058416366577\n",
      "epoch:35,batch:6 loss:1.1069495677947998\n",
      "epoch:35,batch:7 loss:1.1116371154785156\n",
      "epoch:35,batch:8 loss:1.1038246154785156\n",
      "epoch:35,batch:9 loss:1.0975747108459473\n",
      "epoch:35,batch:10 loss:1.0881996154785156\n",
      "epoch:35,batch:11 loss:1.082730770111084\n",
      "epoch:35,batch:12 loss:1.110074520111084\n",
      "epoch:35,batch:13 loss:1.1131997108459473\n",
      "epoch:35,batch:14 loss:1.0827308893203735\n",
      "epoch:35,batch:15 loss:1.1092933416366577\n",
      "epoch:35,batch:16 loss:1.1069495677947998\n",
      "epoch:35,batch:17 loss:1.1342933177947998\n",
      "epoch:35,batch:18 loss:1.1092934608459473\n",
      "epoch:35,batch:19 loss:1.0905433893203735\n",
      "epoch:35,batch:20 loss:1.1108558177947998\n",
      "epoch:35,batch:21 loss:1.0975745916366577\n",
      "epoch:35,batch:22 loss:1.1077308654785156\n",
      "epoch:35,batch:23 loss:1.069449543952942\n",
      "epoch:35,batch:24 loss:1.1077308654785156\n",
      "epoch:35,batch:25 loss:1.1303870677947998\n",
      "epoch:35,batch:26 loss:1.0921058654785156\n",
      "epoch:35,batch:27 loss:1.103824496269226\n",
      "epoch:35,batch:28 loss:1.1171058416366577\n",
      "epoch:35,batch:29 loss:1.0921058654785156\n",
      "epoch:35,batch:30 loss:1.0741369724273682\n",
      "epoch:35,batch:31 loss:1.1014808416366577\n",
      "epoch:35,batch:32 loss:1.123355746269226\n",
      "epoch:35,batch:33 loss:1.107730746269226\n",
      "epoch:35,batch:34 loss:1.0803871154785156\n",
      "epoch:35,batch:35 loss:1.0897620916366577\n",
      "epoch:35,batch:36 loss:1.1030433177947998\n",
      "epoch:35,batch:37 loss:1.0858558416366577\n",
      "epoch:35,batch:38 loss:1.102262020111084\n",
      "epoch:35,batch:39 loss:1.1092933416366577\n",
      "epoch:35,batch:40 loss:1.0952308177947998\n",
      "epoch:35,batch:41 loss:1.0952308177947998\n",
      "epoch:35,batch:42 loss:1.0827308893203735\n",
      "epoch:35,batch:43 loss:1.1171058416366577\n",
      "epoch:35,batch:44 loss:1.0975745916366577\n",
      "epoch:35,batch:45 loss:1.1381995677947998\n",
      "epoch:35,batch:46 loss:1.1030433177947998\n",
      "epoch:35,batch:47 loss:1.0952308177947998\n",
      "epoch:35,batch:48 loss:1.0921058654785156\n",
      "epoch:35,batch:49 loss:1.115543246269226\n",
      "epoch:35,batch:50 loss:1.1006996631622314\n",
      "epoch:35,batch:51 loss:1.1210120916366577\n",
      "epoch:35,batch:52 loss:1.0858558416366577\n",
      "epoch:35,batch:53 loss:1.1155433654785156\n",
      "epoch:35,batch:54 loss:1.0952308177947998\n",
      "epoch:35,batch:55 loss:1.0772621631622314\n",
      "epoch:35,batch:56 loss:1.125699520111084\n",
      "epoch:35,batch:57 loss:1.0702307224273682\n",
      "epoch:35,batch:58 loss:1.0889809131622314\n",
      "epoch:35,batch:59 loss:1.1092933416366577\n",
      "epoch:35,batch:60 loss:1.1186683177947998\n",
      "epoch:35,batch:61 loss:1.1108558177947998\n",
      "epoch:35,batch:62 loss:1.1100746393203735\n",
      "epoch:35,batch:63 loss:1.0967934131622314\n",
      "epoch:35,batch:64 loss:1.1006996631622314\n",
      "epoch:35,batch:65 loss:1.0858558416366577\n",
      "epoch:35,batch:66 loss:1.1046059131622314\n",
      "epoch:35,batch:67 loss:1.0975747108459473\n",
      "epoch:35,batch:68 loss:1.0842933654785156\n",
      "epoch:35,batch:69 loss:1.092887043952942\n",
      "epoch:35,batch:70 loss:1.0889809131622314\n",
      "epoch:35,batch:71 loss:1.0897622108459473\n",
      "epoch:35,batch:72 loss:1.1069495677947998\n",
      "epoch:35,batch:73 loss:1.0913245677947998\n",
      "epoch:35,batch:74 loss:1.1030433177947998\n",
      "epoch:35,batch:75 loss:1.074918270111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [04:57<02:00,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35,batch:76 loss:1.086637020111084\n",
      "epoch:35,batch:77 loss:1.1155433654785156\n",
      "epoch:35, train_loss:1.1155433654785156\n",
      "epoch:36,batch:0 loss:1.102262020111084\n",
      "epoch:36,batch:1 loss:1.098355770111084\n",
      "epoch:36,batch:2 loss:1.0952308177947998\n",
      "epoch:36,batch:3 loss:1.0921058654785156\n",
      "epoch:36,batch:4 loss:1.1077308654785156\n",
      "epoch:36,batch:5 loss:1.0952308177947998\n",
      "epoch:36,batch:6 loss:1.0678870677947998\n",
      "epoch:36,batch:7 loss:1.1038246154785156\n",
      "epoch:36,batch:8 loss:1.113980770111084\n",
      "epoch:36,batch:9 loss:1.081168293952942\n",
      "epoch:36,batch:10 loss:1.0960121154785156\n",
      "epoch:36,batch:11 loss:1.1038246154785156\n",
      "epoch:36,batch:12 loss:1.0819495916366577\n",
      "epoch:36,batch:13 loss:1.0983558893203735\n",
      "epoch:36,batch:14 loss:1.1155433654785156\n",
      "epoch:36,batch:15 loss:1.1171059608459473\n",
      "epoch:36,batch:16 loss:1.1061683893203735\n",
      "epoch:36,batch:17 loss:1.0858558416366577\n",
      "epoch:36,batch:18 loss:1.100699543952942\n",
      "epoch:36,batch:19 loss:1.1053872108459473\n",
      "epoch:36,batch:20 loss:1.0897622108459473\n",
      "epoch:36,batch:21 loss:1.1350746154785156\n",
      "epoch:36,batch:22 loss:1.106168270111084\n",
      "epoch:36,batch:23 loss:1.0975745916366577\n",
      "epoch:36,batch:24 loss:1.0936683416366577\n",
      "epoch:36,batch:25 loss:1.1085121631622314\n",
      "epoch:36,batch:26 loss:1.113980770111084\n",
      "epoch:36,batch:27 loss:1.0889809131622314\n",
      "epoch:36,batch:28 loss:1.099918246269226\n",
      "epoch:36,batch:29 loss:1.0913245677947998\n",
      "epoch:36,batch:30 loss:1.1147620677947998\n",
      "epoch:36,batch:31 loss:1.0928871631622314\n",
      "epoch:36,batch:32 loss:1.0874183177947998\n",
      "epoch:36,batch:33 loss:1.0913245677947998\n",
      "epoch:36,batch:34 loss:1.1092932224273682\n",
      "epoch:36,batch:35 loss:1.1053872108459473\n",
      "epoch:36,batch:36 loss:1.096011996269226\n",
      "epoch:36,batch:37 loss:1.0835120677947998\n",
      "epoch:36,batch:38 loss:1.0905433893203735\n",
      "epoch:36,batch:39 loss:1.0928871631622314\n",
      "epoch:36,batch:40 loss:1.090543270111084\n",
      "epoch:36,batch:41 loss:1.099918246269226\n",
      "epoch:36,batch:42 loss:1.0975745916366577\n",
      "epoch:36,batch:43 loss:1.100699543952942\n",
      "epoch:36,batch:44 loss:1.0858558416366577\n",
      "epoch:36,batch:45 loss:1.1100746393203735\n",
      "epoch:36,batch:46 loss:1.0913245677947998\n",
      "epoch:36,batch:47 loss:1.1038246154785156\n",
      "epoch:36,batch:48 loss:1.1069496870040894\n",
      "epoch:36,batch:49 loss:1.110074520111084\n",
      "epoch:36,batch:50 loss:1.0991371870040894\n",
      "epoch:36,batch:51 loss:1.0952308177947998\n",
      "epoch:36,batch:52 loss:1.1030433177947998\n",
      "epoch:36,batch:53 loss:1.0928871631622314\n",
      "epoch:36,batch:54 loss:1.1006996631622314\n",
      "epoch:36,batch:55 loss:1.1171059608459473\n",
      "epoch:36,batch:56 loss:1.0889809131622314\n",
      "epoch:36,batch:57 loss:1.0483558177947998\n",
      "epoch:36,batch:58 loss:1.1100746393203735\n",
      "epoch:36,batch:59 loss:1.1006996631622314\n",
      "epoch:36,batch:60 loss:1.0983558893203735\n",
      "epoch:36,batch:61 loss:1.113980770111084\n",
      "epoch:36,batch:62 loss:1.1022621393203735\n",
      "epoch:36,batch:63 loss:1.0936683416366577\n",
      "epoch:36,batch:64 loss:1.1147620677947998\n",
      "epoch:36,batch:65 loss:1.0983558893203735\n",
      "epoch:36,batch:66 loss:1.104605793952942\n",
      "epoch:36,batch:67 loss:1.096793293952942\n",
      "epoch:36,batch:68 loss:1.119449496269226\n",
      "epoch:36,batch:69 loss:1.1225745677947998\n",
      "epoch:36,batch:70 loss:1.1124184131622314\n",
      "epoch:36,batch:71 loss:1.1171058416366577\n",
      "epoch:36,batch:72 loss:1.1131995916366577\n",
      "epoch:36,batch:73 loss:1.1264809370040894\n",
      "epoch:36,batch:74 loss:1.0967934131622314\n",
      "epoch:36,batch:75 loss:1.1077308654785156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [05:05<01:50,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36,batch:76 loss:1.0819495916366577\n",
      "epoch:36,batch:77 loss:1.0967934131622314\n",
      "epoch:36, train_loss:1.0967934131622314\n",
      "epoch:37,batch:0 loss:1.0858558416366577\n",
      "epoch:37,batch:1 loss:1.1061683893203735\n",
      "epoch:37,batch:2 loss:1.108512043952942\n",
      "epoch:37,batch:3 loss:1.1069495677947998\n",
      "epoch:37,batch:4 loss:1.1077308654785156\n",
      "epoch:37,batch:5 loss:1.104605793952942\n",
      "epoch:37,batch:6 loss:1.1085121631622314\n",
      "epoch:37,batch:7 loss:1.1069495677947998\n",
      "epoch:37,batch:8 loss:1.0991371870040894\n",
      "epoch:37,batch:9 loss:1.1092932224273682\n",
      "epoch:37,batch:10 loss:1.1264808177947998\n",
      "epoch:37,batch:11 loss:1.0936683416366577\n",
      "epoch:37,batch:12 loss:1.1014808416366577\n",
      "epoch:37,batch:13 loss:1.0897620916366577\n",
      "epoch:37,batch:14 loss:1.1178871393203735\n",
      "epoch:37,batch:15 loss:1.112418293952942\n",
      "epoch:37,batch:16 loss:1.0913245677947998\n",
      "epoch:37,batch:17 loss:1.0936683416366577\n",
      "epoch:37,batch:18 loss:1.0874183177947998\n",
      "epoch:37,batch:19 loss:1.117887020111084\n",
      "epoch:37,batch:20 loss:1.0913245677947998\n",
      "epoch:37,batch:21 loss:1.1100746393203735\n",
      "epoch:37,batch:22 loss:1.1202309131622314\n",
      "epoch:37,batch:23 loss:1.1108558177947998\n",
      "epoch:37,batch:24 loss:1.0803871154785156\n",
      "epoch:37,batch:25 loss:1.1014809608459473\n",
      "epoch:37,batch:26 loss:1.1046059131622314\n",
      "epoch:37,batch:27 loss:1.1061683893203735\n",
      "epoch:37,batch:28 loss:1.1100746393203735\n",
      "epoch:37,batch:29 loss:1.106168270111084\n",
      "epoch:37,batch:30 loss:1.0936683416366577\n",
      "epoch:37,batch:31 loss:1.1022621393203735\n",
      "epoch:37,batch:32 loss:1.0936683416366577\n",
      "epoch:37,batch:33 loss:1.088199496269226\n",
      "epoch:37,batch:34 loss:1.1030433177947998\n",
      "epoch:37,batch:35 loss:1.0819495916366577\n",
      "epoch:37,batch:36 loss:1.0819497108459473\n",
      "epoch:37,batch:37 loss:1.0780433416366577\n",
      "epoch:37,batch:38 loss:1.0905433893203735\n",
      "epoch:37,batch:39 loss:1.067105770111084\n",
      "epoch:37,batch:40 loss:1.1327308416366577\n",
      "epoch:37,batch:41 loss:1.102262020111084\n",
      "epoch:37,batch:42 loss:1.0913246870040894\n",
      "epoch:37,batch:43 loss:1.1108558177947998\n",
      "epoch:37,batch:44 loss:1.1030434370040894\n",
      "epoch:37,batch:45 loss:1.1006996631622314\n",
      "epoch:37,batch:46 loss:1.0725746154785156\n",
      "epoch:37,batch:47 loss:1.1046059131622314\n",
      "epoch:37,batch:48 loss:1.0991370677947998\n",
      "epoch:37,batch:49 loss:1.1022621393203735\n",
      "epoch:37,batch:50 loss:1.0975747108459473\n",
      "epoch:37,batch:51 loss:1.0960121154785156\n",
      "epoch:37,batch:52 loss:1.1092933416366577\n",
      "epoch:37,batch:53 loss:1.1053870916366577\n",
      "epoch:37,batch:54 loss:1.1171058416366577\n",
      "epoch:37,batch:55 loss:1.1217933893203735\n",
      "epoch:37,batch:56 loss:1.0975745916366577\n",
      "epoch:37,batch:57 loss:1.1303870677947998\n",
      "epoch:37,batch:58 loss:1.0921058654785156\n",
      "epoch:37,batch:59 loss:1.0858558416366577\n",
      "epoch:37,batch:60 loss:1.0905433893203735\n",
      "epoch:37,batch:61 loss:1.1022621393203735\n",
      "epoch:37,batch:62 loss:1.1147620677947998\n",
      "epoch:37,batch:63 loss:1.0733559131622314\n",
      "epoch:37,batch:64 loss:1.0756995677947998\n",
      "epoch:37,batch:65 loss:1.1139808893203735\n",
      "epoch:37,batch:66 loss:1.088980793952942\n",
      "epoch:37,batch:67 loss:1.0991371870040894\n",
      "epoch:37,batch:68 loss:1.0952308177947998\n",
      "epoch:37,batch:69 loss:1.1186683177947998\n",
      "epoch:37,batch:70 loss:1.0850746631622314\n",
      "epoch:37,batch:71 loss:1.096011996269226\n",
      "epoch:37,batch:72 loss:1.0827308893203735\n",
      "epoch:37,batch:73 loss:1.1085121631622314\n",
      "epoch:37,batch:74 loss:1.1069494485855103\n",
      "epoch:37,batch:75 loss:1.1006996631622314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [05:13<01:40,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37,batch:76 loss:1.110074520111084\n",
      "epoch:37,batch:77 loss:1.0967934131622314\n",
      "epoch:37, train_loss:1.0967934131622314\n",
      "epoch:38,batch:0 loss:1.1374183893203735\n",
      "epoch:38,batch:1 loss:1.1139808893203735\n",
      "epoch:38,batch:2 loss:1.077262043952942\n",
      "epoch:38,batch:3 loss:1.0999183654785156\n",
      "epoch:38,batch:4 loss:1.0835120677947998\n",
      "epoch:38,batch:5 loss:1.086637020111084\n",
      "epoch:38,batch:6 loss:1.0889809131622314\n",
      "epoch:38,batch:7 loss:1.1092933416366577\n",
      "epoch:38,batch:8 loss:1.113980770111084\n",
      "epoch:38,batch:9 loss:1.0960121154785156\n",
      "epoch:38,batch:10 loss:1.084293246269226\n",
      "epoch:38,batch:11 loss:1.1147621870040894\n",
      "epoch:38,batch:12 loss:1.103824496269226\n",
      "epoch:38,batch:13 loss:1.113980770111084\n",
      "epoch:38,batch:14 loss:1.103824496269226\n",
      "epoch:38,batch:15 loss:1.0913245677947998\n",
      "epoch:38,batch:16 loss:1.1077308654785156\n",
      "epoch:38,batch:17 loss:1.0897620916366577\n",
      "epoch:38,batch:18 loss:1.1147620677947998\n",
      "epoch:38,batch:19 loss:1.0897620916366577\n",
      "epoch:38,batch:20 loss:1.112418293952942\n",
      "epoch:38,batch:21 loss:1.1116371154785156\n",
      "epoch:38,batch:22 loss:1.0678870677947998\n",
      "epoch:38,batch:23 loss:1.1100746393203735\n",
      "epoch:38,batch:24 loss:1.1014807224273682\n",
      "epoch:38,batch:25 loss:1.1092933416366577\n",
      "epoch:38,batch:26 loss:1.106168270111084\n",
      "epoch:38,batch:27 loss:1.0725746154785156\n",
      "epoch:38,batch:28 loss:1.1163246631622314\n",
      "epoch:38,batch:29 loss:1.0881996154785156\n",
      "epoch:38,batch:30 loss:1.081168293952942\n",
      "epoch:38,batch:31 loss:1.0975745916366577\n",
      "epoch:38,batch:32 loss:1.1272621154785156\n",
      "epoch:38,batch:33 loss:1.1131995916366577\n",
      "epoch:38,batch:34 loss:1.0788246393203735\n",
      "epoch:38,batch:35 loss:1.0952308177947998\n",
      "epoch:38,batch:36 loss:1.074918270111084\n",
      "epoch:38,batch:37 loss:1.0874183177947998\n",
      "epoch:38,batch:38 loss:1.0874183177947998\n",
      "epoch:38,batch:39 loss:1.1116371154785156\n",
      "epoch:38,batch:40 loss:1.123355746269226\n",
      "epoch:38,batch:41 loss:1.0967934131622314\n",
      "epoch:38,batch:42 loss:1.1092934608459473\n",
      "epoch:38,batch:43 loss:1.102262020111084\n",
      "epoch:38,batch:44 loss:1.1116371154785156\n",
      "epoch:38,batch:45 loss:1.0944496393203735\n",
      "epoch:38,batch:46 loss:1.0741369724273682\n",
      "epoch:38,batch:47 loss:1.094449520111084\n",
      "epoch:38,batch:48 loss:1.0835120677947998\n",
      "epoch:38,batch:49 loss:1.1327308416366577\n",
      "epoch:38,batch:50 loss:1.096793293952942\n",
      "epoch:38,batch:51 loss:1.0921058654785156\n",
      "epoch:38,batch:52 loss:1.1038246154785156\n",
      "epoch:38,batch:53 loss:1.1077308654785156\n",
      "epoch:38,batch:54 loss:1.1030433177947998\n",
      "epoch:38,batch:55 loss:1.1147620677947998\n",
      "epoch:38,batch:56 loss:1.0874183177947998\n",
      "epoch:38,batch:57 loss:1.1006996631622314\n",
      "epoch:38,batch:58 loss:1.0905433893203735\n",
      "epoch:38,batch:59 loss:1.1100746393203735\n",
      "epoch:38,batch:60 loss:1.1006996631622314\n",
      "epoch:38,batch:61 loss:1.1264808177947998\n",
      "epoch:38,batch:62 loss:1.1038246154785156\n",
      "epoch:38,batch:63 loss:1.0983558893203735\n",
      "epoch:38,batch:64 loss:1.1171058416366577\n",
      "epoch:38,batch:65 loss:1.1014808416366577\n",
      "epoch:38,batch:66 loss:1.0858558416366577\n",
      "epoch:38,batch:67 loss:1.1077308654785156\n",
      "epoch:38,batch:68 loss:1.0921058654785156\n",
      "epoch:38,batch:69 loss:1.094449520111084\n",
      "epoch:38,batch:70 loss:1.1288245916366577\n",
      "epoch:38,batch:71 loss:1.1116371154785156\n",
      "epoch:38,batch:72 loss:1.0889809131622314\n",
      "epoch:38,batch:73 loss:1.113980770111084\n",
      "epoch:38,batch:74 loss:1.081168293952942\n",
      "epoch:38,batch:75 loss:1.1061683893203735\n",
      "epoch:38,batch:76 loss:1.077262043952942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [05:22<01:31,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38,batch:77 loss:1.092887043952942\n",
      "epoch:38, train_loss:1.092887043952942\n",
      "epoch:39,batch:0 loss:1.1108558177947998\n",
      "epoch:39,batch:1 loss:1.0889809131622314\n",
      "epoch:39,batch:2 loss:1.0944496393203735\n",
      "epoch:39,batch:3 loss:1.0936682224273682\n",
      "epoch:39,batch:4 loss:1.098355770111084\n",
      "epoch:39,batch:5 loss:1.1202309131622314\n",
      "epoch:39,batch:6 loss:1.1030433177947998\n",
      "epoch:39,batch:7 loss:1.1053872108459473\n",
      "epoch:39,batch:8 loss:1.1194496154785156\n",
      "epoch:39,batch:9 loss:1.0967934131622314\n",
      "epoch:39,batch:10 loss:1.0928871631622314\n",
      "epoch:39,batch:11 loss:1.102262020111084\n",
      "epoch:39,batch:12 loss:1.0983558893203735\n",
      "epoch:39,batch:13 loss:1.082730770111084\n",
      "epoch:39,batch:14 loss:1.104605793952942\n",
      "epoch:39,batch:15 loss:1.0647621154785156\n",
      "epoch:39,batch:16 loss:1.112418293952942\n",
      "epoch:39,batch:17 loss:1.1186683177947998\n",
      "epoch:39,batch:18 loss:1.1046059131622314\n",
      "epoch:39,batch:19 loss:1.0991370677947998\n",
      "epoch:39,batch:20 loss:1.0889809131622314\n",
      "epoch:39,batch:21 loss:1.0936683416366577\n",
      "epoch:39,batch:22 loss:1.0803871154785156\n",
      "epoch:39,batch:23 loss:1.1092933416366577\n",
      "epoch:39,batch:24 loss:1.1085121631622314\n",
      "epoch:39,batch:25 loss:1.0991370677947998\n",
      "epoch:39,batch:26 loss:1.123355746269226\n",
      "epoch:39,batch:27 loss:1.1038246154785156\n",
      "epoch:39,batch:28 loss:1.103824496269226\n",
      "epoch:39,batch:29 loss:1.0991370677947998\n",
      "epoch:39,batch:30 loss:1.0913245677947998\n",
      "epoch:39,batch:31 loss:1.125699520111084\n",
      "epoch:39,batch:32 loss:1.1061683893203735\n",
      "epoch:39,batch:33 loss:1.1241371631622314\n",
      "epoch:39,batch:34 loss:1.1116371154785156\n",
      "epoch:39,batch:35 loss:1.1092933416366577\n",
      "epoch:39,batch:36 loss:1.0936683416366577\n",
      "epoch:39,batch:37 loss:1.1202309131622314\n",
      "epoch:39,batch:38 loss:1.1233558654785156\n",
      "epoch:39,batch:39 loss:1.0702307224273682\n",
      "epoch:39,batch:40 loss:1.1030433177947998\n",
      "epoch:39,batch:41 loss:1.0991370677947998\n",
      "epoch:39,batch:42 loss:1.0835120677947998\n",
      "epoch:39,batch:43 loss:1.1092933416366577\n",
      "epoch:39,batch:44 loss:1.0881996154785156\n",
      "epoch:39,batch:45 loss:1.102262020111084\n",
      "epoch:39,batch:46 loss:1.0975745916366577\n",
      "epoch:39,batch:47 loss:1.0952308177947998\n",
      "epoch:39,batch:48 loss:1.1053870916366577\n",
      "epoch:39,batch:49 loss:1.0921058654785156\n",
      "epoch:39,batch:50 loss:1.088980793952942\n",
      "epoch:39,batch:51 loss:1.1014808416366577\n",
      "epoch:39,batch:52 loss:1.0952308177947998\n",
      "epoch:39,batch:53 loss:1.1022621393203735\n",
      "epoch:39,batch:54 loss:1.096793293952942\n",
      "epoch:39,batch:55 loss:1.092887043952942\n",
      "epoch:39,batch:56 loss:1.1085121631622314\n",
      "epoch:39,batch:57 loss:1.090543270111084\n",
      "epoch:39,batch:58 loss:1.0811684131622314\n",
      "epoch:39,batch:59 loss:1.0788246393203735\n",
      "epoch:39,batch:60 loss:1.1069495677947998\n",
      "epoch:39,batch:61 loss:1.096793293952942\n",
      "epoch:39,batch:62 loss:1.096793293952942\n",
      "epoch:39,batch:63 loss:1.1030433177947998\n",
      "epoch:39,batch:64 loss:1.1217933893203735\n",
      "epoch:39,batch:65 loss:1.0780433416366577\n",
      "epoch:39,batch:66 loss:1.1069495677947998\n",
      "epoch:39,batch:67 loss:1.0858558416366577\n",
      "epoch:39,batch:68 loss:1.1061683893203735\n",
      "epoch:39,batch:69 loss:1.1053870916366577\n",
      "epoch:39,batch:70 loss:1.099918246269226\n",
      "epoch:39,batch:71 loss:1.1014807224273682\n",
      "epoch:39,batch:72 loss:1.1186683177947998\n",
      "epoch:39,batch:73 loss:1.112418293952942\n",
      "epoch:39,batch:74 loss:1.1030434370040894\n",
      "epoch:39,batch:75 loss:1.1014807224273682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [05:30<01:22,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39,batch:76 loss:1.098355770111084\n",
      "epoch:39,batch:77 loss:1.0850746631622314\n",
      "epoch:39, train_loss:1.0850746631622314\n",
      "epoch:40,batch:0 loss:1.0944496393203735\n",
      "epoch:40,batch:1 loss:1.0991370677947998\n",
      "epoch:40,batch:2 loss:1.0975747108459473\n",
      "epoch:40,batch:3 loss:1.085074543952942\n",
      "epoch:40,batch:4 loss:1.117887020111084\n",
      "epoch:40,batch:5 loss:1.1194496154785156\n",
      "epoch:40,batch:6 loss:1.0842933654785156\n",
      "epoch:40,batch:7 loss:1.0991370677947998\n",
      "epoch:40,batch:8 loss:1.1014808416366577\n",
      "epoch:40,batch:9 loss:1.1069495677947998\n",
      "epoch:40,batch:10 loss:1.113980770111084\n",
      "epoch:40,batch:11 loss:1.116324543952942\n",
      "epoch:40,batch:12 loss:1.104605793952942\n",
      "epoch:40,batch:13 loss:1.1186683177947998\n",
      "epoch:40,batch:14 loss:1.0647621154785156\n",
      "epoch:40,batch:15 loss:1.117887020111084\n",
      "epoch:40,batch:16 loss:1.0842933654785156\n",
      "epoch:40,batch:17 loss:1.1186683177947998\n",
      "epoch:40,batch:18 loss:1.0960121154785156\n",
      "epoch:40,batch:19 loss:1.1108558177947998\n",
      "epoch:40,batch:20 loss:1.1022621393203735\n",
      "epoch:40,batch:21 loss:1.1069495677947998\n",
      "epoch:40,batch:22 loss:1.1053870916366577\n",
      "epoch:40,batch:23 loss:1.0889809131622314\n",
      "epoch:40,batch:24 loss:1.0936683416366577\n",
      "epoch:40,batch:25 loss:1.1264808177947998\n",
      "epoch:40,batch:26 loss:1.0647621154785156\n",
      "epoch:40,batch:27 loss:1.0975745916366577\n",
      "epoch:40,batch:28 loss:1.0928871631622314\n",
      "epoch:40,batch:29 loss:1.0881996154785156\n",
      "epoch:40,batch:30 loss:1.1069495677947998\n",
      "epoch:40,batch:31 loss:1.112418293952942\n",
      "epoch:40,batch:32 loss:1.1108558177947998\n",
      "epoch:40,batch:33 loss:1.0991370677947998\n",
      "epoch:40,batch:34 loss:1.0952309370040894\n",
      "epoch:40,batch:35 loss:1.0952308177947998\n",
      "epoch:40,batch:36 loss:1.0983558893203735\n",
      "epoch:40,batch:37 loss:1.1006996631622314\n",
      "epoch:40,batch:38 loss:1.1053870916366577\n",
      "epoch:40,batch:39 loss:1.106168270111084\n",
      "epoch:40,batch:40 loss:1.1139808893203735\n",
      "epoch:40,batch:41 loss:1.077262043952942\n",
      "epoch:40,batch:42 loss:1.0897620916366577\n",
      "epoch:40,batch:43 loss:1.1069495677947998\n",
      "epoch:40,batch:44 loss:1.1022621393203735\n",
      "epoch:40,batch:45 loss:1.1014807224273682\n",
      "epoch:40,batch:46 loss:1.1053870916366577\n",
      "epoch:40,batch:47 loss:1.0780433416366577\n",
      "epoch:40,batch:48 loss:1.0991370677947998\n",
      "epoch:40,batch:49 loss:1.086637020111084\n",
      "epoch:40,batch:50 loss:1.0881996154785156\n",
      "epoch:40,batch:51 loss:1.0975745916366577\n",
      "epoch:40,batch:52 loss:1.0827308893203735\n",
      "epoch:40,batch:53 loss:1.0928871631622314\n",
      "epoch:40,batch:54 loss:1.0952308177947998\n",
      "epoch:40,batch:55 loss:1.0850746631622314\n",
      "epoch:40,batch:56 loss:1.120230793952942\n",
      "epoch:40,batch:57 loss:1.0842933654785156\n",
      "epoch:40,batch:58 loss:1.0975747108459473\n",
      "epoch:40,batch:59 loss:1.1061683893203735\n",
      "epoch:40,batch:60 loss:1.1053870916366577\n",
      "epoch:40,batch:61 loss:1.1405433416366577\n",
      "epoch:40,batch:62 loss:1.1092934608459473\n",
      "epoch:40,batch:63 loss:1.110074520111084\n",
      "epoch:40,batch:64 loss:1.0913245677947998\n",
      "epoch:40,batch:65 loss:1.0858558416366577\n",
      "epoch:40,batch:66 loss:1.0788246393203735\n",
      "epoch:40,batch:67 loss:1.104605793952942\n",
      "epoch:40,batch:68 loss:1.0967934131622314\n",
      "epoch:40,batch:69 loss:1.084293246269226\n",
      "epoch:40,batch:70 loss:1.0975747108459473\n",
      "epoch:40,batch:71 loss:1.1092933416366577\n",
      "epoch:40,batch:72 loss:1.100699543952942\n",
      "epoch:40,batch:73 loss:1.1147620677947998\n",
      "epoch:40,batch:74 loss:1.112418293952942\n",
      "epoch:40,batch:75 loss:1.0991370677947998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [05:38<01:13,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40,batch:76 loss:1.1139808893203735\n",
      "epoch:40,batch:77 loss:1.121793270111084\n",
      "epoch:40, train_loss:1.121793270111084\n",
      "epoch:41,batch:0 loss:1.1100746393203735\n",
      "epoch:41,batch:1 loss:1.0983558893203735\n",
      "epoch:41,batch:2 loss:1.1233558654785156\n",
      "epoch:41,batch:3 loss:1.1131994724273682\n",
      "epoch:41,batch:4 loss:1.0944496393203735\n",
      "epoch:41,batch:5 loss:1.1030433177947998\n",
      "epoch:41,batch:6 loss:1.1116371154785156\n",
      "epoch:41,batch:7 loss:1.0921058654785156\n",
      "epoch:41,batch:8 loss:1.1194496154785156\n",
      "epoch:41,batch:9 loss:1.112418293952942\n",
      "epoch:41,batch:10 loss:1.1147620677947998\n",
      "epoch:41,batch:11 loss:1.092887043952942\n",
      "epoch:41,batch:12 loss:1.0960121154785156\n",
      "epoch:41,batch:13 loss:1.1256996393203735\n",
      "epoch:41,batch:14 loss:1.0881996154785156\n",
      "epoch:41,batch:15 loss:1.0952308177947998\n",
      "epoch:41,batch:16 loss:1.121793270111084\n",
      "epoch:41,batch:17 loss:1.0686683654785156\n",
      "epoch:41,batch:18 loss:1.0616371631622314\n",
      "epoch:41,batch:19 loss:1.1061683893203735\n",
      "epoch:41,batch:20 loss:1.1030433177947998\n",
      "epoch:41,batch:21 loss:1.0874183177947998\n",
      "epoch:41,batch:22 loss:1.1077308654785156\n",
      "epoch:41,batch:23 loss:1.1014808416366577\n",
      "epoch:41,batch:24 loss:1.0913246870040894\n",
      "epoch:41,batch:25 loss:1.1038246154785156\n",
      "epoch:41,batch:26 loss:1.0983558893203735\n",
      "epoch:41,batch:27 loss:1.1077308654785156\n",
      "epoch:41,batch:28 loss:1.0889809131622314\n",
      "epoch:41,batch:29 loss:1.128043293952942\n",
      "epoch:41,batch:30 loss:1.0944496393203735\n",
      "epoch:41,batch:31 loss:1.1147620677947998\n",
      "epoch:41,batch:32 loss:1.1038246154785156\n",
      "epoch:41,batch:33 loss:1.085074543952942\n",
      "epoch:41,batch:34 loss:1.085074543952942\n",
      "epoch:41,batch:35 loss:1.0835120677947998\n",
      "epoch:41,batch:36 loss:1.081168293952942\n",
      "epoch:41,batch:37 loss:1.1147620677947998\n",
      "epoch:41,batch:38 loss:1.1280434131622314\n",
      "epoch:41,batch:39 loss:1.0967934131622314\n",
      "epoch:41,batch:40 loss:1.0975745916366577\n",
      "epoch:41,batch:41 loss:1.1014808416366577\n",
      "epoch:41,batch:42 loss:1.1147620677947998\n",
      "epoch:41,batch:43 loss:1.104605793952942\n",
      "epoch:41,batch:44 loss:1.1030434370040894\n",
      "epoch:41,batch:45 loss:1.1186683177947998\n",
      "epoch:41,batch:46 loss:1.0827308893203735\n",
      "epoch:41,batch:47 loss:1.123355746269226\n",
      "epoch:41,batch:48 loss:1.0889809131622314\n",
      "epoch:41,batch:49 loss:1.0842933654785156\n",
      "epoch:41,batch:50 loss:1.1092933416366577\n",
      "epoch:41,batch:51 loss:1.1108558177947998\n",
      "epoch:41,batch:52 loss:1.0850746631622314\n",
      "epoch:41,batch:53 loss:1.0944496393203735\n",
      "epoch:41,batch:54 loss:1.0811684131622314\n",
      "epoch:41,batch:55 loss:1.1171058416366577\n",
      "epoch:41,batch:56 loss:1.092887043952942\n",
      "epoch:41,batch:57 loss:1.116324543952942\n",
      "epoch:41,batch:58 loss:1.1108558177947998\n",
      "epoch:41,batch:59 loss:1.0686683654785156\n",
      "epoch:41,batch:60 loss:1.1061683893203735\n",
      "epoch:41,batch:61 loss:1.0991370677947998\n",
      "epoch:41,batch:62 loss:1.0881996154785156\n",
      "epoch:41,batch:63 loss:1.0827308893203735\n",
      "epoch:41,batch:64 loss:1.088980793952942\n",
      "epoch:41,batch:65 loss:1.099918246269226\n",
      "epoch:41,batch:66 loss:1.1030433177947998\n",
      "epoch:41,batch:67 loss:1.1194496154785156\n",
      "epoch:41,batch:68 loss:1.0796058177947998\n",
      "epoch:41,batch:69 loss:1.0858557224273682\n",
      "epoch:41,batch:70 loss:1.1030434370040894\n",
      "epoch:41,batch:71 loss:1.1116371154785156\n",
      "epoch:41,batch:72 loss:1.096011996269226\n",
      "epoch:41,batch:73 loss:1.0928871631622314\n",
      "epoch:41,batch:74 loss:1.1061683893203735\n",
      "epoch:41,batch:75 loss:1.1069495677947998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [05:46<01:05,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41,batch:76 loss:1.0913245677947998\n",
      "epoch:41,batch:77 loss:1.1100746393203735\n",
      "epoch:41, train_loss:1.1100746393203735\n",
      "epoch:42,batch:0 loss:1.1030434370040894\n",
      "epoch:42,batch:1 loss:1.0983558893203735\n",
      "epoch:42,batch:2 loss:1.0835120677947998\n",
      "epoch:42,batch:3 loss:1.1053870916366577\n",
      "epoch:42,batch:4 loss:1.0858559608459473\n",
      "epoch:42,batch:5 loss:1.0975745916366577\n",
      "epoch:42,batch:6 loss:1.1116371154785156\n",
      "epoch:42,batch:7 loss:1.0842933654785156\n",
      "epoch:42,batch:8 loss:1.0936683416366577\n",
      "epoch:42,batch:9 loss:1.0936684608459473\n",
      "epoch:42,batch:10 loss:1.088980793952942\n",
      "epoch:42,batch:11 loss:1.1155433654785156\n",
      "epoch:42,batch:12 loss:1.085074543952942\n",
      "epoch:42,batch:13 loss:1.1225745677947998\n",
      "epoch:42,batch:14 loss:1.1194496154785156\n",
      "epoch:42,batch:15 loss:1.110074520111084\n",
      "epoch:42,batch:16 loss:1.0975745916366577\n",
      "epoch:42,batch:17 loss:1.073355793952942\n",
      "epoch:42,batch:18 loss:1.1006996631622314\n",
      "epoch:42,batch:19 loss:1.0905433893203735\n",
      "epoch:42,batch:20 loss:1.0999183654785156\n",
      "epoch:42,batch:21 loss:1.1061683893203735\n",
      "epoch:42,batch:22 loss:1.1217933893203735\n",
      "epoch:42,batch:23 loss:1.0913246870040894\n",
      "epoch:42,batch:24 loss:1.0835120677947998\n",
      "epoch:42,batch:25 loss:1.0999183654785156\n",
      "epoch:42,batch:26 loss:1.1022621393203735\n",
      "epoch:42,batch:27 loss:1.1022621393203735\n",
      "epoch:42,batch:28 loss:1.1038246154785156\n",
      "epoch:42,batch:29 loss:1.1147620677947998\n",
      "epoch:42,batch:30 loss:1.094449520111084\n",
      "epoch:42,batch:31 loss:1.1194496154785156\n",
      "epoch:42,batch:32 loss:1.1264808177947998\n",
      "epoch:42,batch:33 loss:1.086637020111084\n",
      "epoch:42,batch:34 loss:1.108512043952942\n",
      "epoch:42,batch:35 loss:1.1108558177947998\n",
      "epoch:42,batch:36 loss:1.115543246269226\n",
      "epoch:42,batch:37 loss:1.110074520111084\n",
      "epoch:42,batch:38 loss:1.0881996154785156\n",
      "epoch:42,batch:39 loss:1.0874183177947998\n",
      "epoch:42,batch:40 loss:1.0881996154785156\n",
      "epoch:42,batch:41 loss:1.1155433654785156\n",
      "epoch:42,batch:42 loss:1.1108558177947998\n",
      "epoch:42,batch:43 loss:1.098355770111084\n",
      "epoch:42,batch:44 loss:1.0975747108459473\n",
      "epoch:42,batch:45 loss:1.0881996154785156\n",
      "epoch:42,batch:46 loss:1.088980793952942\n",
      "epoch:42,batch:47 loss:1.0764808654785156\n",
      "epoch:42,batch:48 loss:1.1139808893203735\n",
      "epoch:42,batch:49 loss:1.116324543952942\n",
      "epoch:42,batch:50 loss:1.0944496393203735\n",
      "epoch:42,batch:51 loss:1.099918246269226\n",
      "epoch:42,batch:52 loss:1.106168270111084\n",
      "epoch:42,batch:53 loss:1.098355770111084\n",
      "epoch:42,batch:54 loss:1.0858558416366577\n",
      "epoch:42,batch:55 loss:1.094449520111084\n",
      "epoch:42,batch:56 loss:1.1053870916366577\n",
      "epoch:42,batch:57 loss:1.088980793952942\n",
      "epoch:42,batch:58 loss:1.1069495677947998\n",
      "epoch:42,batch:59 loss:1.092887043952942\n",
      "epoch:42,batch:60 loss:1.112418293952942\n",
      "epoch:42,batch:61 loss:1.0772621631622314\n",
      "epoch:42,batch:62 loss:1.1061683893203735\n",
      "epoch:42,batch:63 loss:1.0960121154785156\n",
      "epoch:42,batch:64 loss:1.0913245677947998\n",
      "epoch:42,batch:65 loss:1.1022621393203735\n",
      "epoch:42,batch:66 loss:1.1092933416366577\n",
      "epoch:42,batch:67 loss:1.0952308177947998\n",
      "epoch:42,batch:68 loss:1.0881996154785156\n",
      "epoch:42,batch:69 loss:1.1381995677947998\n",
      "epoch:42,batch:70 loss:1.0796058177947998\n",
      "epoch:42,batch:71 loss:1.1131995916366577\n",
      "epoch:42,batch:72 loss:1.099918246269226\n",
      "epoch:42,batch:73 loss:1.112418293952942\n",
      "epoch:42,batch:74 loss:1.1092933416366577\n",
      "epoch:42,batch:75 loss:1.0881996154785156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [05:54<00:57,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42,batch:76 loss:1.1139808893203735\n",
      "epoch:42,batch:77 loss:1.0936682224273682\n",
      "epoch:42, train_loss:1.0936682224273682\n",
      "epoch:43,batch:0 loss:1.1163246631622314\n",
      "epoch:43,batch:1 loss:1.0975747108459473\n",
      "epoch:43,batch:2 loss:1.1030433177947998\n",
      "epoch:43,batch:3 loss:1.068668246269226\n",
      "epoch:43,batch:4 loss:1.0913246870040894\n",
      "epoch:43,batch:5 loss:1.1147620677947998\n",
      "epoch:43,batch:6 loss:1.074918270111084\n",
      "epoch:43,batch:7 loss:1.106168270111084\n",
      "epoch:43,batch:8 loss:1.0928871631622314\n",
      "epoch:43,batch:9 loss:1.1217933893203735\n",
      "epoch:43,batch:10 loss:1.0999183654785156\n",
      "epoch:43,batch:11 loss:1.0780432224273682\n",
      "epoch:43,batch:12 loss:1.088980793952942\n",
      "epoch:43,batch:13 loss:1.1100746393203735\n",
      "epoch:43,batch:14 loss:1.1210122108459473\n",
      "epoch:43,batch:15 loss:1.0913245677947998\n",
      "epoch:43,batch:16 loss:1.099918246269226\n",
      "epoch:43,batch:17 loss:1.113980770111084\n",
      "epoch:43,batch:18 loss:1.110074520111084\n",
      "epoch:43,batch:19 loss:1.0889809131622314\n",
      "epoch:43,batch:20 loss:1.0921058654785156\n",
      "epoch:43,batch:21 loss:1.104605793952942\n",
      "epoch:43,batch:22 loss:1.0803871154785156\n",
      "epoch:43,batch:23 loss:1.0928871631622314\n",
      "epoch:43,batch:24 loss:1.0921058654785156\n",
      "epoch:43,batch:25 loss:1.1147620677947998\n",
      "epoch:43,batch:26 loss:1.1030433177947998\n",
      "epoch:43,batch:27 loss:1.0874183177947998\n",
      "epoch:43,batch:28 loss:1.104605793952942\n",
      "epoch:43,batch:29 loss:1.1116371154785156\n",
      "epoch:43,batch:30 loss:1.1030433177947998\n",
      "epoch:43,batch:31 loss:1.1171058416366577\n",
      "epoch:43,batch:32 loss:1.1053870916366577\n",
      "epoch:43,batch:33 loss:1.1100746393203735\n",
      "epoch:43,batch:34 loss:1.078824520111084\n",
      "epoch:43,batch:35 loss:1.1116371154785156\n",
      "epoch:43,batch:36 loss:1.0975745916366577\n",
      "epoch:43,batch:37 loss:1.1006996631622314\n",
      "epoch:43,batch:38 loss:1.0936683416366577\n",
      "epoch:43,batch:39 loss:1.117887020111084\n",
      "epoch:43,batch:40 loss:1.1053870916366577\n",
      "epoch:43,batch:41 loss:1.0975745916366577\n",
      "epoch:43,batch:42 loss:1.1116371154785156\n",
      "epoch:43,batch:43 loss:1.0835120677947998\n",
      "epoch:43,batch:44 loss:1.1342933177947998\n",
      "epoch:43,batch:45 loss:1.1147621870040894\n",
      "epoch:43,batch:46 loss:1.0999183654785156\n",
      "epoch:43,batch:47 loss:1.0850744247436523\n",
      "epoch:43,batch:48 loss:1.0991370677947998\n",
      "epoch:43,batch:49 loss:1.0874183177947998\n",
      "epoch:43,batch:50 loss:1.088980793952942\n",
      "epoch:43,batch:51 loss:1.0999183654785156\n",
      "epoch:43,batch:52 loss:1.1038246154785156\n",
      "epoch:43,batch:53 loss:1.1092933416366577\n",
      "epoch:43,batch:54 loss:1.0936684608459473\n",
      "epoch:43,batch:55 loss:1.0796058177947998\n",
      "epoch:43,batch:56 loss:1.1006996631622314\n",
      "epoch:43,batch:57 loss:1.088199496269226\n",
      "epoch:43,batch:58 loss:1.0991370677947998\n",
      "epoch:43,batch:59 loss:1.080386996269226\n",
      "epoch:43,batch:60 loss:1.0975745916366577\n",
      "epoch:43,batch:61 loss:1.113980770111084\n",
      "epoch:43,batch:62 loss:1.0858559608459473\n",
      "epoch:43,batch:63 loss:1.1069495677947998\n",
      "epoch:43,batch:64 loss:1.0983558893203735\n",
      "epoch:43,batch:65 loss:1.125699520111084\n",
      "epoch:43,batch:66 loss:1.094449520111084\n",
      "epoch:43,batch:67 loss:1.1233558654785156\n",
      "epoch:43,batch:68 loss:1.1108558177947998\n",
      "epoch:43,batch:69 loss:1.1092933416366577\n",
      "epoch:43,batch:70 loss:1.0897620916366577\n",
      "epoch:43,batch:71 loss:1.0764808654785156\n",
      "epoch:43,batch:72 loss:1.112418293952942\n",
      "epoch:43,batch:73 loss:1.0921058654785156\n",
      "epoch:43,batch:74 loss:1.0999183654785156\n",
      "epoch:43,batch:75 loss:1.084293246269226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [06:03<00:49,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43,batch:76 loss:1.1155433654785156\n",
      "epoch:43,batch:77 loss:1.1116371154785156\n",
      "epoch:43, train_loss:1.1116371154785156\n",
      "epoch:44,batch:0 loss:1.1053870916366577\n",
      "epoch:44,batch:1 loss:1.0803872346878052\n",
      "epoch:44,batch:2 loss:1.1233558654785156\n",
      "epoch:44,batch:3 loss:1.1108558177947998\n",
      "epoch:44,batch:4 loss:1.1014808416366577\n",
      "epoch:44,batch:5 loss:1.0889809131622314\n",
      "epoch:44,batch:6 loss:1.1030433177947998\n",
      "epoch:44,batch:7 loss:1.1038246154785156\n",
      "epoch:44,batch:8 loss:1.104605793952942\n",
      "epoch:44,batch:9 loss:1.0803871154785156\n",
      "epoch:44,batch:10 loss:1.0944496393203735\n",
      "epoch:44,batch:11 loss:1.0975747108459473\n",
      "epoch:44,batch:12 loss:1.1092933416366577\n",
      "epoch:44,batch:13 loss:1.102262020111084\n",
      "epoch:44,batch:14 loss:1.0858558416366577\n",
      "epoch:44,batch:15 loss:1.1014808416366577\n",
      "epoch:44,batch:16 loss:1.116324543952942\n",
      "epoch:44,batch:17 loss:1.0967934131622314\n",
      "epoch:44,batch:18 loss:1.0952309370040894\n",
      "epoch:44,batch:19 loss:1.0975745916366577\n",
      "epoch:44,batch:20 loss:1.100699543952942\n",
      "epoch:44,batch:21 loss:1.1194496154785156\n",
      "epoch:44,batch:22 loss:1.1030434370040894\n",
      "epoch:44,batch:23 loss:1.0967934131622314\n",
      "epoch:44,batch:24 loss:1.0921058654785156\n",
      "epoch:44,batch:25 loss:1.0952308177947998\n",
      "epoch:44,batch:26 loss:1.119449496269226\n",
      "epoch:44,batch:27 loss:1.1131995916366577\n",
      "epoch:44,batch:28 loss:1.0717933177947998\n",
      "epoch:44,batch:29 loss:1.0999183654785156\n",
      "epoch:44,batch:30 loss:1.125699520111084\n",
      "epoch:44,batch:31 loss:1.099918246269226\n",
      "epoch:44,batch:32 loss:1.0858558416366577\n",
      "epoch:44,batch:33 loss:1.0936683416366577\n",
      "epoch:44,batch:34 loss:1.1046059131622314\n",
      "epoch:44,batch:35 loss:1.129605770111084\n",
      "epoch:44,batch:36 loss:1.1014808416366577\n",
      "epoch:44,batch:37 loss:1.131168246269226\n",
      "epoch:44,batch:38 loss:1.0678870677947998\n",
      "epoch:44,batch:39 loss:1.116324543952942\n",
      "epoch:44,batch:40 loss:1.1155433654785156\n",
      "epoch:44,batch:41 loss:1.1077308654785156\n",
      "epoch:44,batch:42 loss:1.088980793952942\n",
      "epoch:44,batch:43 loss:1.1069495677947998\n",
      "epoch:44,batch:44 loss:1.1014808416366577\n",
      "epoch:44,batch:45 loss:1.1069496870040894\n",
      "epoch:44,batch:46 loss:1.117887020111084\n",
      "epoch:44,batch:47 loss:1.107730746269226\n",
      "epoch:44,batch:48 loss:1.1046059131622314\n",
      "epoch:44,batch:49 loss:1.1069495677947998\n",
      "epoch:44,batch:50 loss:1.0991370677947998\n",
      "epoch:44,batch:51 loss:1.0960121154785156\n",
      "epoch:44,batch:52 loss:1.0991370677947998\n",
      "epoch:44,batch:53 loss:1.0952309370040894\n",
      "epoch:44,batch:54 loss:1.092887043952942\n",
      "epoch:44,batch:55 loss:1.0881996154785156\n",
      "epoch:44,batch:56 loss:1.1077308654785156\n",
      "epoch:44,batch:57 loss:1.0975745916366577\n",
      "epoch:44,batch:58 loss:1.1038246154785156\n",
      "epoch:44,batch:59 loss:1.072574496269226\n",
      "epoch:44,batch:60 loss:1.085074543952942\n",
      "epoch:44,batch:61 loss:1.0944496393203735\n",
      "epoch:44,batch:62 loss:1.0967934131622314\n",
      "epoch:44,batch:63 loss:1.0788246393203735\n",
      "epoch:44,batch:64 loss:1.112418293952942\n",
      "epoch:44,batch:65 loss:1.1108558177947998\n",
      "epoch:44,batch:66 loss:1.1100746393203735\n",
      "epoch:44,batch:67 loss:1.0796058177947998\n",
      "epoch:44,batch:68 loss:1.104605793952942\n",
      "epoch:44,batch:69 loss:1.1061683893203735\n",
      "epoch:44,batch:70 loss:1.0827308893203735\n",
      "epoch:44,batch:71 loss:1.0936684608459473\n",
      "epoch:44,batch:72 loss:1.1030433177947998\n",
      "epoch:44,batch:73 loss:1.100699543952942\n",
      "epoch:44,batch:74 loss:1.0960121154785156\n",
      "epoch:44,batch:75 loss:1.092887043952942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [06:11<00:41,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44,batch:76 loss:1.1053870916366577\n",
      "epoch:44,batch:77 loss:1.090543270111084\n",
      "epoch:44, train_loss:1.090543270111084\n",
      "epoch:45,batch:0 loss:1.1131995916366577\n",
      "epoch:45,batch:1 loss:1.090543270111084\n",
      "epoch:45,batch:2 loss:1.1147620677947998\n",
      "epoch:45,batch:3 loss:1.0967934131622314\n",
      "epoch:45,batch:4 loss:1.0952309370040894\n",
      "epoch:45,batch:5 loss:1.1069495677947998\n",
      "epoch:45,batch:6 loss:1.0913245677947998\n",
      "epoch:45,batch:7 loss:1.098355770111084\n",
      "epoch:45,batch:8 loss:1.1077308654785156\n",
      "epoch:45,batch:9 loss:1.1030433177947998\n",
      "epoch:45,batch:10 loss:1.116324543952942\n",
      "epoch:45,batch:11 loss:1.0764808654785156\n",
      "epoch:45,batch:12 loss:1.1030433177947998\n",
      "epoch:45,batch:13 loss:1.108512043952942\n",
      "epoch:45,batch:14 loss:1.106168270111084\n",
      "epoch:45,batch:15 loss:1.103824496269226\n",
      "epoch:45,batch:16 loss:1.0936683416366577\n",
      "epoch:45,batch:17 loss:1.085074543952942\n",
      "epoch:45,batch:18 loss:1.0756995677947998\n",
      "epoch:45,batch:19 loss:1.0780433416366577\n",
      "epoch:45,batch:20 loss:1.0874184370040894\n",
      "epoch:45,batch:21 loss:1.1030433177947998\n",
      "epoch:45,batch:22 loss:1.1225745677947998\n",
      "epoch:45,batch:23 loss:1.1131995916366577\n",
      "epoch:45,batch:24 loss:1.1225745677947998\n",
      "epoch:45,batch:25 loss:1.106168270111084\n",
      "epoch:45,batch:26 loss:1.1327307224273682\n",
      "epoch:45,batch:27 loss:1.0944496393203735\n",
      "epoch:45,batch:28 loss:1.1256996393203735\n",
      "epoch:45,batch:29 loss:1.1342933177947998\n",
      "epoch:45,batch:30 loss:1.1053870916366577\n",
      "epoch:45,batch:31 loss:1.108512043952942\n",
      "epoch:45,batch:32 loss:1.0889809131622314\n",
      "epoch:45,batch:33 loss:1.104605793952942\n",
      "epoch:45,batch:34 loss:1.0819495916366577\n",
      "epoch:45,batch:35 loss:1.078824520111084\n",
      "epoch:45,batch:36 loss:1.0936682224273682\n",
      "epoch:45,batch:37 loss:1.0780433416366577\n",
      "epoch:45,batch:38 loss:1.092887043952942\n",
      "epoch:45,batch:39 loss:1.1006996631622314\n",
      "epoch:45,batch:40 loss:1.0975745916366577\n",
      "epoch:45,batch:41 loss:1.108512043952942\n",
      "epoch:45,batch:42 loss:1.0952308177947998\n",
      "epoch:45,batch:43 loss:1.0881996154785156\n",
      "epoch:45,batch:44 loss:1.0788246393203735\n",
      "epoch:45,batch:45 loss:1.0842933654785156\n",
      "epoch:45,batch:46 loss:1.0991370677947998\n",
      "epoch:45,batch:47 loss:1.1210119724273682\n",
      "epoch:45,batch:48 loss:1.0608558654785156\n",
      "epoch:45,batch:49 loss:1.1077308654785156\n",
      "epoch:45,batch:50 loss:1.1264809370040894\n",
      "epoch:45,batch:51 loss:1.1116371154785156\n",
      "epoch:45,batch:52 loss:1.100699543952942\n",
      "epoch:45,batch:53 loss:1.1014807224273682\n",
      "epoch:45,batch:54 loss:1.1163246631622314\n",
      "epoch:45,batch:55 loss:1.0913245677947998\n",
      "epoch:45,batch:56 loss:1.0960121154785156\n",
      "epoch:45,batch:57 loss:1.1116371154785156\n",
      "epoch:45,batch:58 loss:1.0881996154785156\n",
      "epoch:45,batch:59 loss:1.0858558416366577\n",
      "epoch:45,batch:60 loss:1.094449520111084\n",
      "epoch:45,batch:61 loss:1.092887043952942\n",
      "epoch:45,batch:62 loss:1.111636996269226\n",
      "epoch:45,batch:63 loss:1.0936683416366577\n",
      "epoch:45,batch:64 loss:1.0952308177947998\n",
      "epoch:45,batch:65 loss:1.1171058416366577\n",
      "epoch:45,batch:66 loss:1.1038246154785156\n",
      "epoch:45,batch:67 loss:1.111636996269226\n",
      "epoch:45,batch:68 loss:1.1014808416366577\n",
      "epoch:45,batch:69 loss:1.1155433654785156\n",
      "epoch:45,batch:70 loss:1.1202309131622314\n",
      "epoch:45,batch:71 loss:1.0999183654785156\n",
      "epoch:45,batch:72 loss:1.088980793952942\n",
      "epoch:45,batch:73 loss:1.1131995916366577\n",
      "epoch:45,batch:74 loss:1.113980770111084\n",
      "epoch:45,batch:75 loss:1.090543270111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [06:19<00:33,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45,batch:76 loss:1.0889809131622314\n",
      "epoch:45,batch:77 loss:1.0725746154785156\n",
      "epoch:45, train_loss:1.0725746154785156\n",
      "epoch:46,batch:0 loss:1.112418293952942\n",
      "epoch:46,batch:1 loss:1.1264808177947998\n",
      "epoch:46,batch:2 loss:1.0975747108459473\n",
      "epoch:46,batch:3 loss:1.1030434370040894\n",
      "epoch:46,batch:4 loss:1.1061683893203735\n",
      "epoch:46,batch:5 loss:1.0960121154785156\n",
      "epoch:46,batch:6 loss:1.1249183416366577\n",
      "epoch:46,batch:7 loss:1.085074543952942\n",
      "epoch:46,batch:8 loss:1.096011996269226\n",
      "epoch:46,batch:9 loss:1.120230793952942\n",
      "epoch:46,batch:10 loss:1.0975745916366577\n",
      "epoch:46,batch:11 loss:1.1030434370040894\n",
      "epoch:46,batch:12 loss:1.0819495916366577\n",
      "epoch:46,batch:13 loss:1.0803871154785156\n",
      "epoch:46,batch:14 loss:1.077262043952942\n",
      "epoch:46,batch:15 loss:1.0936682224273682\n",
      "epoch:46,batch:16 loss:1.1147620677947998\n",
      "epoch:46,batch:17 loss:1.117887020111084\n",
      "epoch:46,batch:18 loss:1.081168293952942\n",
      "epoch:46,batch:19 loss:1.085074543952942\n",
      "epoch:46,batch:20 loss:1.1092933416366577\n",
      "epoch:46,batch:21 loss:1.0749183893203735\n",
      "epoch:46,batch:22 loss:1.0936683416366577\n",
      "epoch:46,batch:23 loss:1.1155433654785156\n",
      "epoch:46,batch:24 loss:1.0952308177947998\n",
      "epoch:46,batch:25 loss:1.1171058416366577\n",
      "epoch:46,batch:26 loss:1.088980793952942\n",
      "epoch:46,batch:27 loss:1.121793270111084\n",
      "epoch:46,batch:28 loss:1.1038246154785156\n",
      "epoch:46,batch:29 loss:1.1171058416366577\n",
      "epoch:46,batch:30 loss:1.0928871631622314\n",
      "epoch:46,batch:31 loss:1.096793293952942\n",
      "epoch:46,batch:32 loss:1.1155433654785156\n",
      "epoch:46,batch:33 loss:1.092105746269226\n",
      "epoch:46,batch:34 loss:1.1233558654785156\n",
      "epoch:46,batch:35 loss:1.0921058654785156\n",
      "epoch:46,batch:36 loss:1.0874183177947998\n",
      "epoch:46,batch:37 loss:1.0780432224273682\n",
      "epoch:46,batch:38 loss:1.0678870677947998\n",
      "epoch:46,batch:39 loss:1.0866371393203735\n",
      "epoch:46,batch:40 loss:1.1147619485855103\n",
      "epoch:46,batch:41 loss:1.119449496269226\n",
      "epoch:46,batch:42 loss:1.0881996154785156\n",
      "epoch:46,batch:43 loss:1.0960121154785156\n",
      "epoch:46,batch:44 loss:1.088199496269226\n",
      "epoch:46,batch:45 loss:1.0921058654785156\n",
      "epoch:46,batch:46 loss:1.0717933177947998\n",
      "epoch:46,batch:47 loss:1.1155433654785156\n",
      "epoch:46,batch:48 loss:1.0991370677947998\n",
      "epoch:46,batch:49 loss:1.086637020111084\n",
      "epoch:46,batch:50 loss:1.0999183654785156\n",
      "epoch:46,batch:51 loss:1.1085121631622314\n",
      "epoch:46,batch:52 loss:1.094449520111084\n",
      "epoch:46,batch:53 loss:1.0967934131622314\n",
      "epoch:46,batch:54 loss:1.1280434131622314\n",
      "epoch:46,batch:55 loss:1.1014808416366577\n",
      "epoch:46,batch:56 loss:1.0999183654785156\n",
      "epoch:46,batch:57 loss:1.1046059131622314\n",
      "epoch:46,batch:58 loss:1.096793293952942\n",
      "epoch:46,batch:59 loss:1.108512043952942\n",
      "epoch:46,batch:60 loss:1.1061683893203735\n",
      "epoch:46,batch:61 loss:1.092887043952942\n",
      "epoch:46,batch:62 loss:1.1272621154785156\n",
      "epoch:46,batch:63 loss:1.0913245677947998\n",
      "epoch:46,batch:64 loss:1.102262258529663\n",
      "epoch:46,batch:65 loss:1.090543270111084\n",
      "epoch:46,batch:66 loss:1.1108558177947998\n",
      "epoch:46,batch:67 loss:1.0866371393203735\n",
      "epoch:46,batch:68 loss:1.1303870677947998\n",
      "epoch:46,batch:69 loss:1.0803871154785156\n",
      "epoch:46,batch:70 loss:1.110074520111084\n",
      "epoch:46,batch:71 loss:1.112418293952942\n",
      "epoch:46,batch:72 loss:1.094449520111084\n",
      "epoch:46,batch:73 loss:1.1186683177947998\n",
      "epoch:46,batch:74 loss:1.1131997108459473\n",
      "epoch:46,batch:75 loss:1.082730770111084\n",
      "epoch:46,batch:76 loss:1.0866371393203735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [06:27<00:24,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46,batch:77 loss:1.1030433177947998\n",
      "epoch:46, train_loss:1.1030433177947998\n",
      "epoch:47,batch:0 loss:1.104605793952942\n",
      "epoch:47,batch:1 loss:1.1092934608459473\n",
      "epoch:47,batch:2 loss:1.1022621393203735\n",
      "epoch:47,batch:3 loss:1.1046059131622314\n",
      "epoch:47,batch:4 loss:1.0881996154785156\n",
      "epoch:47,batch:5 loss:1.1053869724273682\n",
      "epoch:47,batch:6 loss:1.1100746393203735\n",
      "epoch:47,batch:7 loss:1.0874183177947998\n",
      "epoch:47,batch:8 loss:1.1014807224273682\n",
      "epoch:47,batch:9 loss:1.0835120677947998\n",
      "epoch:47,batch:10 loss:1.082730770111084\n",
      "epoch:47,batch:11 loss:1.1155433654785156\n",
      "epoch:47,batch:12 loss:1.1030433177947998\n",
      "epoch:47,batch:13 loss:1.094449520111084\n",
      "epoch:47,batch:14 loss:1.1077308654785156\n",
      "epoch:47,batch:15 loss:1.086637020111084\n",
      "epoch:47,batch:16 loss:1.0866371393203735\n",
      "epoch:47,batch:17 loss:1.0835120677947998\n",
      "epoch:47,batch:18 loss:1.1092933416366577\n",
      "epoch:47,batch:19 loss:1.1092933416366577\n",
      "epoch:47,batch:20 loss:1.1069495677947998\n",
      "epoch:47,batch:21 loss:1.090543270111084\n",
      "epoch:47,batch:22 loss:1.1069495677947998\n",
      "epoch:47,batch:23 loss:1.1194496154785156\n",
      "epoch:47,batch:24 loss:1.0952308177947998\n",
      "epoch:47,batch:25 loss:1.1108558177947998\n",
      "epoch:47,batch:26 loss:1.0913245677947998\n",
      "epoch:47,batch:27 loss:1.1014808416366577\n",
      "epoch:47,batch:28 loss:1.1069495677947998\n",
      "epoch:47,batch:29 loss:1.1092933416366577\n",
      "epoch:47,batch:30 loss:1.0608558654785156\n",
      "epoch:47,batch:31 loss:1.110074520111084\n",
      "epoch:47,batch:32 loss:1.0967934131622314\n",
      "epoch:47,batch:33 loss:1.1131995916366577\n",
      "epoch:47,batch:34 loss:1.108512043952942\n",
      "epoch:47,batch:35 loss:1.0803871154785156\n",
      "epoch:47,batch:36 loss:1.085074543952942\n",
      "epoch:47,batch:37 loss:1.1061683893203735\n",
      "epoch:47,batch:38 loss:1.0788246393203735\n",
      "epoch:47,batch:39 loss:1.1085121631622314\n",
      "epoch:47,batch:40 loss:1.1100746393203735\n",
      "epoch:47,batch:41 loss:1.1030433177947998\n",
      "epoch:47,batch:42 loss:1.1147619485855103\n",
      "epoch:47,batch:43 loss:1.1131995916366577\n",
      "epoch:47,batch:44 loss:1.1038246154785156\n",
      "epoch:47,batch:45 loss:1.1171058416366577\n",
      "epoch:47,batch:46 loss:1.1163246631622314\n",
      "epoch:47,batch:47 loss:1.098355770111084\n",
      "epoch:47,batch:48 loss:1.0866371393203735\n",
      "epoch:47,batch:49 loss:1.1155433654785156\n",
      "epoch:47,batch:50 loss:1.0897620916366577\n",
      "epoch:47,batch:51 loss:1.1108558177947998\n",
      "epoch:47,batch:52 loss:1.1108558177947998\n",
      "epoch:47,batch:53 loss:1.1155433654785156\n",
      "epoch:47,batch:54 loss:1.077262043952942\n",
      "epoch:47,batch:55 loss:1.0975745916366577\n",
      "epoch:47,batch:56 loss:1.110074520111084\n",
      "epoch:47,batch:57 loss:1.1038246154785156\n",
      "epoch:47,batch:58 loss:1.096793293952942\n",
      "epoch:47,batch:59 loss:1.124137043952942\n",
      "epoch:47,batch:60 loss:1.1131995916366577\n",
      "epoch:47,batch:61 loss:1.1053870916366577\n",
      "epoch:47,batch:62 loss:1.0952308177947998\n",
      "epoch:47,batch:63 loss:1.1225745677947998\n",
      "epoch:47,batch:64 loss:1.0967934131622314\n",
      "epoch:47,batch:65 loss:1.0975745916366577\n",
      "epoch:47,batch:66 loss:1.0764808654785156\n",
      "epoch:47,batch:67 loss:1.1038246154785156\n",
      "epoch:47,batch:68 loss:1.085074543952942\n",
      "epoch:47,batch:69 loss:1.0702308416366577\n",
      "epoch:47,batch:70 loss:1.1178871393203735\n",
      "epoch:47,batch:71 loss:1.108512043952942\n",
      "epoch:47,batch:72 loss:1.0960121154785156\n",
      "epoch:47,batch:73 loss:1.0827308893203735\n",
      "epoch:47,batch:74 loss:1.090543270111084\n",
      "epoch:47,batch:75 loss:1.0983558893203735\n",
      "epoch:47,batch:76 loss:1.096011996269226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [06:36<00:16,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47,batch:77 loss:1.0866371393203735\n",
      "epoch:47, train_loss:1.0866371393203735\n",
      "epoch:48,batch:0 loss:1.0975745916366577\n",
      "epoch:48,batch:1 loss:1.1171058416366577\n",
      "epoch:48,batch:2 loss:1.1069495677947998\n",
      "epoch:48,batch:3 loss:1.1147620677947998\n",
      "epoch:48,batch:4 loss:1.0913245677947998\n",
      "epoch:48,batch:5 loss:1.0741372108459473\n",
      "epoch:48,batch:6 loss:1.1085121631622314\n",
      "epoch:48,batch:7 loss:1.0921058654785156\n",
      "epoch:48,batch:8 loss:1.110074520111084\n",
      "epoch:48,batch:9 loss:1.0991370677947998\n",
      "epoch:48,batch:10 loss:1.102262020111084\n",
      "epoch:48,batch:11 loss:1.1131995916366577\n",
      "epoch:48,batch:12 loss:1.1038246154785156\n",
      "epoch:48,batch:13 loss:1.090543508529663\n",
      "epoch:48,batch:14 loss:1.1147620677947998\n",
      "epoch:48,batch:15 loss:1.0967934131622314\n",
      "epoch:48,batch:16 loss:1.0936683416366577\n",
      "epoch:48,batch:17 loss:1.094449520111084\n",
      "epoch:48,batch:18 loss:1.088980793952942\n",
      "epoch:48,batch:19 loss:1.115543246269226\n",
      "epoch:48,batch:20 loss:1.1139808893203735\n",
      "epoch:48,batch:21 loss:1.100699543952942\n",
      "epoch:48,batch:22 loss:1.0944496393203735\n",
      "epoch:48,batch:23 loss:1.1319496631622314\n",
      "epoch:48,batch:24 loss:1.0913245677947998\n",
      "epoch:48,batch:25 loss:1.1249183416366577\n",
      "epoch:48,batch:26 loss:1.1171057224273682\n",
      "epoch:48,batch:27 loss:1.1288244724273682\n",
      "epoch:48,batch:28 loss:1.1014807224273682\n",
      "epoch:48,batch:29 loss:1.099918246269226\n",
      "epoch:48,batch:30 loss:1.108512043952942\n",
      "epoch:48,batch:31 loss:1.0756995677947998\n",
      "epoch:48,batch:32 loss:1.0999183654785156\n",
      "epoch:48,batch:33 loss:1.0991370677947998\n",
      "epoch:48,batch:34 loss:1.1069495677947998\n",
      "epoch:48,batch:35 loss:1.0881996154785156\n",
      "epoch:48,batch:36 loss:1.0913245677947998\n",
      "epoch:48,batch:37 loss:1.1131995916366577\n",
      "epoch:48,batch:38 loss:1.0936683416366577\n",
      "epoch:48,batch:39 loss:1.096793293952942\n",
      "epoch:48,batch:40 loss:1.1030433177947998\n",
      "epoch:48,batch:41 loss:1.0936683416366577\n",
      "epoch:48,batch:42 loss:1.1006996631622314\n",
      "epoch:48,batch:43 loss:1.1014808416366577\n",
      "epoch:48,batch:44 loss:1.0967934131622314\n",
      "epoch:48,batch:45 loss:1.1100746393203735\n",
      "epoch:48,batch:46 loss:1.088980793952942\n",
      "epoch:48,batch:47 loss:1.1053869724273682\n",
      "epoch:48,batch:48 loss:1.1030433177947998\n",
      "epoch:48,batch:49 loss:1.0975745916366577\n",
      "epoch:48,batch:50 loss:1.096793293952942\n",
      "epoch:48,batch:51 loss:1.084293246269226\n",
      "epoch:48,batch:52 loss:1.0960121154785156\n",
      "epoch:48,batch:53 loss:1.0913245677947998\n",
      "epoch:48,batch:54 loss:1.0952309370040894\n",
      "epoch:48,batch:55 loss:1.1053872108459473\n",
      "epoch:48,batch:56 loss:1.1053870916366577\n",
      "epoch:48,batch:57 loss:1.0952308177947998\n",
      "epoch:48,batch:58 loss:1.090543270111084\n",
      "epoch:48,batch:59 loss:1.0796059370040894\n",
      "epoch:48,batch:60 loss:1.074918270111084\n",
      "epoch:48,batch:61 loss:1.0858559608459473\n",
      "epoch:48,batch:62 loss:1.092105746269226\n",
      "epoch:48,batch:63 loss:1.112418293952942\n",
      "epoch:48,batch:64 loss:1.104605793952942\n",
      "epoch:48,batch:65 loss:1.090543270111084\n",
      "epoch:48,batch:66 loss:1.1061683893203735\n",
      "epoch:48,batch:67 loss:1.125699520111084\n",
      "epoch:48,batch:68 loss:1.1030433177947998\n",
      "epoch:48,batch:69 loss:1.1155433654785156\n",
      "epoch:48,batch:70 loss:1.0999183654785156\n",
      "epoch:48,batch:71 loss:1.0991370677947998\n",
      "epoch:48,batch:72 loss:1.0881996154785156\n",
      "epoch:48,batch:73 loss:1.0866371393203735\n",
      "epoch:48,batch:74 loss:1.1014808416366577\n",
      "epoch:48,batch:75 loss:1.0936683416366577\n",
      "epoch:48,batch:76 loss:1.117887020111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [06:46<00:08,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48,batch:77 loss:1.0874183177947998\n",
      "epoch:48, train_loss:1.0874183177947998\n",
      "epoch:49,batch:0 loss:1.0975745916366577\n",
      "epoch:49,batch:1 loss:1.116324543952942\n",
      "epoch:49,batch:2 loss:1.0905433893203735\n",
      "epoch:49,batch:3 loss:1.116324543952942\n",
      "epoch:49,batch:4 loss:1.096793293952942\n",
      "epoch:49,batch:5 loss:1.0897620916366577\n",
      "epoch:49,batch:6 loss:1.094449520111084\n",
      "epoch:49,batch:7 loss:1.102262020111084\n",
      "epoch:49,batch:8 loss:1.1014808416366577\n",
      "epoch:49,batch:9 loss:1.0921058654785156\n",
      "epoch:49,batch:10 loss:1.1006996631622314\n",
      "epoch:49,batch:11 loss:1.0842933654785156\n",
      "epoch:49,batch:12 loss:1.0874183177947998\n",
      "epoch:49,batch:13 loss:1.0874183177947998\n",
      "epoch:49,batch:14 loss:1.094449520111084\n",
      "epoch:49,batch:15 loss:1.110074520111084\n",
      "epoch:49,batch:16 loss:1.116324543952942\n",
      "epoch:49,batch:17 loss:1.1030433177947998\n",
      "epoch:49,batch:18 loss:1.128043293952942\n",
      "epoch:49,batch:19 loss:1.088980793952942\n",
      "epoch:49,batch:20 loss:1.117887020111084\n",
      "epoch:49,batch:21 loss:1.0975745916366577\n",
      "epoch:49,batch:22 loss:1.1022621393203735\n",
      "epoch:49,batch:23 loss:1.1077308654785156\n",
      "epoch:49,batch:24 loss:1.0819495916366577\n",
      "epoch:49,batch:25 loss:1.0756995677947998\n",
      "epoch:49,batch:26 loss:1.1006996631622314\n",
      "epoch:49,batch:27 loss:1.1272621154785156\n",
      "epoch:49,batch:28 loss:1.0835121870040894\n",
      "epoch:49,batch:29 loss:1.0710121393203735\n",
      "epoch:49,batch:30 loss:1.1124181747436523\n",
      "epoch:49,batch:31 loss:1.0936683416366577\n",
      "epoch:49,batch:32 loss:1.0796059370040894\n",
      "epoch:49,batch:33 loss:1.1030433177947998\n",
      "epoch:49,batch:34 loss:1.123355746269226\n",
      "epoch:49,batch:35 loss:1.0889809131622314\n",
      "epoch:49,batch:36 loss:1.108512043952942\n",
      "epoch:49,batch:37 loss:1.1124184131622314\n",
      "epoch:49,batch:38 loss:1.0842933654785156\n",
      "epoch:49,batch:39 loss:1.086637020111084\n",
      "epoch:49,batch:40 loss:1.1116371154785156\n",
      "epoch:49,batch:41 loss:1.1131995916366577\n",
      "epoch:49,batch:42 loss:1.1116371154785156\n",
      "epoch:49,batch:43 loss:1.1147620677947998\n",
      "epoch:49,batch:44 loss:1.1038246154785156\n",
      "epoch:49,batch:45 loss:1.0999183654785156\n",
      "epoch:49,batch:46 loss:1.0991370677947998\n",
      "epoch:49,batch:47 loss:1.1022621393203735\n",
      "epoch:49,batch:48 loss:1.1171058416366577\n",
      "epoch:49,batch:49 loss:1.0835121870040894\n",
      "epoch:49,batch:50 loss:1.0913246870040894\n",
      "epoch:49,batch:51 loss:1.098355770111084\n",
      "epoch:49,batch:52 loss:1.117887020111084\n",
      "epoch:49,batch:53 loss:1.0827308893203735\n",
      "epoch:49,batch:54 loss:1.0967934131622314\n",
      "epoch:49,batch:55 loss:1.117887020111084\n",
      "epoch:49,batch:56 loss:1.0858558416366577\n",
      "epoch:49,batch:57 loss:1.1030433177947998\n",
      "epoch:49,batch:58 loss:1.1069496870040894\n",
      "epoch:49,batch:59 loss:1.094449520111084\n",
      "epoch:49,batch:60 loss:1.0858558416366577\n",
      "epoch:49,batch:61 loss:1.1046059131622314\n",
      "epoch:49,batch:62 loss:1.0936683416366577\n",
      "epoch:49,batch:63 loss:1.0858558416366577\n",
      "epoch:49,batch:64 loss:1.1155433654785156\n",
      "epoch:49,batch:65 loss:1.1014808416366577\n",
      "epoch:49,batch:66 loss:1.1085121631622314\n",
      "epoch:49,batch:67 loss:1.1077308654785156\n",
      "epoch:49,batch:68 loss:1.102262020111084\n",
      "epoch:49,batch:69 loss:1.100699543952942\n",
      "epoch:49,batch:70 loss:1.1124184131622314\n",
      "epoch:49,batch:71 loss:1.1194496154785156\n",
      "epoch:49,batch:72 loss:1.0796058177947998\n",
      "epoch:49,batch:73 loss:1.1210120916366577\n",
      "epoch:49,batch:74 loss:1.117887020111084\n",
      "epoch:49,batch:75 loss:1.0897620916366577\n",
      "epoch:49,batch:76 loss:1.0842933654785156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:54<00:00,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49,batch:77 loss:1.1046059131622314\n",
      "epoch:49, train_loss:1.1046059131622314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建优化器\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=0.005, parameters=model.parameters())\n",
    "\n",
    "# 模型训练\n",
    "for current_epoch in tqdm(range(50)):\n",
    "    for batch_id, data in enumerate(train_reader()): \n",
    "        # 前向传播\n",
    "        data_x = data[0]\n",
    "        data_y = data[1]\n",
    "        predict = model(data_x)\n",
    "        # 放到tensor中\n",
    "        data_y = paddle.to_tensor(data_y.numpy(), dtype='int64')\n",
    "        # 交叉信息熵损失\n",
    "        avg_loss = F.cross_entropy(predict,data_y)\n",
    "        #print('predict=', predict)\n",
    "        #break\n",
    "        y_np = np.array(data_y.numpy()).reshape(-1, 1)\n",
    "        # 将结果转换为one_hot形式\n",
    "        y_onehot = onehot_encoder.transform(y_np)\n",
    "        # 得到avg_score\n",
    "        avg_score = mae_loss(predict.numpy(), y_onehot)\n",
    "        # 反向传播\n",
    "        avg_loss.backward()       \n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "        print(\"epoch:{},batch:{} loss:{}\".format(current_epoch, batch_id, np.mean(avg_loss.numpy())))\n",
    "\n",
    "    print(\"epoch:{}, train_loss:{}\".format(current_epoch, avg_loss.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:42:33.136141Z",
     "iopub.status.busy": "2022-04-15T06:42:33.135723Z",
     "iopub.status.idle": "2022-04-15T06:42:33.237035Z",
     "shell.execute_reply": "2022-04-15T06:42:33.236128Z",
     "shell.execute_reply.started": "2022-04-15T06:42:33.136112Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1046059131622314\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "paddle.save(model.state_dict(),'work/model/cnn.model')\n",
    "print(\"Loss: {}\".format(avg_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:42:33.238692Z",
     "iopub.status.busy": "2022-04-15T06:42:33.238151Z",
     "iopub.status.idle": "2022-04-15T06:42:33.372416Z",
     "shell.execute_reply": "2022-04-15T06:42:33.371605Z",
     "shell.execute_reply.started": "2022-04-15T06:42:33.238660Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型参数加载\n",
    "param_dict = paddle.load('work/model/cnn.model')\n",
    "model=CNNModel()\n",
    "# 加载参数\n",
    "model.load_dict(param_dict)   \n",
    "# 预测模式\n",
    "model.eval()   \n",
    "\n",
    "# 定义DataLoader\n",
    "data_reader = paddle.io.DataLoader(test_dataset,\n",
    "                        batch_size=1280,\n",
    "                        shuffle=False,\n",
    "                        drop_last=False,\n",
    "                        num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:42:33.374011Z",
     "iopub.status.busy": "2022-04-15T06:42:33.373499Z",
     "iopub.status.idle": "2022-04-15T06:42:34.145625Z",
     "shell.execute_reply": "2022-04-15T06:42:34.144846Z",
     "shell.execute_reply.started": "2022-04-15T06:42:33.373980Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, data in enumerate(data_reader()):\n",
    "    x = data[0]\n",
    "    out = model(x)\n",
    "    if index==0:\n",
    "        y_pred = out.numpy()\n",
    "    else:\n",
    "        y_pred = np.vstack((y_pred, out.numpy()))\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T06:42:34.147319Z",
     "iopub.status.busy": "2022-04-15T06:42:34.146782Z",
     "iopub.status.idle": "2022-04-15T06:42:34.239162Z",
     "shell.execute_reply": "2022-04-15T06:42:34.238413Z",
     "shell.execute_reply.started": "2022-04-15T06:42:34.147286Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>119995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>119996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>119997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>119998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>119999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  label_0  label_1  label_2  label_3\n",
       "0      100000      1.0      0.0      0.0      0.0\n",
       "1      100001      1.0      0.0      0.0      0.0\n",
       "2      100002      1.0      0.0      0.0      0.0\n",
       "3      100003      1.0      0.0      0.0      0.0\n",
       "4      100004      1.0      0.0      0.0      0.0\n",
       "...       ...      ...      ...      ...      ...\n",
       "19995  119995      1.0      0.0      0.0      0.0\n",
       "19996  119996      1.0      0.0      0.0      0.0\n",
       "19997  119997      1.0      0.0      0.0      0.0\n",
       "19998  119998      1.0      0.0      0.0      0.0\n",
       "19999  119999      1.0      0.0      0.0      0.0\n",
       "\n",
       "[20000 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出预测结果\n",
    "result = test1[['id']]\n",
    "result['label_0'] = y_pred[:,0]\n",
    "result['label_1'] = y_pred[:, 1]\n",
    "result['label_2'] = y_pred[:, 2]\n",
    "result['label_3'] = y_pred[:, 3]\n",
    "result.to_csv('./predict4-paddle-aistudio.csv',index=False)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
